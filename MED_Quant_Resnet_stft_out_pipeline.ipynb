{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af08b4fb",
   "metadata": {},
   "source": [
    "### Mofified the initial code to include SpecAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce548639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: jupyterlab in /opt/conda/lib/python3.8/site-packages (2.3.2)\n",
      "Collecting jupyterlab\n",
      "  Downloading jupyterlab-4.0.8-py3-none-any.whl (9.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.2 MB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from jupyterlab) (21.3)\n",
      "Requirement already satisfied: importlib-resources>=1.4 in /opt/conda/lib/python3.8/site-packages (from jupyterlab) (5.4.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.8/site-packages (from jupyterlab) (4.9.1)\n",
      "Requirement already satisfied: tomli in /opt/conda/lib/python3.8/site-packages (from jupyterlab) (1.2.2)\n",
      "Collecting jupyter-server<3,>=2.4.0\n",
      "  Downloading jupyter_server-2.10.0-py3-none-any.whl (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 128.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-lsp>=2.0.0\n",
      "  Downloading jupyter_lsp-2.2.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 113.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-lru>=1.0.0\n",
      "  Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.8/site-packages (from jupyterlab) (6.6.0)\n",
      "Collecting notebook-shim>=0.2\n",
      "  Downloading notebook_shim-0.2.3-py3-none-any.whl (13 kB)\n",
      "Collecting jupyterlab-server<3,>=2.19.0\n",
      "  Downloading jupyterlab_server-2.25.1-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 87.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-metadata>=4.8.3\n",
      "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
      "Collecting tornado>=6.2.0\n",
      "  Downloading tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n",
      "\u001b[K     |████████████████████████████████| 427 kB 108.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2>=3.0.3 in /opt/conda/lib/python3.8/site-packages (from jupyterlab) (3.0.3)\n",
      "Requirement already satisfied: traitlets in /opt/conda/lib/python3.8/site-packages (from jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from async-lru>=1.0.0->jupyterlab) (4.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.8.3->jupyterlab) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2>=3.0.3->jupyterlab) (2.0.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (21.1.0)\n",
      "Collecting anyio>=3.1.0\n",
      "  Downloading anyio-4.0.0-py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 83.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting overrides\n",
      "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
      "Collecting websocket-client\n",
      "  Downloading websocket_client-1.6.4-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 105.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-core\n",
      "  Downloading jupyter_core-5.5.0-py3-none-any.whl (28 kB)\n",
      "Collecting jupyter-events>=0.6.0\n",
      "  Downloading jupyter_events-0.9.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.12.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.12.1)\n",
      "Collecting traitlets\n",
      "  Downloading traitlets-5.13.0-py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 120.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyzmq>=24\n",
      "  Downloading pyzmq-25.1.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 113.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nbconvert>=6.4.4\n",
      "  Downloading nbconvert-7.11.0-py3-none-any.whl (256 kB)\n",
      "\u001b[K     |████████████████████████████████| 256 kB 123.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-client>=7.4.4\n",
      "  Downloading jupyter_client-8.6.0-py3-none-any.whl (105 kB)\n",
      "\u001b[K     |████████████████████████████████| 105 kB 150.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-server-terminals\n",
      "  Downloading jupyter_server_terminals-0.4.4-py3-none-any.whl (13 kB)\n",
      "Collecting nbformat>=5.3.0\n",
      "  Downloading nbformat-5.9.2-py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 91.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting send2trash>=1.8.2\n",
      "  Downloading Send2Trash-1.8.2-py3-none-any.whl (18 kB)\n",
      "Collecting exceptiongroup>=1.0.2\n",
      "  Downloading exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.8/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.1)\n",
      "Collecting sniffio>=1.1\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.8.2)\n",
      "Collecting platformdirs>=2.5\n",
      "  Downloading platformdirs-3.11.0-py3-none-any.whl (17 kB)\n",
      "Collecting jsonschema[format-nongpl]>=4.18.0\n",
      "  Downloading jsonschema-4.19.2-py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 77.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rfc3986-validator>=0.1.1\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.8/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0)\n",
      "Collecting referencing\n",
      "  Downloading referencing-0.30.2-py3-none-any.whl (25 kB)\n",
      "Collecting rfc3339-validator\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Collecting python-json-logger>=2.0.4\n",
      "  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
      "Collecting pkgutil-resolve-name>=1.3.10\n",
      "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 93.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting attrs>=22.2.0\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 93.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jsonschema-specifications>=2023.03.6\n",
      "  Downloading jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n",
      "Collecting isoduration\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Collecting fqdn\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting jsonpointer>1.13\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting uri-template\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Collecting webcolors>=1.11\n",
      "  Downloading webcolors-1.13-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/conda/lib/python3.8/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab) (0.9.6)\n",
      "Collecting requests>=2.31\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 71.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting babel>=2.10\n",
      "  Downloading Babel-2.13.1-py3-none-any.whl (10.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1 MB 119.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2015.7 in /opt/conda/lib/python3.8/site-packages (from babel>=2.10->jupyterlab-server<3,>=2.19.0->jupyterlab) (2021.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.9)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.10.0)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.1.0)\n",
      "Collecting tinycss2\n",
      "  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.8/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.10.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Collecting mistune<4,>=2.0.3\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 87.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from nbclient>=0.5.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.4)\n",
      "Collecting fastjsonschema\n",
      "  Downloading fastjsonschema-2.18.1-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->jupyterlab) (3.0.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.19.0->jupyterlab) (2.0.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.19.0->jupyterlab) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.19.0->jupyterlab) (2021.10.8)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.8/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab) (2.21)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.3)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyterlab) (0.1.3)\n",
      "Collecting jupyter-client>=7.4.4\n",
      "  Downloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 76.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyterlab) (7.30.0)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab) (59.4.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab) (3.0.22)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyterlab) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->jupyterlab) (0.2.5)\n",
      "Collecting arrow>=0.15.0\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "\u001b[K     |████████████████████████████████| 66 kB 99.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting types-python-dateutil>=2.8.10\n",
      "  Downloading types_python_dateutil-2.8.19.14-py3-none-any.whl (9.4 kB)\n",
      "Installing collected packages: rpds-py, attrs, referencing, types-python-dateutil, traitlets, platformdirs, pkgutil-resolve-name, jsonschema-specifications, tornado, pyzmq, jupyter-core, jsonschema, fastjsonschema, arrow, webcolors, uri-template, rfc3986-validator, rfc3339-validator, nbformat, jupyter-client, jsonpointer, isoduration, fqdn, tinycss2, sniffio, python-json-logger, mistune, importlib-metadata, exceptiongroup, websocket-client, send2trash, overrides, nbconvert, jupyter-server-terminals, jupyter-events, anyio, requests, jupyter-server, babel, notebook-shim, jupyterlab-server, jupyter-lsp, async-lru, jupyterlab\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 21.2.0\n",
      "    Uninstalling attrs-21.2.0:\n",
      "      Successfully uninstalled attrs-21.2.0\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.1.1\n",
      "    Uninstalling traitlets-5.1.1:\n",
      "      Successfully uninstalled traitlets-5.1.1\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 6.1\n",
      "    Uninstalling tornado-6.1:\n",
      "      Successfully uninstalled tornado-6.1\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 22.3.0\n",
      "    Uninstalling pyzmq-22.3.0:\n",
      "      Successfully uninstalled pyzmq-22.3.0\n",
      "  Attempting uninstall: jupyter-core\n",
      "    Found existing installation: jupyter-core 4.9.1\n",
      "    Uninstalling jupyter-core-4.9.1:\n",
      "      Successfully uninstalled jupyter-core-4.9.1\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.2.1\n",
      "    Uninstalling jsonschema-4.2.1:\n",
      "      Successfully uninstalled jsonschema-4.2.1\n",
      "  Attempting uninstall: nbformat\n",
      "    Found existing installation: nbformat 5.1.3\n",
      "    Uninstalling nbformat-5.1.3:\n",
      "      Successfully uninstalled nbformat-5.1.3\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter-client 7.1.0\n",
      "    Uninstalling jupyter-client-7.1.0:\n",
      "      Successfully uninstalled jupyter-client-7.1.0\n",
      "  Attempting uninstall: mistune\n",
      "    Found existing installation: mistune 0.8.4\n",
      "    Uninstalling mistune-0.8.4:\n",
      "      Successfully uninstalled mistune-0.8.4\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.8.2\n",
      "    Uninstalling importlib-metadata-4.8.2:\n",
      "      Successfully uninstalled importlib-metadata-4.8.2\n",
      "  Attempting uninstall: send2trash\n",
      "    Found existing installation: Send2Trash 1.8.0\n",
      "    Uninstalling Send2Trash-1.8.0:\n",
      "      Successfully uninstalled Send2Trash-1.8.0\n",
      "  Attempting uninstall: nbconvert\n",
      "    Found existing installation: nbconvert 6.3.0\n",
      "    Uninstalling nbconvert-6.3.0:\n",
      "      Successfully uninstalled nbconvert-6.3.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.26.0\n",
      "    Uninstalling requests-2.26.0:\n",
      "      Successfully uninstalled requests-2.26.0\n",
      "  Attempting uninstall: babel\n",
      "    Found existing installation: Babel 2.9.1\n",
      "    Uninstalling Babel-2.9.1:\n",
      "      Successfully uninstalled Babel-2.9.1\n",
      "  Attempting uninstall: jupyterlab-server\n",
      "    Found existing installation: jupyterlab-server 1.2.0\n",
      "    Uninstalling jupyterlab-server-1.2.0:\n",
      "      Successfully uninstalled jupyterlab-server-1.2.0\n",
      "  Attempting uninstall: jupyterlab\n",
      "    Found existing installation: jupyterlab 2.3.2\n",
      "    Uninstalling jupyterlab-2.3.2:\n",
      "      Successfully uninstalled jupyterlab-2.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.12.0a0 requires torch==1.11.0a0+b6df043, but you have torch 2.1.0 which is incompatible.\n",
      "markdown-it-py 1.1.0 requires attrs<22,>=19, but you have attrs 23.1.0 which is incompatible.\u001b[0m\n",
      "Successfully installed anyio-4.0.0 arrow-1.3.0 async-lru-2.0.4 attrs-23.1.0 babel-2.13.1 exceptiongroup-1.1.3 fastjsonschema-2.18.1 fqdn-1.5.1 importlib-metadata-6.8.0 isoduration-20.11.0 jsonpointer-2.4 jsonschema-4.19.2 jsonschema-specifications-2023.7.1 jupyter-client-7.4.9 jupyter-core-5.5.0 jupyter-events-0.9.0 jupyter-lsp-2.2.0 jupyter-server-2.10.0 jupyter-server-terminals-0.4.4 jupyterlab-4.0.8 jupyterlab-server-2.25.1 mistune-3.0.2 nbconvert-7.11.0 nbformat-5.9.2 notebook-shim-0.2.3 overrides-7.4.0 pkgutil-resolve-name-1.3.10 platformdirs-3.11.0 python-json-logger-2.0.7 pyzmq-25.1.1 referencing-0.30.2 requests-2.31.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.12.0 send2trash-1.8.2 sniffio-1.3.0 tinycss2-1.2.1 tornado-6.3.3 traitlets-5.13.0 types-python-dateutil-2.8.19.14 uri-template-1.3.0 webcolors-1.13 websocket-client-1.6.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from jupyter) (7.11.0)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\n",
      "\u001b[K     |████████████████████████████████| 139 kB 7.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipykernel in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.6.0)\n",
      "Collecting qtconsole\n",
      "  Downloading qtconsole-5.5.0-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 61.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-console\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.4.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.5.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (7.30.0)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (0.1.3)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (6.3.3)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (7.4.9)\n",
      "Requirement already satisfied: traitlets<6.0,>=5.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.13.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.18.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (2.10.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (3.0.22)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (59.4.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.3)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel->jupyter) (25.1.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.4 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel->jupyter) (1.5.4)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel->jupyter) (5.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel->jupyter) (0.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-core>=4.9.2->jupyter-client<8.0->ipykernel->jupyter) (3.11.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->jupyter) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.2->jupyter-client<8.0->ipykernel->jupyter) (1.16.0)\n",
      "Collecting jupyterlab-widgets~=3.0.9\n",
      "  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\n",
      "\u001b[K     |████████████████████████████████| 214 kB 127.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting widgetsnbextension~=4.0.9\n",
      "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 122.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting comm>=0.1.3\n",
      "  Downloading comm-0.2.0-py3-none-any.whl (7.0 kB)\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
      "  Downloading prompt_toolkit-3.0.39-py3-none-any.whl (385 kB)\n",
      "\u001b[K     |████████████████████████████████| 385 kB 116.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipykernel\n",
      "  Downloading ipykernel-6.26.0-py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 125.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.8.0)\n",
      "Collecting debugpy<2.0,>=1.0.0\n",
      "  Downloading debugpy-1.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 152.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=3.6 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (6.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (1.2.1)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (2.0.1)\n",
      "Requirement already satisfied: nbformat>=5.7 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (5.9.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.9)\n",
      "Requirement already satisfied: jinja2>=3.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (3.0.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (4.10.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=3.6->nbconvert->jupyter) (3.6.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.8/site-packages (from nbformat>=5.7->nbconvert->jupyter) (4.19.2)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.8/site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.18.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter) (1.3.10)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter) (0.12.0)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter) (0.30.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter) (23.1.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter) (5.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter) (2023.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.3)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (21.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.1)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (1.8.2)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->ipykernel->jupyter) (3.0.6)\n",
      "Collecting qtpy>=2.4.0\n",
      "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 84.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: prompt-toolkit, debugpy, comm, widgetsnbextension, qtpy, jupyterlab-widgets, ipykernel, qtconsole, jupyter-console, ipywidgets, jupyter\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt-toolkit 3.0.22\n",
      "    Uninstalling prompt-toolkit-3.0.22:\n",
      "      Successfully uninstalled prompt-toolkit-3.0.22\n",
      "  Attempting uninstall: debugpy\n",
      "    Found existing installation: debugpy 1.5.1\n",
      "    Uninstalling debugpy-1.5.1:\n",
      "      Successfully uninstalled debugpy-1.5.1\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 6.6.0\n",
      "    Uninstalling ipykernel-6.6.0:\n",
      "      Successfully uninstalled ipykernel-6.6.0\n",
      "Successfully installed comm-0.2.0 debugpy-1.8.0 ipykernel-6.26.0 ipywidgets-8.1.1 jupyter-1.0.0 jupyter-console-6.6.3 jupyterlab-widgets-3.0.9 prompt-toolkit-3.0.39 qtconsole-5.5.0 qtpy-2.4.1 widgetsnbextension-4.0.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.1.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.13.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.30.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (59.4.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade jupyterlab\n",
    "!pip install --upgrade jupyter\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb36c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/nnAudio/Spectrogram.py:4: Warning: importing Spectrogram subpackage will be deprecated soon. You should import the feature extractor from the feature subpackage. See actual documentation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "#sys.path.append(0, os.path.abspath('ComParE2022_VecNet/src'))\n",
    "sys.path.append('../../src')\n",
    "\n",
    "import config \n",
    "#from evaluate import get_results\n",
    "import numpy as np\n",
    "\n",
    "# Troubleshooting and visualisation\n",
    "# import IPython.display as ipd\n",
    "\n",
    "# humbug lib imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "#from PyTorch import config_pytorch\n",
    "from datetime import datetime\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "# additional pytorch tools\n",
    "import random\n",
    "import torchaudio\n",
    "import torchaudio.transforms as AT\n",
    "import torchvision.transforms as VT\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "import timm\n",
    "import timm.optim\n",
    "from timm.loss import BinaryCrossEntropy\n",
    "from timm.utils import NativeScaler\n",
    "from timm.models import model_parameters\n",
    "from glob import glob\n",
    "## nnAudio\n",
    "from nnAudio import features , Spectrogram\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import argparse\n",
    "import torchvision.models.quantization as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e261dc19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 85.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True, progress=True, quantize=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.train()\n",
    "model.fuse_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d39e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5da013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant_prep(model_ft):\n",
    "    model_ft[0].qconfig = torch.quantization.default_qat_qconfig  # Use default QAT configuration\n",
    "# Step 3\n",
    "    model_ft = torch.quantization.prepare_qat(model_ft, inplace=True)\n",
    "    for param in model_ft.parameters():\n",
    "        param.requires_grad = True\n",
    "    return(model_ft)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cdff1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def create_combined_model(model_fe):\n",
    "    # Step 1. Isolate the feature extractor.\n",
    "    model_fe_features = nn.Sequential(\n",
    "    model_fe.quant,  # Quantize the input\n",
    "    model_fe.conv1,\n",
    "    model_fe.bn1,\n",
    "    model_fe.relu,\n",
    "    model_fe.maxpool,\n",
    "    model_fe.layer1,\n",
    "    model_fe.layer2,\n",
    "    model_fe.layer3,\n",
    "    model_fe.layer4,\n",
    "    model_fe.avgpool,\n",
    "    model_fe.dequant,  # Dequantize the output\n",
    "  )\n",
    "\n",
    "    # Step 2. Create a new \"head\"\n",
    "    new_head = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(num_ftrs, 2),\n",
    "   )\n",
    "\n",
    "  # Step 3. Combine, and don't forget the quant stubs.\n",
    "    new_model = nn.Sequential(\n",
    "    model_fe_features,\n",
    "    nn.Flatten(1),\n",
    "    new_head,)\n",
    "    \n",
    "    model_ft  = quant_prep(new_model)\n",
    "    \n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "637aa601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ft = create_combined_model(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b2fd567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.rand(3,224,224)\n",
    "# y_t = model_ft(x)\n",
    "# print(y_t)\n",
    "# torch.argmax(y_t, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67e31b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offsets_df(df, short_audio=False):\n",
    "    audio_offsets = []\n",
    "    #This is same as defined in config -min_duration = win_size * frame_duration\n",
    "    min_length = config.win_size*config.NFFT/(((1/config.n_hop)*config.NFFT)*config.rate)\n",
    "    step_frac = config.step_size/config.win_size\n",
    "    stride = step_frac*min_length\n",
    "#     print(\"min_length = \" +str(min_length))\n",
    "#     print(\"step_frac = \" +str(step_frac))\n",
    "#     print(\"stride = \" +str(stride))\n",
    "    for _,row in df.iterrows():\n",
    "        #processed_data keeps track of the tensor_values processed thus far\n",
    "        if row['length'] > min_length:\n",
    "            processed_data = 0\n",
    "            #total_data is the total tensor present in the audio\n",
    "            total_data = config.rate*row['length']\n",
    "            label_ind = row['sound_type']\n",
    "            if label_ind == 'mosquito':\n",
    "                label_ind =1\n",
    "            else:\n",
    "                label_ind = 0\n",
    "            #print(\"********\")\n",
    "            count = 0\n",
    "            #print(\"count = \" +str(count))\n",
    "            #print(\"id = \" + str(row['id']) + \" duration = \" +str(row['length']) + \"total x vals = \" + str(total_data))\n",
    "            inner_loop_flag = False\n",
    "            #print(\"going into the inner loop to offset....\")\n",
    "            while(processed_data < total_data):\n",
    "                #print(\"inside inner loop.....\")\n",
    "                start = count*stride*config.rate\n",
    "                #now find out the row_len\n",
    "                if total_data - (start + min_length*config.rate) >= 0:\n",
    "                    #print(\"full chunk \")\n",
    "                    row_len = min_length\n",
    "                    end = start + row_len*config.rate\n",
    "                    audio_offsets.append({'id':row['id'], 'offset':count, 'length': row_len,'specie_ind': label_ind,'start':start,'end':end})\n",
    "                    #print(\"count = \" +str(count) + \"offset = \" +str(count) + \"start = \" +str(start) + \"end = \" +str(end))\n",
    "                    #print(\"for count.... = \" + str(count) + \"processed data = \" +str(processed_data))\n",
    "                    count+=1\n",
    "                    processed_data = (count*stride)*config.rate\n",
    "                    \n",
    "                else:\n",
    "                    inner_loop_flag = True\n",
    "                    break\n",
    "                    \n",
    "                                                       \n",
    "            #for processing residual data\n",
    "            if(inner_loop_flag):\n",
    "                #print(\"processing residual ....processed \" +str(processed_data) + \" of \" + str(total_data))\n",
    "                start = count*stride*config.rate\n",
    "                resid_durn = round((total_data - processed_data)/config.rate,2)\n",
    "                end = total_data\n",
    "                #print(\"for...\" + str(row['id']) + \" adding the residual data in the data frame with duration = \" + str(resid_durn))\n",
    "                audio_offsets.append({'id':row['id'], 'offset':count, 'length':resid_durn ,'specie_ind': label_ind,'start':start,'end':end})\n",
    "            \n",
    "        elif short_audio:\n",
    "            label_ind = row['sound_type']\n",
    "            if label_ind == 'mosquito':\n",
    "                label_ind =1\n",
    "            else:\n",
    "                label_ind = 0\n",
    "            start = 0\n",
    "            end = row['length']*config.rate\n",
    "            audio_offsets.append({'id':row['id'], 'offset':0,'length': row['length'],'specie_ind': label_ind,'start':0 , 'end':end})\n",
    "    return pd.DataFrame(audio_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "755b675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(csv_loc = config.data_df  ):\n",
    "    \"\"\"This function reads a csv and creates a dataframe for further processing.\"\"\"\n",
    "    df = pd.read_csv(csv_loc)\n",
    "    idx_test_A = np.logical_and(df['country'] == 'Tanzania', df['location_type'] == 'field')\n",
    "    idx_test_B = np.logical_and(df['country'] == 'UK', df['location_type'] == 'culture')\n",
    "    idx_train = np.logical_not(np.logical_or(idx_test_A, idx_test_B))\n",
    "    #df_test_A = df[idx_test_A]\n",
    "    #df_test_B = df[idx_test_B]\n",
    "    #df = df.loc[df['Grade'].notnull()]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "005996d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(df):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    import seaborn as sns\n",
    "    sns.countplot(x = 'species', data = df , ax = ax , hue = 'gender',palette='dark')\n",
    "    #ax.bar_label(ax.containers[0])\n",
    "    #ax.bar_label(ax.containers[-1], fmt='Count:\\n%.2f', label_type='center')\n",
    "    plt.xticks(rotation=90 )\n",
    "    plt.title(\"Distribution of Species \")\n",
    "    plt.rc('xtick', labelsize=12)\n",
    "    plt.rc('xtick', labelsize=12)\n",
    "    plt.rc('axes', labelsize=15)\n",
    "    plt.rc('figure', titlesize=15)\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6270dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df_all):\n",
    "    np.random.seed(42)\n",
    "    msk_test = np.random.rand(len(df_all)) < 0.2\n",
    "    df_test = df_all[msk_test]\n",
    "    df_train_temp  = df_all[~msk_test]\n",
    "    msk_train = np.random.rand(len(df_train_temp)) < 0.2\n",
    "    df_val = df_train_temp[msk_train]\n",
    "    df_train  = df_train_temp[~msk_train]\n",
    "    return df_train ,df_val ,df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15855647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_split(df1 , df2):\n",
    "    df_temp = pd.merge(df1,df2, on = 'id', how = 'inner')\n",
    "    #print(df_temp)\n",
    "    common_elem = len(df_temp)\n",
    "    #print(\"common_elem = \",common_elem)\n",
    "    con = (common_elem == 0)\n",
    "    #print(\"condition = \",con)\n",
    "    assert (con), \"Split has issues\"\n",
    "    print(\"split is a success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d31a0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specie_distri(df , classes , type_df = None):\n",
    "    \"\"\"This function takes a dataframe and provides a count of each specie class\"\"\"\n",
    "    for i in range(len(classes)):\n",
    "        print(\"DF type = \" + str(type_df))\n",
    "        df_temp = df[df['specie_ind'] == i]\n",
    "        print(\"i = \" +str(i))\n",
    "        print(len(df_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3900125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(df):\n",
    "    np.array(df_train_offset.specie_ind)\n",
    "    from sklearn.utils import class_weight\n",
    "    class_weights = class_weight.compute_class_weight('balanced',classes=np.unique(np.array(df.specie_ind)),y=np.array(np.array(df.specie_ind)))\n",
    "    print(type(class_weights))\n",
    "    print(class_weights.shape)\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cb9ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_mean(x_temp,rate = config.rate, min_length = config.min_duration ):\n",
    "    if DEBUG:\n",
    "        print(\"inside padding mean...\")\n",
    "    x_mean = torch.mean(x_temp)\n",
    "    #x_mean.cuda()\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"X_mean = \" + str(x_mean))\n",
    "    left_pad_amt = int((rate*min_length-x_temp.shape[1])//2)\n",
    "    if DEBUG:\n",
    "        print(\"left_pad_amt = \" + str(left_pad_amt))\n",
    "    left_pad = torch.zeros(1,left_pad_amt) #+ (0.1**0.5)*torch.randn(1, left_pad_amt)\n",
    "    if DEBUG:\n",
    "        print(\"left_pad shape = \" + str(left_pad.shape))\n",
    "    left_pad_mean_add = left_pad + x_mean\n",
    "    if DEBUG:\n",
    "        print(\"left_pad_mean shape = \" + str(left_pad_mean_add))\n",
    "        print(\"sum of left pad mean add = \" + str(torch.sum(left_pad_mean_add)))\n",
    "    \n",
    "    right_pad_amt = int(rate*min_length-x_temp.shape[1]-left_pad_amt)\n",
    "    right_pad = torch.zeros(1,right_pad_amt)# + (0.1**0.5)*torch.randn(1, right_pad_amt)\n",
    "    if DEBUG:\n",
    "        print(\"right_pad shape = \" + str(right_pad.shape))\n",
    "    right_pad_mean_add = right_pad + x_mean\n",
    "    if DEBUG:\n",
    "        print(\"right_pad_mean shape = \" + str(right_pad_mean_add))\n",
    "        print(\"sum of right pad mean add = \"  + str(torch.sum(right_pad_mean_add)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    f = torch.cat([left_pad,x_temp,right_pad],dim=1)[0]\n",
    "    f = f.unsqueeze(dim = 0)\n",
    "    #print(\"returning a tensor of shape = \" + str(f.shape))\n",
    "    return(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7cf30f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_hat,y_true,classes):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_hat, y_true ,labels= range(len(classes)))\n",
    "    import seaborn as sns\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, fmt = 'g'); #annot=True to annotate cellsplt.xticks(rotation=90)\n",
    "    ax.xaxis.set_ticklabels(classes, fontsize = 10)\n",
    "    ax.xaxis.tick_bottom()\n",
    "    plt.xticks(rotation=90)\n",
    "    ax.set_ylabel('True', fontsize=20)\n",
    "    ax.yaxis.set_ticklabels(classes, fontsize = 10)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97a91570",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize_batch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Normalize_batch, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_mean = torch.mean(x, dim=0, keepdim=True)\n",
    "        batch_std = torch.std(x, dim=0, keepdim=True)\n",
    "        epsilon = 1e-8\n",
    "        batch_std = torch.sqrt(batch_std ** 2 + epsilon)\n",
    "        batch_normalized = (x - batch_mean) / batch_std\n",
    "        return batch_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ee41a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyModel(nn.Module):\n",
    "#     def __init__(self,model = model,image_size = 224):\n",
    "#         super().__init__()\n",
    "#         # num_classes=0 removes the pretrained head\n",
    "#         self.backbone = create_combined_model(model)\n",
    "#         #####  This section is model specific\n",
    "#         #### It freezes some fo the layers by name\n",
    "#         #### you'll have to inspect the model to see the names\n",
    "#                 #### end layer freezing\n",
    "#         #self.out = nn.Linear(self.backbone.num_features, 1)\n",
    "#         self.sizer = VT.Resize((image_size,image_size),antialias = True)\n",
    "#         self.spec_layer = features.STFT(n_fft=int(config.NFFT), freq_bins=None, hop_length=int(config.n_hop),\n",
    "#                               window='hann', freq_scale='linear', center=True, pad_mode='reflect',\n",
    "#                            sr=config.rate, output_format=\"Magnitude\", trainable=True,verbose = False).to('cuda')\n",
    "#         self.batch_norm = nn.BatchNorm2d(num_features= 1)\n",
    "#         #self.augment_layer = augment_audio(trainable = True, sample_rate = config.rate)\n",
    "#         self.quant = torch.ao.quantization.QuantStub()\n",
    "#         self.dequant = torch.ao.quantization.DeQuantStub()\n",
    "        \n",
    "        \n",
    "#     def forward(self, x,train = True):\n",
    "#         # first compute spectrogram\n",
    "#         #x = self.quant(x)\n",
    "#         spec_gram = self.spec_layer(x)\n",
    "#         #print(\"post spec gram shape = \",spec_gram.shape)\n",
    "#         spec_gram = self.batch_norm(spec_gram.unsqueeze(dim = 1))\n",
    "#         #print(\"post norm shape = \",spec_gram.shape)\n",
    "#         spec_gram_nan_check = torch.isnan(spec_gram).any().item()\n",
    "#         assert not (spec_gram_nan_check) ,\"Tensor contains NaN values after spec gram creation.\"\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             if train == True:\n",
    "#                 #generate a random number and if condition is met apply aug\n",
    "#                 ta_transformations_rndm_choice = VT.RandomChoice([AT.FrequencyMasking(freq_mask_param=100),AT.TimeMasking(time_mask_param=50)], p=[.4, .4])\n",
    "#                 ta_transformations_rndm_apply = VT.RandomApply([AT.FrequencyMasking(freq_mask_param=50),AT.TimeMasking(time_mask_param=25)],p = .15)\n",
    "#                 spec_gram = ta_transformations_rndm_choice(spec_gram)\n",
    "#                 spec_gram = ta_transformations_rndm_apply(spec_gram)\n",
    "#                 spec_gram_nan_check = torch.isnan(spec_gram).any().item()\n",
    "#                 assert not (spec_gram_nan_check) ,\"Tensor contains NaN values after augmentations  \"\n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "#         x = self.sizer(spec_gram.squeeze(dim = 1))\n",
    "#         #print(\"post sizer shape = \",x.shape)\n",
    "#         x = x.unsqueeze(dim = 1)\n",
    "#         #print(\"post unsqueeze shape = \",x.shape)\n",
    "        \n",
    "#         # then repeat channels\n",
    "#         del spec_gram,spec_gram_nan_check\n",
    "#         if DEBUG:\n",
    "#             print(\"Final shape that goes to backbone = \" + str(x.shape))\n",
    "                \n",
    "#         x = x.expand(-1, 3, -1, -1)\n",
    "#         #print(\"post expansion x device = \",x.device)\n",
    "#         x = self.backbone(x)\n",
    "#         backbone_op_nan_check = torch.isnan(x).any().item()\n",
    "#         assert not (backbone_op_nan_check) ,\"Tensor contains NaN values in the backbone OP \"\n",
    "#         #print(\"x shape after backbone  = \" + str(x.shape))\n",
    "#         #print(\"output of model = \" +str(x))\n",
    "#         #pred = nn.Softmax(x)\n",
    "#         #x = self.dequant(x)\n",
    "#         pred = x\n",
    "#         #print(np.argmax(pred.detach().cpu().numpy()))\n",
    "#         #print(pred)\n",
    "#         output = {\"prediction\": pred }\n",
    "#         #print(output)\n",
    "#         del x , backbone_op_nan_check\n",
    "#         return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "227faedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specgram_apply_aug(x , train = True , image_size = 224):\n",
    "    \n",
    "    sizer = VT.Resize((image_size,image_size),antialias = True)\n",
    "    spec_layer = features.STFT(n_fft=int(config.NFFT), freq_bins=None, hop_length=int(config.n_hop),\n",
    "                              window='hann', freq_scale='linear', center=True, pad_mode='reflect',\n",
    "                           sr=config.rate, output_format=\"Magnitude\", trainable=False,verbose = False).to('cuda')\n",
    "    batch_norm = nn.BatchNorm2d(num_features= 1).to('cuda')\n",
    "    x.to('cuda')\n",
    "    #print(\"x device before spec gram = \" , x.device)\n",
    "    spec_gram = spec_layer(x)\n",
    "    #print(\"post spec gram generation device  = \" , spec_gram.device)\n",
    "    spec_gram.to('cuda')\n",
    "    spec_gram = spec_gram.unsqueeze(dim = 1).to('cuda')\n",
    "    #print(\"post unsqueeze device  = \" , spec_gram.device)\n",
    "    spec_gram = batch_norm(spec_gram)\n",
    "    #print(\"post norm device  = \" , spec_gram.device)\n",
    "    \n",
    "    if train == True:\n",
    "        #generate a random number and if condition is met apply aug\n",
    "        ta_transformations_rndm_choice = VT.RandomChoice([AT.FrequencyMasking(freq_mask_param=100),AT.TimeMasking(time_mask_param=50)], p=[.4, .4])\n",
    "        ta_transformations_rndm_apply = VT.RandomApply([AT.FrequencyMasking(freq_mask_param=50),AT.TimeMasking(time_mask_param=25)],p = .15)\n",
    "        spec_gram = ta_transformations_rndm_choice(spec_gram)\n",
    "        spec_gram = ta_transformations_rndm_apply(spec_gram)\n",
    "        spec_gram_nan_check = torch.isnan(spec_gram).any().item()\n",
    "        assert not (spec_gram_nan_check) ,\"Tensor contains NaN values after augmentations  \"\n",
    "    \n",
    "    spec_gram = sizer(spec_gram.squeeze(dim = 1))\n",
    "    #converting to 3 channels as required by resnet.\n",
    "    spec_gram = spec_gram.unsqueeze(dim = 1)\n",
    "    spec_gram = spec_gram.expand(-1, 3, -1, -1)\n",
    "    #print(\"shape of spec gram being returned = \", spec_gram.shape)\n",
    "    \n",
    "    return spec_gram\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54e1c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.rand(64,15360, device = 'cuda')\n",
    "# t = get_specgram_apply_aug(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd045082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loader, criterion,  device=None , call = \"val\"):\n",
    "    softmax = nn.Softmax()\n",
    "    if DEBUG:\n",
    "        print(\"calling for ...\" +str(call))\n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        sigmoid = nn.Sigmoid()\n",
    "        test_loss = 0.0\n",
    "        model.eval()\n",
    "        if DEBUG:\n",
    "            print(\"inside test....\")\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        counter = 1\n",
    "        if DEBUG:\n",
    "            print(\"length of loader = \" + str(len(loader)))\n",
    "        for idx,(x,y) in enumerate(loader):\n",
    "            if DEBUG:\n",
    "                print(\"loader index = \" + str(idx))\n",
    "                            \n",
    "            x = x.to(device).float() \n",
    "            y = y.type(torch.LongTensor).to(device)\n",
    "            if DEBUG:\n",
    "                print(\"y = \" + str(y))\n",
    "            spec = get_specgram_apply_aug(x, train = False)\n",
    "            y_pred = model(spec)\n",
    "            #y_pred_smax = softmax(y_pred)\n",
    "            preds = torch.argmax(y_pred, axis = 1)\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            if DEBUG:\n",
    "                print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "            #preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "            if DEBUG:\n",
    "                print(\"preds = \" +str(preds))\n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "                                   \n",
    "            loss = criterion(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            all_y.append(y.cpu().detach())\n",
    "            #all_y_pred.append(np.argmax(y_pred.cpu().detach().numpy()))\n",
    "            \n",
    "            del x\n",
    "            del y\n",
    "            del y_pred\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        if DEBUG:\n",
    "            print(\"inside test....\")\n",
    "            print(\"y = \" + str(all_y))\n",
    "            print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "        test_loss = test_loss/len(test_loader)\n",
    "        test_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "    \n",
    "    \n",
    "    return test_loss, test_f1 , all_y,all_y_pred\n",
    "## Train_model ####\n",
    "#train_loader, val_loader, test_loader,model,classes,df_train_offset ,num_epochs = num_epochs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3ffb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, val_loader,test_loader, model ,class_weights,num_epochs ):\n",
    "    # Creates a GradScaler once at the beginning of training.\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Training on {device}')    \n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using data parallel\")\n",
    "        model = nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "\n",
    "    model = model.to(device)\n",
    "    weights_adj = torch.tensor(class_weights).type(torch.float).to(device)\n",
    "    criterion = BinaryCrossEntropy(weight=weights_adj)\n",
    "    lr = .000015\n",
    "    base_optimiser = timm.optim.AdamP(model.parameters(), lr= lr)\n",
    "    look_optimiser = timm.optim.Lookahead(base_optimiser)\n",
    "    cooldown_epoch = 50\n",
    "    \n",
    "    #optimiser = timm.optim.AdamW(model.parameters(), lr=config_pytorch.lr)\n",
    "    #timm.optim.Lookahead(optimiser, alpha=0.5, k=6)\n",
    "    scheduler = timm.scheduler.CosineLRScheduler(base_optimiser, t_initial= num_epochs,lr_min= lr/100,warmup_t = 5,warmup_lr_init= lr/10,noise_std=.075)\n",
    "    \n",
    "    \n",
    "    #optimiser = timm.optim.RAdam(model.parameters(), lr=config_pytorch.lr/10)\n",
    "    num_epochs = num_epochs\n",
    "    all_train_loss = []\n",
    "    all_train_f1 = []\n",
    "    all_val_loss = []\n",
    "    all_val_f1 = []\n",
    "    best_val_loss = np.inf\n",
    "    best_val_f1 = -np.inf\n",
    "    best_train_f1 = -np.inf\n",
    "    best_epoch = -1\n",
    "    checkpoint_name = None\n",
    "    overrun_counter = 0\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    softmax = nn.Softmax()\n",
    "    all_train_f1 = []\n",
    "    all_val_f1 = []\n",
    "    accumulation_steps = 4\n",
    "    lr_log = []\n",
    "    for e in range(num_epochs + cooldown_epoch):\n",
    "        start_time = time.time()\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        #tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "        for batch_i, inputs in enumerate(train_loader):\n",
    "            if DEBUG:\n",
    "                print(\"inside train loop.. batch_ind = \" +str(batch_i))\n",
    "            if batch_i % 20 == 0:\n",
    "                bat_time = time.time()\n",
    "                durn = (bat_time - start_time)/60\n",
    "                print(\"epoch = \" +str(e) + \"batch = \" +str(batch_i) + \" of \" + str(len(train_loader)) + \"duraation = \" + str(durn))\n",
    "            x = inputs[0].to(device).float()\n",
    "            #create a transformation here\n",
    "            # create a spectrogram and call for the randomization\n",
    "            spec = get_specgram_apply_aug(x, train = True)\n",
    "            if DEBUG:\n",
    "                print(\"inside train loop.. x device = \" +str(x.device))\n",
    "                \n",
    "            \n",
    "            y = inputs[1].type(torch.LongTensor).to(device)\n",
    "                                             \n",
    "            with autocast():\n",
    "                spec.to(device)\n",
    "                y_pred = model(spec)\n",
    "                #y_pred_smax = softmax(y_pred)\n",
    "                preds = torch.argmax(y_pred, axis = 1)\n",
    "                loss = criterion(y_pred, y)\n",
    "                            \n",
    "            if DEBUG:\n",
    "                    print(\"y_pred  = \" +str(y_pred))\n",
    "                    print(\"preds = \" +str(preds))\n",
    "                   \n",
    "            train_loss += loss.item()\n",
    "            all_y.append(y.cpu().detach())\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            #preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "            if DEBUG:\n",
    "                print(\"batch_ind = \" +str(batch_i))\n",
    "                print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "                \n",
    "            loss.backward()\n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "            base_optimiser.step()\n",
    "            base_optimiser.zero_grad()\n",
    "            #scheduler.step(e)\n",
    "                \n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),error_if_nonfinite=False ,max_norm = 1.0 )\n",
    "            base_optimiser.step()\n",
    "            del x\n",
    "            del y\n",
    "            del y_pred,preds\n",
    "        \n",
    "        #lr_log.append(lr)\n",
    "        look_optimiser.sync_lookahead()\n",
    "        all_train_loss.append(train_loss/len(train_loader))\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        if DEBUG:\n",
    "            print(\"y = \" + str(all_y))\n",
    "            print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "        train_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "        all_train_f1.append(train_f1)\n",
    "        if DEBUG:\n",
    "            print(\"train acc = \" +str(train_acc))\n",
    "        all_train_f1.append(train_f1)\n",
    "        val_loss, val_f1 , _,_ = test_model(model, val_loader, criterion = criterion, device=device, call = \"val\")\n",
    "        all_val_f1.append(val_f1)\n",
    "        all_val_loss.append(val_loss)\n",
    "        if DEBUG:\n",
    "            print(\"val F1 = \" + str(val_f1))\n",
    "        all_val_loss.append(val_loss)\n",
    "        all_val_f1.append(val_f1)\n",
    "        \n",
    "        acc_metric = val_f1\n",
    "        best_acc_metric = best_val_f1\n",
    "        if acc_metric > best_acc_metric:  \n",
    "            overrun_counter = -1\n",
    "            checkpoint_name = f'model_med{e}_{datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")}.pth'\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_dir,  checkpoint_name))\n",
    "            sys.stdout.flush()\n",
    "            print('Epoch: %d, Train Loss: %.8f, Train f1: %.8f, Val Loss: %.8f, Val f1: %.8f, overrun_counter %i' % (e, train_loss/len(train_loader), train_f1, val_loss/len(val_loader), val_f1,  overrun_counter))\n",
    "            print('Saving model to:', os.path.join(config.model_dir,  checkpoint_name)) \n",
    "            print(\"Now printing classification rport... \")\n",
    "            print(\"********************************\")\n",
    "            current_lr = base_optimiser.param_groups[0]['lr']\n",
    "            print(\"Current LR = \" + '{0:.8f}'.format(current_lr))\n",
    "            from sklearn.metrics import classification_report\n",
    "            _, _ , all_y_test,all_y_pred_test = test_model(model, val_loader, criterion = criterion, device=device, call = \"test\")\n",
    "            # at times output is not getting printed. Could be due to multi threading and hence adding sleep\n",
    "            time.sleep(2)\n",
    "            sys.stdout.flush()\n",
    "            print(classification_report(all_y_test.numpy(), all_y_pred_test.numpy(), target_names= [\"0\",\"1\"]))\n",
    "            print(\"********************************\")\n",
    "            time.sleep(2)\n",
    "            plot_confusion_matrix(all_y_pred_test.numpy(), all_y_test.numpy() , [\"0\",\"1\"])\n",
    "            best_epoch = e\n",
    "            best_val_f1 = val_f1\n",
    "            best_val_loss = val_loss\n",
    "            \n",
    "        else:\n",
    "            print(\"..Overrun....no improvement\")\n",
    "            overrun_counter += 1\n",
    "            sys.stdout.flush()\n",
    "            print('Epoch: %d, Train Loss: %.8f, Train f1: %.8f, Val Loss: %.8f, Val f1: %.8f, overrun_counter %i' % (e, train_loss/len(train_loader), train_f1, val_loss/len(val_loader), val_f1,  overrun_counter))\n",
    "        scheduler.step(e+1)\n",
    "        if overrun_counter > 20:\n",
    "            break\n",
    "            \n",
    "    \n",
    "    return model, lr_log,all_train_f1,all_train_loss,all_val_loss,all_val_f1\n",
    "\n",
    "\n",
    "\n",
    "#### Dataste class #####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73ae132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fcfc47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MozDataset(Dataset):\n",
    "\n",
    "    def __init__(self, audio_df, data_dir, min_length, cache=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            audio_df (DataFrame): from get_offsets_df function \n",
    "            noise_df (DataFrame): the df of noise files and lengths\n",
    "            data_dir (string): Directory with all the wavs.\n",
    "            cache (dict): Empty dictionary used as cache\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.audio_df = audio_df\n",
    "        #self.noise_df = noise_df\n",
    "        self.data_dir = data_dir\n",
    "        self.min_length = min_length\n",
    "        self.transform = transform\n",
    "        self.cache = cache\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #real_idx = idx % len(self.audio_df)\n",
    "        temp_id = int(self.audio_df.loc[idx]['id'])\n",
    "        file_path = os.path.join(\"..\",\"data\",\"audio\")\n",
    "        path_var = file_path +\"/\" +str(temp_id)+ str(\".wav\")\n",
    "        entire_aud, inp_rate = torchaudio.load(path_var)\n",
    "        #print(\"processsing file on \" +str(path_var))\n",
    "        if inp_rate != config.rate:\n",
    "            #print(\" Original sample rate = \" +str(inp_rate)+ \" resampling ...\")\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(inp_rate, config.rate, dtype=entire_aud.dtype)\n",
    "            entire_aud = resampler(entire_aud)\n",
    "            #print(\"processsing file on \" +str(path_var) + \"Post resample shape =  \" + str(entire_aud.shape))\n",
    "        \n",
    "        aud_len = self.audio_df.loc[idx]['length']\n",
    "        offset = int(self.audio_df.loc[idx]['offset'])\n",
    "        #print(\"sliced val = \" +str(int((offset+config.min_duration)*config.rate)))\n",
    "        start_pos = int(round(self.audio_df.loc[idx]['start']))\n",
    "        #print(\"start_pos = \" +str(start_pos))\n",
    "        end_pos =  int(round(self.audio_df.loc[idx]['end']))\n",
    "        #print(\"end_pos = \" +str(end_pos))\n",
    "        x = entire_aud[:,start_pos:end_pos]\n",
    "        #print(\"extracted x = \" +str(x))\n",
    "        #print(\"x shape = \" +str(x.shape))\n",
    "        if (aud_len < config.min_duration) or (x.shape[1] < 15360):\n",
    "            #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "            #print(\"padding on \" +str(path_var))\n",
    "            f_out = pad_mean(x)\n",
    "            #print(\"returning from padding  SHape = \" +str(f_out.shape))\n",
    "        else:\n",
    "            f_out = x[0]\n",
    "            f_out = f_out.unsqueeze(0)\n",
    "            #print(\"inside else, returned  SHape = \" +str(f_out.shape))\n",
    "            \n",
    "        if DEBUG:\n",
    "            print(\"idx = \" + str(idx))\n",
    "            #print(\"offset = \" + str(offset))\n",
    "            #print(\"shape of x post augmentation = \" + str(x.shape))\n",
    "            print(\"from get_item of train, returning  x of shape = \" +str(f_out.shape))\n",
    "        \n",
    "        #x_val = x[:,start:end]\n",
    "        #now that we have final x- let's create specgram and add augmentations.\n",
    "                 \n",
    "        return (f_out,self.audio_df.loc[idx]['specie_ind'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1e3af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_indices(num_values ,df ,classes = classes):\n",
    "#     new_df = pd.DataFrame()\n",
    "#     for ind in range(len(classes)):\n",
    "#         #print(\"ind = \", ind)\n",
    "#         op = df[df['specie_ind'] == ind]\n",
    "#         #print(\"len op = \", len(op))\n",
    "#         op_new = op.sample(n = 1)\n",
    "#         #print(\"rand_ind = \" , rand_ind)\n",
    "#         #([df1, df2], axis=1)\n",
    "#         new_df = pd.concat([op_new,new_df],axis = 0)\n",
    "#         #print(\"elem = \" , elem)\n",
    "#         #new_list.append(elem)\n",
    "#     if len(new_df) < num_values:\n",
    "#         diff =  num_values - len(new_df)\n",
    "#         #print(\"diff = \", diff)\n",
    "#         remaining_elems= df.sample(n = diff)\n",
    "#         #print(\"len of remaining elems = \", len(remaining_elems))\n",
    "#         new_df = pd.concat([remaining_elems,new_df],axis = 0)\n",
    "        \n",
    "#     #print(\"new_df = \", new_df)    \n",
    "#     new_df_1 = new_df.reset_index(drop = True)\n",
    "#     return new_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f3d426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_model(filepath, model=MyModel('convnext_xlarge_in22k')):\n",
    "#     # Instantiate model to inspect\n",
    "#     print(\"Filepath = \" + str(filepath))\n",
    "#     print(\"model = \" +str(model))\n",
    "#     device = torch.device('cuda:0' if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "#     print(f'Training on {device}')\n",
    "        \n",
    "#     if torch.cuda.device_count() > 1:\n",
    "#         print(\"Using data parallel\")\n",
    "#         model = nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "#     model = model.to(device)\n",
    "#     # Load trained parameters from checkpoint (may need to download from S3 first)\n",
    "\n",
    "\n",
    "#     if torch.cuda.is_available():\n",
    "#         map_location=lambda storage, loc: storage.cuda()\n",
    "#     else:\n",
    "#         map_location='cpu'\n",
    "        \n",
    "#     checkpoint = model.load_state_dict(torch.load(filepath))\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "267435eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2048\n",
    "pin_memory = True\n",
    "num_workers = 8\n",
    "num_epochs = 200\n",
    "short_audio=True\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96a5e24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside main.....\n",
      "The current working directory is  /dli/task/notebooks\n",
      "now validating the split post loading and keeping TZ data\n",
      "split is a success\n",
      "split is a success\n",
      "split is a success\n",
      "now validating the split post offset_creation\n",
      "split is a success\n",
      "split is a success\n",
      "split is a success\n"
     ]
    }
   ],
   "source": [
    "print(\"inside main.....\")\n",
    "print(\"The current working directory is \", os.getcwd())\n",
    "csv_loc = os.path.join(\"..\",\"data\",\"metadata\",\"neurips_2021_zenodo_0_0_1.csv\")\n",
    "df = prepare_df(csv_loc = csv_loc)\n",
    "#plot_df(df)\n",
    "df_train ,df_val ,df_test = train_test_split(df)\n",
    "print(\"now validating the split post loading and keeping TZ data\")\n",
    "validate_split(df_train ,df_val)\n",
    "validate_split(df_train ,df_test)\n",
    "validate_split(df_test ,df_val)\n",
    "df_train_offset = get_offsets_df(df_train, short_audio=True)\n",
    "df_test_offset = get_offsets_df(df_test, short_audio=True)\n",
    "df_val_offset = get_offsets_df(df_val, short_audio=True)\n",
    "df_train_offset.reset_index(inplace = True , drop = True)\n",
    "df_test_offset.reset_index(inplace = True , drop = True)\n",
    "df_val_offset.reset_index(inplace = True , drop = True)\n",
    "print(\"now validating the split post offset_creation\")\n",
    "validate_split(df_train_offset ,df_val_offset)\n",
    "validate_split(df_train_offset ,df_test_offset)\n",
    "validate_split(df_test_offset ,df_val_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283853a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4fa44dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(2,)\n",
      "inside main. class_weigths type =  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "class_weights = get_class_weights(df_train_offset)\n",
    "print(\"inside main. class_weigths type = \", type(class_weights))\n",
    "model = create_combined_model(model)\n",
    "min_length = (config.win_size * config.n_hop) / config.rate\n",
    "\n",
    "train_dataset = MozDataset(df_train_offset,  config.data_dir, min_length)\n",
    "val_dataset = MozDataset(df_val_offset,  config.data_dir, min_length)\n",
    "test_dataset = MozDataset(df_test_offset,  config.data_dir, min_length)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, num_workers=num_workers,batch_size = batch_size,shuffle = True, pin_memory=True )\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,num_workers=num_workers, pin_memory=pin_memory, shuffle = True )\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,num_workers= num_workers, pin_memory=pin_memory,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc88927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cce187e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n",
      "epoch = 0batch = 0 of 55duraation = 0.9035072684288025\n",
      "epoch = 0batch = 20 of 55duraation = 2.9172995686531067\n",
      "epoch = 0batch = 40 of 55duraation = 5.495684051513672\n",
      "Epoch: 0, Train Loss: 0.76672256, Train f1: 0.50272389, Val Loss: 0.04029807, Val f1: 0.52637483, overrun_counter -1\n",
      "Saving model to: /dli/task/models/model_med0_2023_11_08_22_44_10.pth\n",
      "Now printing classification rport... \n",
      "********************************\n",
      "Current LR = 0.00000150\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.14      0.24     13006\n",
      "           1       0.56      0.99      0.72     14596\n",
      "\n",
      "    accuracy                           0.59     27602\n",
      "   macro avg       0.73      0.56      0.48     27602\n",
      "weighted avg       0.72      0.59      0.49     27602\n",
      "\n",
      "********************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_393/1557173779.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train_loader, val_loader,test_loader, model ,class_weights, classes = classes, num_epochs = args.num_epochs ,n_channels = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#train_loader, val_loader,test_loader, model, classes ,df,num_epochs = args.num_epochs ,n_channels = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_log\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_train_f1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_train_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_val_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_val_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weights\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ALL DONE!!!!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_393/881895835.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, val_loader, test_loader, model, class_weights, num_epochs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mall_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m#tk0 = tqdm(train_loader, total=int(len(train_loader)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inside train loop.. batch_ind = \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#train_loader, val_loader,test_loader, model ,class_weights, classes = classes, num_epochs = args.num_epochs ,n_channels = 1\n",
    "#train_loader, val_loader,test_loader, model, classes ,df,num_epochs = args.num_epochs ,n_channels = 1\n",
    "tr_model, lr_log,all_train_f1,all_train_loss,all_val_loss,all_val_f1 = train_model(train_loader, val_loader, test_loader,model,class_weights ,num_epochs = num_epochs )\n",
    "\n",
    "print(\"ALL DONE!!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551e9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
