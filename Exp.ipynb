{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f83cad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('ComParE2022_VecNet/src'))\n",
    "#import config,config_pytorch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score ,confusion_matrix, classification_report\n",
    "\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import random\n",
    "import torchaudio\n",
    "import torchaudio.transforms as AT\n",
    "import torchvision.transforms as VT\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "#from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "import timm\n",
    "import timm.optim\n",
    "from timm.models import model_parameters\n",
    "from glob import glob\n",
    "## nnAudio\n",
    "from nnAudio import features\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import argparse\n",
    "## DDp Import\n",
    "import torch.distributed as dist\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import argparse\n",
    "import deepspeed\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "import torch.profiler\n",
    "from contextlib import ExitStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92971804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_size =8, hidden_size =8, output_size=8):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Gate(nn.Module):\n",
    "    def __init__(self, input_size=8, num_experts = 8):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.softmax(x, dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca9a6528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model_name, image_size,input_size =8, hidden_size=8, num_classes=8,num_experts =8):\n",
    "        super().__init__()\n",
    "        # num_classes=0 removes the pretrained head\n",
    "        self.backbone = timm.create_model(model_name,\n",
    "                        pretrained=True, num_classes=8, in_chans=1, \n",
    "                        drop_path_rate=0.2, global_pool='max',\n",
    "                        drop_rate=0.25)\n",
    "        #####  This section is model specific\n",
    "        #### It freezes some fo the layers by name\n",
    "        #### you'll have to inspect the model to see the names\n",
    "                #### end layer freezing\n",
    "        self.out = nn.Linear(self.backbone.num_features, 1)\n",
    "        self.sizer = VT.Resize((image_size,image_size),antialias = True)\n",
    "        self.spec_layer = features.STFT(n_fft=int(2048), freq_bins=None, hop_length=int(128),\n",
    "                              window='hann', freq_scale='linear', center=True, pad_mode='reflect',\n",
    "                           sr=8000, output_format=\"Magnitude\", trainable=False,verbose = False)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features= 1)\n",
    "        self.experts = nn.ModuleList([Expert(input_size, hidden_size, num_classes) for _ in range(num_experts)])\n",
    "        self.gate = Gate(input_size, num_experts)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x,train = True):\n",
    "        # first compute spectrogram\n",
    "        warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"nnAudio\")\n",
    "        spec_gram = self.spec_layer(x)\n",
    "        print(\"post spec gram shape = \",spec_gram.shape)\n",
    "        spec_gram = self.batch_norm(spec_gram.unsqueeze(dim = 1))\n",
    "        print(\"post norm shape = \",spec_gram.shape)\n",
    "        spec_gram_nan_check = torch.isnan(spec_gram).any().item()\n",
    "        assert not (spec_gram_nan_check) ,\"Tensor contains NaN values after spec gram creation.\"\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if train == True:\n",
    "                #generate a random number and if condition is met apply aug\n",
    "                ta_transformations_rndm_choice = VT.RandomChoice([AT.FrequencyMasking(freq_mask_param=100),AT.TimeMasking(time_mask_param=50)], p=[.4, .4])\n",
    "                ta_transformations_rndm_apply = VT.RandomApply([AT.FrequencyMasking(freq_mask_param=50),AT.TimeMasking(time_mask_param=25)],p = .15)\n",
    "                spec_gram = ta_transformations_rndm_choice(spec_gram)\n",
    "                spec_gram = ta_transformations_rndm_apply(spec_gram)\n",
    "                spec_gram_nan_check = torch.isnan(spec_gram).any().item()\n",
    "                assert not (spec_gram_nan_check) ,\"Tensor contains NaN values after augmentations  \"\n",
    "                    \n",
    "            \n",
    "        \n",
    "        x = self.sizer(spec_gram.squeeze(dim = 1))\n",
    "        print(\"post sizer shape = \",x.shape)\n",
    "        x = x.unsqueeze(dim = 1)\n",
    "        print(\"post unsqueeze shape = \",x.shape)\n",
    "        \n",
    "        # then repeat channels\n",
    "        del spec_gram,spec_gram_nan_check\n",
    "                  \n",
    "        x = self.backbone(x)\n",
    "        backbone_op_nan_check = torch.isnan(x).any().item()\n",
    "        assert not (backbone_op_nan_check) ,\"Tensor contains NaN values in the backbone OP \"\n",
    "        print(\"x shape = \" + str(x.shape))\n",
    "        #print(\"x = \" +str(x))\n",
    "        #pred = nn.Softmax(x)\n",
    "        expert_outputs = [expert(x) for expert in self.experts]\n",
    "        print(\"expert_outputs = \",expert_outputs)\n",
    "        expert_outputs = torch.stack(expert_outputs, dim=1)\n",
    "        print(\"expert_outputs post stack = \",expert_outputs)\n",
    "        print(\"post stack shape  = \",expert_outputs.shape)\n",
    "        gate_outputs = self.gate(x)\n",
    "        print(\" gate_outputs= \",gate_outputs)\n",
    "        print(\" gate_outputs shape = \",gate_outputs.shape)\n",
    "        \n",
    "        gate_outputs = gate_outputs.unsqueeze(2)\n",
    "        print(\"post unsqueeze gate_outputs =  \",gate_outputs.shape)\n",
    "        weighted_sum = torch.bmm(expert_outputs, gate_outputs)\n",
    "        print(\"weighted_sum = \",weighted_sum)\n",
    "        \n",
    "        #print(np.argmax(pred.detach().cpu().numpy()))\n",
    "        #print(pred)\n",
    "        \n",
    "        #print(output)\n",
    "        del x , backbone_op_nan_check,expert_outputs,gate_outputs\n",
    "        return weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "55ebf016",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,15360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2d58802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b =MyModel('convnext_xlarge_in22k',224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e543aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_elements = [p.numel() for p in model_b.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e23c1ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(num_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b495a0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348159443"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cffd099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post spec gram shape =  torch.Size([1, 1025, 121])\n",
      "post norm shape =  torch.Size([1, 1, 1025, 121])\n",
      "post sizer shape =  torch.Size([1, 224, 224])\n",
      "post unsqueeze shape =  torch.Size([1, 1, 224, 224])\n",
      "x shape = torch.Size([1, 8])\n",
      "expert_outputs =  [tensor([[-0.1601, -0.4489, -0.0433,  0.2854,  0.0722, -0.0035, -0.0689, -0.1482]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.1712, -0.2729, -0.3395,  0.2567, -0.1832, -0.0094, -0.2059, -0.2965]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.3129,  0.0536, -0.1088, -0.4036,  0.0566,  0.0638,  0.1453, -0.1662]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2269,  0.0128, -0.3687,  0.2167,  0.2184,  0.2583, -0.1777, -0.1274]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.0029, -0.2734,  0.1919, -0.0383,  0.1120,  0.1098, -0.1129, -0.2748]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.0019,  0.2014, -0.2976, -0.1182,  0.1901,  0.2917, -0.2344,  0.3787]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0019,  0.2192,  0.1563,  0.2827,  0.2845,  0.2834, -0.2446,  0.0498]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.2079,  0.2467, -0.3794, -0.4193,  0.4827, -0.0064,  0.1925,  0.0961]],\n",
      "       grad_fn=<AddmmBackward0>)]\n",
      "expert_outputs post stack =  tensor([[[-0.1601, -0.4489, -0.0433,  0.2854,  0.0722, -0.0035, -0.0689,\n",
      "          -0.1482],\n",
      "         [-0.1712, -0.2729, -0.3395,  0.2567, -0.1832, -0.0094, -0.2059,\n",
      "          -0.2965],\n",
      "         [-0.3129,  0.0536, -0.1088, -0.4036,  0.0566,  0.0638,  0.1453,\n",
      "          -0.1662],\n",
      "         [ 0.2269,  0.0128, -0.3687,  0.2167,  0.2184,  0.2583, -0.1777,\n",
      "          -0.1274],\n",
      "         [ 0.0029, -0.2734,  0.1919, -0.0383,  0.1120,  0.1098, -0.1129,\n",
      "          -0.2748],\n",
      "         [ 0.0019,  0.2014, -0.2976, -0.1182,  0.1901,  0.2917, -0.2344,\n",
      "           0.3787],\n",
      "         [-0.0019,  0.2192,  0.1563,  0.2827,  0.2845,  0.2834, -0.2446,\n",
      "           0.0498],\n",
      "         [-0.2079,  0.2467, -0.3794, -0.4193,  0.4827, -0.0064,  0.1925,\n",
      "           0.0961]]], grad_fn=<StackBackward0>)\n",
      "post stack shape  =  torch.Size([1, 8, 8])\n",
      " gate_outputs=  tensor([[0.1218, 0.1610, 0.1671, 0.1062, 0.0946, 0.1081, 0.0941, 0.1469]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      " gate_outputs shape =  torch.Size([1, 8])\n",
      "post unsqueeze gate_outputs =   torch.Size([1, 8, 1])\n",
      "weighted_sum =  tensor([[[-0.0905],\n",
      "         [-0.1756],\n",
      "         [-0.0890],\n",
      "         [ 0.0043],\n",
      "         [-0.0442],\n",
      "         [ 0.0535],\n",
      "         [ 0.1331],\n",
      "         [-0.0163]]], grad_fn=<BmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "o = model_b(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa3ab3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0905],\n",
      "         [-0.1756],\n",
      "         [-0.0890],\n",
      "         [ 0.0043],\n",
      "         [-0.0442],\n",
      "         [ 0.0535],\n",
      "         [ 0.1331],\n",
      "         [-0.0163]]], grad_fn=<BmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43f40aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size , num_classes , num_experts):\n",
    "        super().__init__()\n",
    "        self.experts = nn.ModuleList([Expert(input_size, hidden_size, num_classes) for _ in range(num_experts)])\n",
    "        self.gate = Gate(input_size, num_experts)\n",
    "        self.input = MyModel('convnext_xlarge_in22k',224)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        print(\"shape post cnn = \",x.shape)\n",
    "        expert_outputs = [expert(x) for expert in self.experts]\n",
    "        print(\"expert_outputs = \",expert_outputs)\n",
    "        expert_outputs = torch.stack(expert_outputs, dim=1)\n",
    "        print(\"expert_outputs post stack = \",expert_outputs)\n",
    "        print(\"post stack shape  = \",expert_outputs.shape)\n",
    "        \n",
    "        gate_outputs = self.gate(x)\n",
    "        print(\" gate_outputs= \",gate_outputs)\n",
    "        print(\" gate_outputs shape = \",gate_outputs.shape)\n",
    "        \n",
    "        gate_outputs = gate_outputs.unsqueeze(2)\n",
    "        print(\"post unsqueeze gate_outputs =  \",gate_outputs.shape)\n",
    "        weighted_sum = torch.bmm(expert_outputs, gate_outputs)\n",
    "        print(\"weighted_sum = \",weighted_sum)\n",
    "        \n",
    "        return weighted_sum.squeeze(2)\n",
    "\n",
    "# Example usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88d8fd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post spec gram shape =  torch.Size([1, 1025, 121])\n",
      "post norm shape =  torch.Size([1, 1, 1025, 121])\n",
      "post sizer shape =  torch.Size([1, 224, 224])\n",
      "post unsqueeze shape =  torch.Size([1, 1, 224, 224])\n",
      "x shape = torch.Size([1, 8])\n",
      "shape post cnn =  torch.Size([1, 8])\n",
      "expert_outputs =  [tensor([[ 0.2929,  0.0893, -0.2214, -0.0515,  0.0937,  0.0526,  0.2732, -0.0616]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.1425, -0.2046,  0.1789,  0.2661,  0.3432,  0.1691,  0.1548, -0.0121]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.4719, -0.1176, -0.2985, -0.2853,  0.0560, -0.2683,  0.6084, -0.0822]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0644, -0.1544, -0.1961,  0.0087,  0.0336, -0.2573,  0.2496,  0.1691]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.4718,  0.4125, -0.2638, -0.1281,  0.3371, -0.2907,  0.1157,  0.3006]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.3383, -0.2543,  0.2033,  0.1455,  0.0376,  0.0285, -0.2432, -0.3004]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.3286, -0.1048,  0.2065, -0.0592, -0.4057,  0.0907,  0.4603,  0.2600]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.4004,  0.3137, -0.1371,  0.1570,  0.1382, -0.0024, -0.2622,  0.1794]],\n",
      "       grad_fn=<AddmmBackward0>)]\n",
      "expert_outputs post stack =  tensor([[[ 0.2929,  0.0893, -0.2214, -0.0515,  0.0937,  0.0526,  0.2732,\n",
      "          -0.0616],\n",
      "         [ 0.1425, -0.2046,  0.1789,  0.2661,  0.3432,  0.1691,  0.1548,\n",
      "          -0.0121],\n",
      "         [ 0.4719, -0.1176, -0.2985, -0.2853,  0.0560, -0.2683,  0.6084,\n",
      "          -0.0822],\n",
      "         [-0.0644, -0.1544, -0.1961,  0.0087,  0.0336, -0.2573,  0.2496,\n",
      "           0.1691],\n",
      "         [-0.4718,  0.4125, -0.2638, -0.1281,  0.3371, -0.2907,  0.1157,\n",
      "           0.3006],\n",
      "         [-0.3383, -0.2543,  0.2033,  0.1455,  0.0376,  0.0285, -0.2432,\n",
      "          -0.3004],\n",
      "         [-0.3286, -0.1048,  0.2065, -0.0592, -0.4057,  0.0907,  0.4603,\n",
      "           0.2600],\n",
      "         [ 0.4004,  0.3137, -0.1371,  0.1570,  0.1382, -0.0024, -0.2622,\n",
      "           0.1794]]], grad_fn=<StackBackward0>)\n",
      "post stack shape  =  torch.Size([1, 8, 8])\n",
      " gate_outputs=  tensor([[0.1587, 0.0981, 0.1216, 0.0599, 0.1327, 0.1474, 0.1833, 0.0982]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      " gate_outputs shape =  torch.Size([1, 8])\n",
      "post unsqueeze gate_outputs =   torch.Size([1, 8, 1])\n",
      "weighted_sum =  tensor([[[ 0.0894],\n",
      "         [ 0.1379],\n",
      "         [ 0.0813],\n",
      "         [-0.0198],\n",
      "         [-0.0216],\n",
      "         [-0.1101],\n",
      "         [ 0.0286],\n",
      "         [ 0.0746]]], grad_fn=<BmmBackward0>)\n",
      "output =  tensor([[ 0.0894,  0.1379,  0.0813, -0.0198, -0.0216, -0.1101,  0.0286,  0.0746]],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "model = MoE(input_size=8, hidden_size=8, num_classes=8, num_experts=8)\n",
    "input_data = torch.randn(1, 15360)\n",
    "output = model(input_data)\n",
    "print(\"output = \",output)  # (32, 5)\n",
    "pred = torch.argmax(output, dim = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc00ec52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30732652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Expert, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "class Gate(nn.Module):\n",
    "    def __init__(self, input_size, num_experts):\n",
    "        super(Gate, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, num_experts)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "class MixtureOfExperts(nn.Module):\n",
    "    def __init__(self, input_size =8 , hidden_size = 8, num_experts = 8):\n",
    "        super(MixtureOfExperts, self).__init__()\n",
    "        self.experts = nn.ModuleList([Expert(input_size, hidden_size) for i in range(num_experts)])\n",
    "        self.gate = Gate(input_size, num_experts)\n",
    "        self.input = MyModel('convnext_xlarge_in22k',224)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        gates = self.gate(x)\n",
    "        print(\"shape after gates is = \",gates.shape)\n",
    "        print(\"output of gates = \",gates)\n",
    "        expert_outputs = [expert(x) for expert in self.experts]\n",
    "        print(\"expert_outputs = \",expert_outputs)\n",
    "        output = torch.stack(expert_outputs, dim=1)\n",
    "        print(\"output post stack  = \",output)\n",
    "        print(\"post stack shape   = \",output.shape)\n",
    "        output = torch.bmm(gates.unsqueeze(1), output).squeeze(1)\n",
    "        print(\"Final output = \",output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "baf347b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "moe_model = MixtureOfExperts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c38012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post spec gram shape =  torch.Size([1, 1025, 121])\n",
      "post norm shape =  torch.Size([1, 1, 1025, 121])\n",
      "post sizer shape =  torch.Size([1, 224, 224])\n",
      "post unsqueeze shape =  torch.Size([1, 1, 224, 224])\n",
      "x shape = torch.Size([1, 8])\n",
      "shape after gates is =  torch.Size([1, 8])\n",
      "output of gates =  tensor([[0.1725, 0.0945, 0.0841, 0.1015, 0.1362, 0.1459, 0.1654, 0.0999]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "expert_outputs =  [tensor([[0.0326]], grad_fn=<AddmmBackward0>), tensor([[-0.1055]], grad_fn=<AddmmBackward0>), tensor([[0.4171]], grad_fn=<AddmmBackward0>), tensor([[-0.0510]], grad_fn=<AddmmBackward0>), tensor([[0.2768]], grad_fn=<AddmmBackward0>), tensor([[0.2766]], grad_fn=<AddmmBackward0>), tensor([[0.6636]], grad_fn=<AddmmBackward0>), tensor([[-0.1350]], grad_fn=<AddmmBackward0>)]\n",
      "output post stack  =  tensor([[[ 0.0326],\n",
      "         [-0.1055],\n",
      "         [ 0.4171],\n",
      "         [-0.0510],\n",
      "         [ 0.2768],\n",
      "         [ 0.2766],\n",
      "         [ 0.6636],\n",
      "         [-0.1350]]], grad_fn=<StackBackward0>)\n",
      "post stack shape   =  torch.Size([1, 8, 1])\n",
      "Final output =  tensor([[0.1999]], grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1999]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moe_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a8281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
