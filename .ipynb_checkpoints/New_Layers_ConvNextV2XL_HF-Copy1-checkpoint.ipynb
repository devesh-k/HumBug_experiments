{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14790518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.21.4)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.28.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.3.2)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (6.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.25->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib!=3.6.1,>=3.1->seaborn) (1.2.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib!=3.6.1,>=3.1->seaborn) (59.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: nvidia-ml-py3 in /opt/conda/lib/python3.8/site-packages (7.352.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "!pip install nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9492a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Troubleshooting and visualisation\n",
    "import IPython.display as ipd\n",
    "# Troubleshooting and visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4d7edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional pytorch tools\n",
    "import random\n",
    "import torchaudio.transforms as T\n",
    "import torchvision.transforms as VT\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "scaler = GradScaler()\n",
    "from glob import glob\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be471b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hugging face and nn Audio\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ConformerForCTC ,AutoProcessor , AutoProcessor,Wav2Vec2Tokenizer\n",
    "from transformers import Wav2Vec2ConformerConfig, Wav2Vec2ConformerModel \n",
    "from transformers import AutoImageProcessor, ConvNextV2ForImageClassification\n",
    "from nnAudio import features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a03f9f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general Py and SK learn\n",
    "from sklearn.metrics import f1_score\n",
    "#from PyTorch import config_pytorch\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import os , gc\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../../src'))\n",
    "import config ,config_pytorch\n",
    "import numpy as np\n",
    "torch.backends.cuda.matmul.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe0d60b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: timm in /opt/conda/lib/python3.8/site-packages (0.6.7)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.8/site-packages (from timm) (1.11.0+cu113)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from timm) (0.12.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.4->timm) (4.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (2.26.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (1.21.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (9.2.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->timm) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->timm) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->timm) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->timm) (2.0.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6caddd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6.7\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "print(timm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ba112b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Training variables \n",
    "USE_SHORT_AUDIO = True\n",
    "num_workers= 0\n",
    "pin_memory=False\n",
    "#train_size = 100\n",
    "batch_size = 16\n",
    "test_batch_size = 16\n",
    "num_epochs = 400\n",
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    batch_size = 4\n",
    "    test_batch_size = 4\n",
    "    num_workers=0\n",
    "    num_epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b156bb",
   "metadata": {},
   "source": [
    "### Let's get the data in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1fe5893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates 1.92 secs rows of audio in a data frame format\n",
    "# This function creates 1.92 secs rows of audio in a data frame format\n",
    "def get_offsets_df(df, short_audio=False):\n",
    "    audio_offsets = []\n",
    "    #This is same as defined in config -min_duration = win_size * frame_duration\n",
    "    min_length = config.win_size*config.NFFT/(((1/config.n_hop)*config.NFFT)*config.rate)\n",
    "    step_frac = config.step_size/config.win_size\n",
    "    stride = step_frac*min_length\n",
    "#     print(\"min_length = \" +str(min_length))\n",
    "#     print(\"step_frac = \" +str(step_frac))\n",
    "#     print(\"stride = \" +str(stride))\n",
    "    for _,row in df.iterrows():\n",
    "        #processed_data keeps track of the tensor_values processed thus far\n",
    "        if row['length'] > min_length:\n",
    "            processed_data = 0\n",
    "            #total_data is the total tensor present in the audio\n",
    "            total_data = config.rate*row['length']\n",
    "            #print(\"********\")\n",
    "            count = 0\n",
    "#             print(\"count = \" +str(count))\n",
    "#             print(\"id = \" + str(row['id']) + \" duration = \" +str(row['length']) + \"total x vals = \" + str(total_data))\n",
    "            inner_loop_flag = False\n",
    "            #print(\"going into the inner loop to offset....\")\n",
    "            while(processed_data < total_data):\n",
    "                #print(\"inside inner loop.....\")\n",
    "                start = count*stride*config.rate\n",
    "                #now find out the row_len\n",
    "                if total_data - (start + min_length*config.rate) >= 0:\n",
    "                    #print(\"full chunk \")\n",
    "                    row_len = min_length\n",
    "                    end = start + row_len*config.rate\n",
    "                    audio_offsets.append({'id':row['id'], 'offset':count, 'length': row_len,'specie_ind': row['specie_ind'],'start':start,'end':end})\n",
    "                    #print(\"count = \" +str(count) + \"offset = \" +str(count) + \"start = \" +str(start) + \"end = \" +str(end))\n",
    "                    #print(\"for count.... = \" + str(count) + \"processed data = \" +str(processed_data))\n",
    "                    count+=1\n",
    "                    processed_data = (count*stride)*config.rate\n",
    "                    \n",
    "                else:\n",
    "                    inner_loop_flag = True\n",
    "                    break\n",
    "                    \n",
    "                                                       \n",
    "            #for processing residual data\n",
    "            if(inner_loop_flag):\n",
    "                #print(\"processing residual ....processed \" +str(processed_data) + \" of \" + str(total_data))\n",
    "                start = count*stride*config.rate\n",
    "                resid_durn = round((total_data - processed_data)/config.rate,2)\n",
    "                end = total_data\n",
    "                #print(\"for...\" + str(row['id']) + \" adding the residual data in the data frame with duration = \" + str(resid_durn))\n",
    "                audio_offsets.append({'id':row['id'], 'offset':count, 'length':resid_durn ,'specie_ind': row['specie_ind'],'start':start,'end':end})\n",
    "            \n",
    "        elif short_audio:\n",
    "            start = 0\n",
    "            end = row['length']*config.rate\n",
    "            audio_offsets.append({'id':row['id'], 'offset':0,'length': row['length'],'specie_ind': row['specie_ind'],'start':0 , 'end':end})\n",
    "    return pd.DataFrame(audio_offsets)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac7efffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['an arabiensis','culex pipiens complex', 'ae aegypti','an funestus ss','an squamosus',\n",
    "               'an coustani','ma uniformis','ma africanus' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661564a",
   "metadata": {},
   "source": [
    "### Read CSV and get train/test groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "637b9c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>name</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>record_datetime</th>\n",
       "      <th>sound_type</th>\n",
       "      <th>species</th>\n",
       "      <th>gender</th>\n",
       "      <th>fed</th>\n",
       "      <th>plurality</th>\n",
       "      <th>age</th>\n",
       "      <th>method</th>\n",
       "      <th>mic_type</th>\n",
       "      <th>device_type</th>\n",
       "      <th>country</th>\n",
       "      <th>district</th>\n",
       "      <th>province</th>\n",
       "      <th>place</th>\n",
       "      <th>location_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>0.463456</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>0.170249</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>0.104041</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>0.274290</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56</td>\n",
       "      <td>0.420894</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>3562</td>\n",
       "      <td>6.083093</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000</th>\n",
       "      <td>3556</td>\n",
       "      <td>6.719908</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an maculatus</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9009</th>\n",
       "      <td>3553</td>\n",
       "      <td>6.128580</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an maculatus</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9011</th>\n",
       "      <td>3561</td>\n",
       "      <td>11.614280</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9012</th>\n",
       "      <td>3552</td>\n",
       "      <td>2.920249</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6008 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     length                             name  sample_rate  \\\n",
       "1       53   0.463456  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "2       57   0.170249  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "3       61   0.104041  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "4       69   0.274290  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "5       56   0.420894  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "...    ...        ...                              ...          ...   \n",
       "8999  3562   6.083093                    #988-1001.wav        44100   \n",
       "9000  3556   6.719908                    #988-1001.wav        44100   \n",
       "9009  3553   6.128580                    #988-1001.wav        44100   \n",
       "9011  3561  11.614280                    #988-1001.wav        44100   \n",
       "9012  3552   2.920249                    #988-1001.wav        44100   \n",
       "\n",
       "     record_datetime sound_type       species  gender  fed plurality  age  \\\n",
       "1      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "2      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "3      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "4      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "5      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Plural  NaN   \n",
       "...              ...        ...           ...     ...  ...       ...  ...   \n",
       "8999  1/7/2018 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "9000  1/7/2018 12:00   mosquito  an maculatus  Female    t    Single  NaN   \n",
       "9009  1/7/2018 12:00   mosquito  an maculatus  Female    t    Single  NaN   \n",
       "9011  1/7/2018 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "9012  1/7/2018 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "\n",
       "     method mic_type    device_type   country          district  \\\n",
       "1       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "2       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "3       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "4       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "5       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "...     ...      ...            ...       ...               ...   \n",
       "8999    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9000    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9009    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9011    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9012    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "\n",
       "                   province                            place location_type  \n",
       "1                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "2                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "3                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "4                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "5                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "...                     ...                              ...           ...  \n",
       "8999  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9000  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9009  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9011  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9012  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "\n",
       "[6008 rows x 19 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if DEBUG:\n",
    "#     df = pd.read_csv(config.data_df_msc_test)\n",
    "# else:\n",
    "df = pd.read_csv(config.data_df)\n",
    "\n",
    "#df = df.loc[df['Grade'].notnull()]\n",
    "df = df.loc[df['species'].notnull()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d00370d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a colum for specie encoding\n",
    "df['specie_ind'] = \"NULL_VAL\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "596dd0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specie = an arabiensisand its index = 0\n",
      "specie = culex pipiens complexand its index = 1\n",
      "specie = ae aegyptiand its index = 2\n",
      "specie = an funestus ssand its index = 3\n",
      "specie = an squamosusand its index = 4\n",
      "specie = an coustaniand its index = 5\n",
      "specie = ma uniformisand its index = 6\n",
      "specie = ma africanusand its index = 7\n"
     ]
    }
   ],
   "source": [
    "# Adding a new column to encode specie_index in the same order as the list \"classes\"\n",
    "ind = 0\n",
    "for specie in classes:\n",
    "    print(\"specie = \" + str(specie) + \"and its index = \" + str(ind) )\n",
    "    row_indexes=df[df['species']==specie].index \n",
    "    df.loc[row_indexes,'specie_ind']= ind\n",
    "    ind+=1\n",
    "\n",
    "    \n",
    "# other_df_ind = df[df['specie_ind'] == \"NULL_VAL\"].index\n",
    "# df.loc[other_df_ind,'specie_ind']= other_ind                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5f70a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['specie_ind'] == \"NULL_VAL\"].index, inplace=True)\n",
    "#other_df_ind = df[df['specie_ind'] == \"NULL_VAL\"].index\n",
    "#df.loc[other_df_ind,'specie_ind']= other_ind        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd28582",
   "metadata": {},
   "source": [
    "At this stage we have all extracted the data with specie information and have encoded the specie encoding in a col = 'specie_ind'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "052137db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the TZ and Cup data- this is as per the humbug paper\n",
    "\n",
    "idx_multiclass = np.logical_and(df['country'] == 'Tanzania', df['location_type'] == 'cup')\n",
    "df_all = df[idx_multiclass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "539f7cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.reset_index(inplace=True ,drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03d4e8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>name</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>record_datetime</th>\n",
       "      <th>sound_type</th>\n",
       "      <th>species</th>\n",
       "      <th>gender</th>\n",
       "      <th>fed</th>\n",
       "      <th>plurality</th>\n",
       "      <th>age</th>\n",
       "      <th>method</th>\n",
       "      <th>mic_type</th>\n",
       "      <th>device_type</th>\n",
       "      <th>country</th>\n",
       "      <th>district</th>\n",
       "      <th>province</th>\n",
       "      <th>place</th>\n",
       "      <th>location_type</th>\n",
       "      <th>specie_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221103</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_24_664.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221111</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_25_665.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221110</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_25_665.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221149</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_26_666.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an arabiensis</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221150</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_26_666.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an arabiensis</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>222615</td>\n",
       "      <td>30.72</td>\n",
       "      <td>IFA_86_39_3439.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>222585</td>\n",
       "      <td>25.60</td>\n",
       "      <td>IFA_86_40_3440.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>222586</td>\n",
       "      <td>40.90</td>\n",
       "      <td>IFA_87_10_3450.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>222596</td>\n",
       "      <td>40.90</td>\n",
       "      <td>IFA_87_11_3451.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>222614</td>\n",
       "      <td>38.40</td>\n",
       "      <td>IFA_87_12_3452.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2288 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  length                name  sample_rate record_datetime  \\\n",
       "0     221103    2.56   IFA_17_24_664.wav        44100  30-01-20 00:00   \n",
       "1     221111    2.56   IFA_17_25_665.wav        44100  30-01-20 00:00   \n",
       "2     221110    2.56   IFA_17_25_665.wav        44100  30-01-20 00:00   \n",
       "3     221149    2.56   IFA_17_26_666.wav        44100  30-01-20 00:00   \n",
       "4     221150    2.56   IFA_17_26_666.wav        44100  30-01-20 00:00   \n",
       "...      ...     ...                 ...          ...             ...   \n",
       "2283  222615   30.72  IFA_86_39_3439.wav        44100  23-08-20 00:00   \n",
       "2284  222585   25.60  IFA_86_40_3440.wav        44100  23-08-20 00:00   \n",
       "2285  222586   40.90  IFA_87_10_3450.wav        44100  23-08-20 00:00   \n",
       "2286  222596   40.90  IFA_87_11_3451.wav        44100  23-08-20 00:00   \n",
       "2287  222614   38.40  IFA_87_12_3452.wav        44100  23-08-20 00:00   \n",
       "\n",
       "     sound_type         species  gender fed plurality  age method mic_type  \\\n",
       "0      mosquito    ma africanus  Female   f    Single  NaN    HBN  telinga   \n",
       "1      mosquito    ma africanus  Female   f    Single  NaN    HBN  telinga   \n",
       "2      mosquito    ma africanus  Female   f    Single  NaN    HBN  telinga   \n",
       "3      mosquito   an arabiensis  Female   f    Single  NaN    HBN  telinga   \n",
       "4      mosquito   an arabiensis  Female   f    Single  NaN    HBN  telinga   \n",
       "...         ...             ...     ...  ..       ...  ...    ...      ...   \n",
       "2283   mosquito  an funestus ss  Female   f    Single  NaN     LT  telinga   \n",
       "2284   mosquito  an funestus ss  Female   f    Single  NaN     LT  telinga   \n",
       "2285   mosquito  an funestus ss  Female   f    Single  NaN     LT  telinga   \n",
       "2286   mosquito  an funestus ss  Female   f    Single  NaN     LT  telinga   \n",
       "2287   mosquito  an funestus ss  Female   f    Single  NaN     LT  telinga   \n",
       "\n",
       "     device_type   country            district  province    place  \\\n",
       "0         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "1         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "3         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "4         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "...          ...       ...                 ...       ...      ...   \n",
       "2283      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2284      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2285      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2286      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2287      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "\n",
       "     location_type specie_ind  \n",
       "0              cup          7  \n",
       "1              cup          7  \n",
       "2              cup          7  \n",
       "3              cup          0  \n",
       "4              cup          0  \n",
       "...            ...        ...  \n",
       "2283           cup          3  \n",
       "2284           cup          3  \n",
       "2285           cup          3  \n",
       "2286           cup          3  \n",
       "2287           cup          3  \n",
       "\n",
       "[2288 rows x 20 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a34bc28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "import seaborn as sns\n",
    "sns.countplot(x = 'species', data = df_all , ax = ax , hue = 'gender',palette='dark')\n",
    "#ax.bar_label(ax.containers[0])\n",
    "#ax.bar_label(ax.containers[-1], fmt='Count:\\n%.2f', label_type='center')\n",
    "plt.xticks(rotation=90 )\n",
    "plt.title(\"Distribution of Species \")\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('axes', labelsize=15)\n",
    "plt.rc('figure', titlesize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352e09d",
   "metadata": {},
   "source": [
    "### Train-Test split( avoiding sklearn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "899698f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "msk_test = np.random.rand(len(df_all)) < 0.2\n",
    "df_test = df_all[msk_test]\n",
    "df_train_temp  = df_all[~msk_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b1d73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "msk_train = np.random.rand(len(df_train_temp)) < 0.2\n",
    "df_val = df_train_temp[msk_train]\n",
    "df_train  = df_train_temp[~msk_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e026787b",
   "metadata": {},
   "source": [
    "## Let's verify for data leakage by performing an inner-join on id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "988d0060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>length_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>sample_rate_x</th>\n",
       "      <th>record_datetime_x</th>\n",
       "      <th>sound_type_x</th>\n",
       "      <th>species_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>fed_x</th>\n",
       "      <th>plurality_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_y</th>\n",
       "      <th>method_y</th>\n",
       "      <th>mic_type_y</th>\n",
       "      <th>device_type_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>district_y</th>\n",
       "      <th>province_y</th>\n",
       "      <th>place_y</th>\n",
       "      <th>location_type_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, length_x, name_x, sample_rate_x, record_datetime_x, sound_type_x, species_x, gender_x, fed_x, plurality_x, age_x, method_x, mic_type_x, device_type_x, country_x, district_x, province_x, place_x, location_type_x, specie_ind_x, length_y, name_y, sample_rate_y, record_datetime_y, sound_type_y, species_y, gender_y, fed_y, plurality_y, age_y, method_y, mic_type_y, device_type_y, country_y, district_y, province_y, place_y, location_type_y, specie_ind_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 39 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_test,df_train, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efe6e770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>length_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>sample_rate_x</th>\n",
       "      <th>record_datetime_x</th>\n",
       "      <th>sound_type_x</th>\n",
       "      <th>species_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>fed_x</th>\n",
       "      <th>plurality_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_y</th>\n",
       "      <th>method_y</th>\n",
       "      <th>mic_type_y</th>\n",
       "      <th>device_type_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>district_y</th>\n",
       "      <th>province_y</th>\n",
       "      <th>place_y</th>\n",
       "      <th>location_type_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, length_x, name_x, sample_rate_x, record_datetime_x, sound_type_x, species_x, gender_x, fed_x, plurality_x, age_x, method_x, mic_type_x, device_type_x, country_x, district_x, province_x, place_x, location_type_x, specie_ind_x, length_y, name_y, sample_rate_y, record_datetime_y, sound_type_y, species_y, gender_y, fed_y, plurality_y, age_y, method_y, mic_type_y, device_type_y, country_y, district_y, province_y, place_y, location_type_y, specie_ind_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 39 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_test,df_val, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "414f4e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>length_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>sample_rate_x</th>\n",
       "      <th>record_datetime_x</th>\n",
       "      <th>sound_type_x</th>\n",
       "      <th>species_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>fed_x</th>\n",
       "      <th>plurality_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_y</th>\n",
       "      <th>method_y</th>\n",
       "      <th>mic_type_y</th>\n",
       "      <th>device_type_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>district_y</th>\n",
       "      <th>province_y</th>\n",
       "      <th>place_y</th>\n",
       "      <th>location_type_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, length_x, name_x, sample_rate_x, record_datetime_x, sound_type_x, species_x, gender_x, fed_x, plurality_x, age_x, method_x, mic_type_x, device_type_x, country_x, district_x, province_x, place_x, location_type_x, specie_ind_x, length_y, name_y, sample_rate_y, record_datetime_y, sound_type_y, species_y, gender_y, fed_y, plurality_y, age_y, method_y, mic_type_y, device_type_y, country_y, district_y, province_y, place_y, location_type_y, specie_ind_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 39 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_train,df_val, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43350e84",
   "metadata": {},
   "source": [
    "We've confirmed that there is no recording that is common in Train,Test,val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f27efcd",
   "metadata": {},
   "source": [
    "### Next, we perform \"offsets\", spliting each(long) recording into multiple 1.92 secs chunk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94b5b98a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_offset = get_offsets_df(df_train)\n",
    "df_test_offset = get_offsets_df(df_test)\n",
    "df_val_offset = get_offsets_df(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfe3502a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train offset = 35043\n",
      "length of test offset = 11043\n",
      "length of val offset = 9466\n"
     ]
    }
   ],
   "source": [
    "print(\"length of train offset = \" +str(len(df_train_offset)))\n",
    "print(\"length of test offset = \" +str(len(df_test_offset)))\n",
    "print(\"length of val offset = \" +str(len(df_val_offset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3017105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_temp.reset_index(inplace = True)\n",
    "df_train_offset.reset_index(inplace = True,drop = True)\n",
    "df_test_offset.reset_index(inplace = True , drop = True)\n",
    "df_val_offset.reset_index(inplace = True , drop = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d32bed5",
   "metadata": {},
   "source": [
    "### Let's check for data leakage in offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "297be5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>offset_x</th>\n",
       "      <th>length_x</th>\n",
       "      <th>specie_ind_x</th>\n",
       "      <th>start_x</th>\n",
       "      <th>end_x</th>\n",
       "      <th>offset_y</th>\n",
       "      <th>length_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, offset_x, length_x, specie_ind_x, start_x, end_x, offset_y, length_y, specie_ind_y, start_y, end_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_train_offset , df_test_offset , on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a366e822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>offset_x</th>\n",
       "      <th>length_x</th>\n",
       "      <th>specie_ind_x</th>\n",
       "      <th>start_x</th>\n",
       "      <th>end_x</th>\n",
       "      <th>offset_y</th>\n",
       "      <th>length_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, offset_x, length_x, specie_ind_x, start_x, end_x, offset_y, length_y, specie_ind_y, start_y, end_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_train_offset , df_val_offset , on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff5a5010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>offset_x</th>\n",
       "      <th>length_x</th>\n",
       "      <th>specie_ind_x</th>\n",
       "      <th>start_x</th>\n",
       "      <th>end_x</th>\n",
       "      <th>offset_y</th>\n",
       "      <th>length_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, offset_x, length_x, specie_ind_x, start_x, end_x, offset_y, length_y, specie_ind_y, start_y, end_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_test_offset , df_val_offset , on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056301c6",
   "metadata": {},
   "source": [
    "### At this stage we've a dataframe of recordin ids and each row corresponds to a 1.92 secs recording or shorter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e4e490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specie_distri(df , classes , type_df = None):\n",
    "    \"\"\"This function takes a dataframe and provides a count of each specie class\"\"\"\n",
    "    for i in range(len(classes)):\n",
    "        print(\"DF type = \" + str(type_df))\n",
    "        df_temp = df[df['specie_ind'] == i]\n",
    "        print(\"i = \" +str(i))\n",
    "        print(len(df_temp))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8d86fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32524317 0.56223527 3.61119126 0.62576786 1.97670352 4.1207667\n",
      " 3.00231323 5.25855342]\n"
     ]
    }
   ],
   "source": [
    "#Class imbalance \n",
    "np.array(df_train_offset.specie_ind)\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',classes=np.unique(np.array(df_train_offset.specie_ind)),y=np.array(np.array(df_train_offset.specie_ind)))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "647c038d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>specie_ind</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221122</td>\n",
       "      <td>0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221122</td>\n",
       "      <td>1</td>\n",
       "      <td>1.92</td>\n",
       "      <td>6</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221122</td>\n",
       "      <td>2</td>\n",
       "      <td>1.28</td>\n",
       "      <td>6</td>\n",
       "      <td>10240.0</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221124</td>\n",
       "      <td>0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221124</td>\n",
       "      <td>1</td>\n",
       "      <td>1.92</td>\n",
       "      <td>6</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  offset  length  specie_ind    start      end\n",
       "0  221122       0    1.92           6      0.0  15360.0\n",
       "1  221122       1    1.92           6   5120.0  20480.0\n",
       "2  221122       2    1.28           6  10240.0  20480.0\n",
       "3  221124       0    1.92           6      0.0  15360.0\n",
       "4  221124       1    1.92           6   5120.0  20480.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_offset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1c56cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "import seaborn as sns\n",
    "sns.countplot(x = 'specie_ind', data = df_val_offset , ax = ax ,palette='dark')\n",
    "#ax.bar_label(ax.containers[0])\n",
    "#ax.bar_label(ax.containers[-1], fmt='Count:\\n%.2f', label_type='center')\n",
    "plt.xticks(rotation=90 )\n",
    "plt.title(\"Distribution of Species in Val set\")\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('axes', labelsize=15)\n",
    "plt.rc('figure', titlesize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2952ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "import seaborn as sns\n",
    "sns.countplot(x = 'specie_ind', data = df_test_offset , ax = ax ,palette='dark')\n",
    "#ax.bar_label(ax.containers[0])\n",
    "#ax.bar_label(ax.containers[-1], fmt='Count:\\n%.2f', label_type='center')\n",
    "plt.xticks(rotation=90 )\n",
    "plt.title(\"Distribution of Species in Test set\")\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('axes', labelsize=15)\n",
    "plt.rc('figure', titlesize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d748b73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>specie_ind</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>220340</td>\n",
       "      <td>0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2529</th>\n",
       "      <td>220340</td>\n",
       "      <td>1</td>\n",
       "      <td>1.92</td>\n",
       "      <td>4</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>220340</td>\n",
       "      <td>2</td>\n",
       "      <td>1.92</td>\n",
       "      <td>4</td>\n",
       "      <td>10240.0</td>\n",
       "      <td>25600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>220340</td>\n",
       "      <td>3</td>\n",
       "      <td>1.92</td>\n",
       "      <td>4</td>\n",
       "      <td>15360.0</td>\n",
       "      <td>30720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>220340</td>\n",
       "      <td>4</td>\n",
       "      <td>1.92</td>\n",
       "      <td>4</td>\n",
       "      <td>20480.0</td>\n",
       "      <td>35840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>222218</td>\n",
       "      <td>38</td>\n",
       "      <td>1.92</td>\n",
       "      <td>4</td>\n",
       "      <td>194560.0</td>\n",
       "      <td>209920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6939</th>\n",
       "      <td>222218</td>\n",
       "      <td>39</td>\n",
       "      <td>1.92</td>\n",
       "      <td>4</td>\n",
       "      <td>199680.0</td>\n",
       "      <td>215040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6940</th>\n",
       "      <td>222218</td>\n",
       "      <td>40</td>\n",
       "      <td>1.92</td>\n",
       "      <td>4</td>\n",
       "      <td>204800.0</td>\n",
       "      <td>220160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6941</th>\n",
       "      <td>222218</td>\n",
       "      <td>41</td>\n",
       "      <td>1.92</td>\n",
       "      <td>4</td>\n",
       "      <td>209920.0</td>\n",
       "      <td>225280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6942</th>\n",
       "      <td>222218</td>\n",
       "      <td>42</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4</td>\n",
       "      <td>215040.0</td>\n",
       "      <td>225280.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  offset  length  specie_ind     start       end\n",
       "2528  220340       0    1.92           4       0.0   15360.0\n",
       "2529  220340       1    1.92           4    5120.0   20480.0\n",
       "2530  220340       2    1.92           4   10240.0   25600.0\n",
       "2531  220340       3    1.92           4   15360.0   30720.0\n",
       "2532  220340       4    1.92           4   20480.0   35840.0\n",
       "...      ...     ...     ...         ...       ...       ...\n",
       "6938  222218      38    1.92           4  194560.0  209920.0\n",
       "6939  222218      39    1.92           4  199680.0  215040.0\n",
       "6940  222218      40    1.92           4  204800.0  220160.0\n",
       "6941  222218      41    1.92           4  209920.0  225280.0\n",
       "6942  222218      42    1.28           4  215040.0  225280.0\n",
       "\n",
       "[318 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_offset[df_val_offset['specie_ind'] == 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b0a8b",
   "metadata": {},
   "source": [
    "### Now we need to populate the lists of file_names and label_names for use in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb820047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e660a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed7b47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lists(df):\n",
    "    #parent_dir = os.path.join(\"~\",\"ComParE2022_VecNet\",\"data\",\"audio\")\n",
    "    parent_dir = os.path.join(\"..\",\"..\",\"data\",\"audio\")\n",
    "    file_list = []\n",
    "    label_list = []\n",
    "    #print(\"inside get_lists\")\n",
    "    for ind,row in tqdm(df.iterrows()):\n",
    "        #print(row)\n",
    "        #print(row['id'])\n",
    "        wav = str(int(row['id']))+\".wav\"\n",
    "        final_path = parent_dir + \"/\"+wav\n",
    "        #print(\"wav file path = \",final_path)\n",
    "        start = int(round((row['start'])))\n",
    "        end = int(round((row['end'])))\n",
    "        \n",
    "        #start_offset = int(round((row['start'])))\n",
    "        #end_offset = int(round((row['end'])))\n",
    "        tup = (final_path , start ,end)                          \n",
    "        file_list.append(tup)\n",
    "        label_list.append(torch.tensor(row['specie_ind']))\n",
    "        \n",
    "    return file_list, label_list\n",
    "        \n",
    "   \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d7f64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for x in label_list_test:\n",
    "#     if x == 4:\n",
    "#         count +=1\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a279a941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013936996459960938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf53f4ca4014292b48d36bae21ddbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012979269027709961,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4bdb17969f474e9a6269f8c32e9f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012718677520751953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f16485ec6446cea5a6804d7525dfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_list_train , label_list_train = get_lists(df_train_offset)\n",
    "file_list_val , label_list_val = get_lists(df_val_offset)\n",
    "file_list_test , label_list_test = get_lists(df_test_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c448cf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_list_train len =  35043\n",
      "label_list_train len =  35043\n",
      "file_list_val len =  9466\n",
      "label_list_val len =  9466\n",
      "file_list_test len =  11043\n",
      "label_list_test len =  11043\n"
     ]
    }
   ],
   "source": [
    "print(\"file_list_train len = \", len(file_list_train))\n",
    "print(\"label_list_train len = \", len(label_list_train))\n",
    "print(\"file_list_val len = \", len(file_list_val))\n",
    "print(\"label_list_val len = \", len(label_list_val))\n",
    "print(\"file_list_test len = \", len(file_list_test))\n",
    "print(\"label_list_test len = \", len(label_list_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7403b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_hat,y_true,classes):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_hat, y_true ,labels= range(len(classes)))\n",
    "    import seaborn as sns\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, fmt = 'g'); #annot=True to annotate cellsplt.xticks(rotation=90)\n",
    "    ax.xaxis.set_ticklabels(classes, fontsize = 10)\n",
    "    ax.xaxis.tick_bottom()\n",
    "    plt.xticks(rotation=90)\n",
    "    ax.set_ylabel('True', fontsize=20)\n",
    "    ax.yaxis.set_ticklabels(classes, fontsize = 10)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b599e639",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f5628d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b440bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loader, criterion,  classes = classes,device=None , call = \"val\"):\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        test_loss = 0.0\n",
    "        model.eval()\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        counter = 1\n",
    "        print(\"^^^^^^^^ TEST MODEL STARTS^^^^^^^^^^^^^\")\n",
    "        for i,(inputs,labels) in enumerate(loader):\n",
    "            #inputs,labels = tup[i]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.type(torch.LongTensor).to(device)\n",
    "            output_dict = model_new(inputs, train = False)\n",
    "            y_pred = output_dict['probs']\n",
    "            preds = output_dict['preds']\n",
    "            del output_dict\n",
    "            #_, preds = torch.max(outputs, 1)\n",
    "            #preds = torch.argmax(y_pred_smax, axis = 1)\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            #all_y_pred.append(preds.cpu().detach())\n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "                                   \n",
    "            loss = criterion(y_pred, labels)\n",
    "            test_loss += loss.item()\n",
    "            all_y.append(labels.cpu().detach())\n",
    "            #all_y_pred.append(np.argmax(y_pred.cpu().detach().numpy()))\n",
    "            if DEBUG:\n",
    "                print(\"inside test....\" + \"calling for \" + str(call))\n",
    "                print(\"inputs shape  = \" + str(inputs.shape))\n",
    "                print(\"labels shape  = \" + str(labels.shape))\n",
    "                print(\"y_pred  = \" + str(y_pred))\n",
    "                #print(\"y_pred_smax = \" +str(y_pred_smax))\n",
    "                print(\"preds = \" +str(preds))\n",
    "                            \n",
    "            \n",
    "            \n",
    "            del inputs\n",
    "            del labels\n",
    "            del y_pred,preds\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        test_loss = test_loss/len(test_loader)\n",
    "        test_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "        if DEBUG:\n",
    "            print(\"all_y_pred = \", all_y_pred)\n",
    "            print(\"all_y = \", all_y)\n",
    "            print(\"test_f1 = \", test_f1)\n",
    "            \n",
    "        print(\"^^^^^^TEST MODEL ENDS^^^^^^^^\")    \n",
    "            \n",
    "    \n",
    "    \n",
    "    return test_loss, test_f1 , all_y,all_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87929e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader,val_loader,test_loader,model ,classes = classes,class_weights = class_weights,num_epochs = num_epochs ,n_channels = 1):\n",
    "    # Creates a GradScaler once at the beginning of training.\n",
    "    \n",
    "    torch.manual_seed(0)\n",
    "    lr = 1e-4\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f'Training on {device}')    \n",
    "    model = model.to(device)\n",
    "    #print(\"inside train _model\")\n",
    "    #print(\"after sending the model to GPU, memory footprint..\")\n",
    "    #print_gpu_utilization()\n",
    "    class_weights = class_weights\n",
    "    weights_adj = torch.tensor(class_weights).type(torch.float).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights_adj)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(weight=weights_adj)\n",
    "    #torch.optim.adafactor(model.parameters(), lr=lr)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    num_epochs = num_epochs\n",
    "    all_train_loss = []\n",
    "    all_train_f1 = []\n",
    "    all_val_loss = []\n",
    "    all_val_f1 = []\n",
    "    best_val_loss = np.inf\n",
    "    best_val_f1 = -np.inf\n",
    "    best_train_f1 = -np.inf\n",
    "    best_epoch = -1\n",
    "    checkpoint_name = None\n",
    "    overrun_counter = 0\n",
    "    all_train_f1 = []\n",
    "    all_val_f1 = []\n",
    "    lr_log = []\n",
    "    accumulation_steps = 2\n",
    "    for e in tqdm(range(num_epochs), desc = \"epoc loop\"):\n",
    "        start_time = time.time()\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        for i, (inputs,labels) in enumerate(train_loader):\n",
    "            #print(\"^^^^^^^^^i^^^^^^^^^ = \" +str(i) + \"^^^^^^^^^i^^^^^^^^^ \")\n",
    "                  \n",
    "            if i % 700 == 0:\n",
    "                bat_time = time.time()\n",
    "                durn = (bat_time - start_time)/60\n",
    "                print(\"epoch = \" +str(e) + \"batch = \" +str(i) + \" of \" + str(len(train_loader)) + \"duraation = \" + str(durn))\n",
    "            \n",
    "            #inputs,labels = tup[i]\n",
    "            #print(\"before sending the data to GPU \")\n",
    "            #print_gpu_utilization()\n",
    "            inputs = inputs.to(device)\n",
    "            #.type(torch.LongTensor)\n",
    "            labels = labels.type(torch.LongTensor).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            #print(\"after loadig the model and inputs and labels GPU util = \")\n",
    "            #print_gpu_utilization()\n",
    "            if DEBUG:\n",
    "                    print(\"inputs shape = \", inputs.shape)\n",
    "                    print(\"labels  = \", labels)\n",
    "                    print(\"inputs ->\", inputs)\n",
    "            with autocast():\n",
    "                #y_pred = model_new(inputs).logits\n",
    "                output_dict = model_new(inputs ,train = True)\n",
    "                #print(\"output_dict = \" , output_dict)\n",
    "                y_pred = output_dict['probs']\n",
    "                preds = output_dict['preds']\n",
    "                #y_pred = model(inputs).detach()\n",
    "                del inputs , output_dict\n",
    "                #preds = torch.max(y_pred, dim=1)\n",
    "                #print(\"outputs = \",preds)\n",
    "                if DEBUG:\n",
    "                    print(\"y_pred = \", y_pred)\n",
    "                    print(\"y_pred shape = \", y_pred.shape)\n",
    "                    \n",
    "                    #print(\"y_pred_smax = \", y_pred_smax)\n",
    "                    #print(\"preds shape = \", preds.shape)\n",
    "                    print(\"preds  = \", preds)\n",
    "                    \n",
    "                loss = loss_fn(y_pred, labels)\n",
    "                loss = loss / accumulation_steps\n",
    "                                    \n",
    "            scaler.scale(loss).backward()\n",
    "            if ((i + 1) % accumulation_steps == 0):\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            #train_loss += loss.item()\n",
    "            all_y.append(labels.cpu().detach())\n",
    "            #y_pred_cpu = preds.cpu().detach()\n",
    "            #all_y_pred.append(preds.cpu().detach())\n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "            del labels\n",
    "            del y_pred,preds\n",
    "            #gc.collect()\n",
    "            #torch.cuda.empty_cache()\n",
    "            \n",
    "        #lr_log.append(lr)\n",
    "        train_loss += loss.detach().item()\n",
    "        all_train_loss.append(train_loss/len(train_loader))\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "                 \n",
    "        train_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "        if DEBUG:\n",
    "            print(\"all_y = \", all_y.numpy())\n",
    "            print(\"all_y_pred.numpy() = \", all_y_pred.numpy())\n",
    "            print(\"train f1  = \", train_f1)\n",
    "        all_train_f1.append(train_f1)\n",
    "        all_train_f1.append(train_f1)\n",
    "        val_loss, val_f1 , _,_ = test_model(model, val_loader, criterion = nn.CrossEntropyLoss(), classes = classes ,device=device, call = \"val\")\n",
    "        all_val_f1.append(val_f1)\n",
    "        all_val_loss.append(val_loss)\n",
    "        all_val_loss.append(val_loss)\n",
    "        all_val_f1.append(val_f1)\n",
    "        \n",
    "        acc_metric = val_f1\n",
    "        best_acc_metric = best_val_f1\n",
    "        if acc_metric > best_acc_metric:  \n",
    "            overrun_counter = -1\n",
    "            checkpoint_name = f'model_e{e}_{datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")}.pth'\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_dir,  checkpoint_name))\n",
    "            sys.stdout.flush()\n",
    "            print('Epoch: %d, Train Loss: %.8f, Train f1: %.8f, Val Loss: %.8f, Val f1: %.8f, overrun_counter %i' % (e, train_loss/len(train_loader), train_f1, val_loss/len(val_loader), val_f1,  overrun_counter))\n",
    "            print('Saving model to:', os.path.join(config.model_dir,  checkpoint_name)) \n",
    "            print(\"Now printing classification rport... \")\n",
    "            print(\"********************************\")\n",
    "            from sklearn.metrics import classification_report\n",
    "            _, _ , all_y_test,all_y_pred_test = test_model(model, test_loader, criterion = nn.CrossEntropyLoss(), classes = classes ,device=device, call = \"test\")\n",
    "            # at times output is not getting printed. Could be due to multi threading and hence adding sleep\n",
    "            time.sleep(2)\n",
    "            sys.stdout.flush()\n",
    "            print(classification_report(all_y_test.numpy(), all_y_pred_test.numpy(), target_names= classes))\n",
    "            print(\"********************************\")\n",
    "            time.sleep(2)\n",
    "            plot_confusion_matrix(all_y_pred_test.numpy(), all_y_test.numpy() , classes)\n",
    "            best_epoch = e\n",
    "            best_val_f1 = val_f1\n",
    "            best_val_loss = val_loss\n",
    "            \n",
    "        else:\n",
    "            print(\"..Overrun....no improvement\")\n",
    "            overrun_counter += 1\n",
    "            sys.stdout.flush()\n",
    "            print('Epoch: %d, Train Loss: %.8f, Train f1: %.8f, Val Loss: %.8f, Val f1: %.8f, overrun_counter %i' % (e, train_loss/len(train_loader), train_f1, val_loss/len(val_loader), val_f1,  overrun_counter))\n",
    "        if overrun_counter > config_pytorch.max_overrun:\n",
    "            break\n",
    "            \n",
    "    \n",
    "    return model, lr_log,all_train_f1,all_train_loss,all_val_loss,all_val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bbd148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd1f9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the function for loading the dataset\n",
    "def load_dataset(file_list, label_list, batch_size=batch_size):\n",
    "    dataset = AudioDataset(file_list, label_list)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True,num_workers = num_workers , drop_last = True)\n",
    "    return dataloader\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9c0d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_mean(x_temp,rate = config.rate, min_length = config.min_duration ):\n",
    "    if DEBUG:\n",
    "        print(\"inside padding mean...\")\n",
    "    x_mean = torch.mean(x_temp)\n",
    "    #x_mean.cuda()\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"X_mean = \" + str(x_mean))\n",
    "    left_pad_amt = int((rate*min_length-x_temp.shape[1])//2)\n",
    "    if DEBUG:\n",
    "        print(\"left_pad_amt = \" + str(left_pad_amt))\n",
    "    left_pad = torch.zeros(1,left_pad_amt) #+ (0.1**0.5)*torch.randn(1, left_pad_amt)\n",
    "    if DEBUG:\n",
    "        print(\"left_pad shape = \" + str(left_pad.shape))\n",
    "    left_pad_mean_add = left_pad + x_mean\n",
    "    if DEBUG:\n",
    "        print(\"left_pad_mean shape = \" + str(left_pad_mean_add))\n",
    "        print(\"sum of left pad mean add = \" + str(torch.sum(left_pad_mean_add)))\n",
    "    \n",
    "    right_pad_amt = int(rate*min_length-x_temp.shape[1]-left_pad_amt)\n",
    "    right_pad = torch.zeros(1,right_pad_amt)# + (0.1**0.5)*torch.randn(1, right_pad_amt)\n",
    "    if DEBUG:\n",
    "        print(\"right_pad shape = \" + str(right_pad.shape))\n",
    "    right_pad_mean_add = right_pad + x_mean\n",
    "    if DEBUG:\n",
    "        print(\"right_pad_mean shape = \" + str(right_pad_mean_add))\n",
    "        print(\"sum of right pad mean add = \"  + str(torch.sum(right_pad_mean_add)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    f = torch.cat([left_pad,x_temp,right_pad],dim=1)[0]\n",
    "    f = f.unsqueeze(dim = 0)\n",
    "    #print(\"returning a tensor of shape = \" + str(f.shape))\n",
    "    return(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fba65c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class ApplyAug(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.aug_flag_y = transforms.Compose([\n",
    "            transforms.GaussianBlur(3),\n",
    "            transforms.RandomErasing(),\n",
    "            transforms.Normalize(mean=2.7360104e-05, std=.0061507192)\n",
    "        ])\n",
    "        self.aug_flag_n = transforms.Compose([\n",
    "            transforms.Normalize(mean=2.7360104e-05, std=.0061507192)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, spec_gram, aug_flag):\n",
    "        if aug_flag == \"Y\":\n",
    "            rgb_img_auto_aug = self.aug_flag_y(spec_gram)\n",
    "            return rgb_img_auto_aug\n",
    "        else:\n",
    "            img_tensor = self.aug_flag_n(spec_gram)\n",
    "            return img_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa678e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, file_list,label_list):\n",
    "        self.file_list = file_list\n",
    "        self.label_list = label_list\n",
    "        \n",
    "        \n",
    "        #self.labels = labels\n",
    "        #processor = processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-conformer-rope-large-960h-ft\")\n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        config.rate = 8000\n",
    "        min_duration = 1.92\n",
    "        file_path, start , end = self.file_list[index]\n",
    "        \n",
    "        #file_path = self.file_list[index]\n",
    "        label = self.label_list[index]\n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"file_path = \", file_path)\n",
    "            #print(\"start = \", start)\n",
    "            #print(\"end = \", end)\n",
    "        entire_aud, sample_rate = torchaudio.load(file_path)\n",
    "        if sample_rate != config.rate:\n",
    "            if DEBUG:\n",
    "                print(\"file_path = \" + str(file_path) + \" Original sample rate = \" +str(sample_rate)+ \" resampling ...\")\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(sample_rate, config.rate, dtype=entire_aud.dtype)\n",
    "            entire_aud = resampler(entire_aud)\n",
    "            if DEBUG:\n",
    "                print(\"Aud  shape post resampling = \", entire_aud.shape)\n",
    "        \n",
    "        \n",
    "        waveform = entire_aud[:,start:end]\n",
    "        if waveform.shape[1] < config.rate*min_duration:\n",
    "            waveform = pad_mean(waveform)\n",
    "            \n",
    "        waveform.to('cuda')\n",
    "        #print(\"after loading . Wavform shape = \" , waveform.shape)\n",
    "              \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        #generate spectrogram\n",
    "                  \n",
    "        label = self.label_list[index]\n",
    "        return waveform.squeeze(), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d9a3ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35043"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c43e22bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e51a5ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(num_values ,label_list ,classes = classes):\n",
    "    new_list = []\n",
    "    for ind in range(len(classes)):\n",
    "        #print(\"ind = \", ind)\n",
    "        op = [indx for indx,elem in enumerate(label_list) if label_list[indx] == ind ]\n",
    "        #print(\"len op = \", len(op))\n",
    "        rand_ind = int(np.random.randint(0,len(op)))\n",
    "        print(\"rand_ind = \" , rand_ind)\n",
    "        elem = op[rand_ind]\n",
    "        print(\"elem = \" , elem)\n",
    "        new_list.append(elem)\n",
    "    if len(new_list) < num_values:\n",
    "        diff =  num_values - len(new_list)\n",
    "        #print(\"diff = \", diff)\n",
    "        remaining_elems= [indx for indx,elem in enumerate(label_list)][:diff]\n",
    "        #print(\"len of remaining elems = \", len(remaining_elems))\n",
    "        new_list = remaining_elems + new_list\n",
    "    print(\"new_list = \", new_list)    \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "662306be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    #randomly select 10 rows\n",
    "    #nums_tr = list(np.random.randint(0,20000,10))\n",
    "    #nums_val = list(np.random.randint(0,4000,6))\n",
    "    #nums_test = list(np.random.randint(0,5000,7))\n",
    "    nums_tr = get_indices(12 , label_list_train , classes)\n",
    "    nums_val =  get_indices(8 , label_list_val , classes)\n",
    "    nums_test = get_indices(8 , label_list_test , classes)\n",
    "    \n",
    "    print(\"inside DEBUG for dataset creation..\" + \" nums_tr = \" + str(nums_tr))\n",
    "    print(\"inside DEBUG for dataset creation..\" + \" nums_val = \" + str(nums_val))\n",
    "    print(\"inside DEBUG for dataset creation..\" + \" nums_test = \" + str(nums_test))\n",
    "    \n",
    "    file_list_train = [file_list_train[x] for x in nums_tr ]\n",
    "    label_list_train = [label_list_train[x] for x in nums_tr]\n",
    "    \n",
    "        \n",
    "    file_list_val = [file_list_val[x] for x in nums_val]\n",
    "    label_list_val = [label_list_val[x] for x in nums_val]\n",
    "    \n",
    "    file_list_test = [file_list_test[x] for x in nums_test]\n",
    "    label_list_test = [label_list_test[x] for x in nums_test]\n",
    "    \n",
    "    train_loader = load_dataset(file_list_train,label_list_train,batch_size=batch_size)\n",
    "    val_loader = load_dataset(file_list_val,label_list_val, batch_size=batch_size)\n",
    "    test_loader = load_dataset(file_list_test,label_list_test ,batch_size=batch_size)\n",
    "    print(\"inside DEBUG for dataset creation..\" + \" len of train_loader = \" + str(len(train_loader)))\n",
    "    print(\"inside DEBUG for dataset creation..\" + \" len of val_loader = \" + str(len(val_loader)))\n",
    "    print(\"inside DEBUG for dataset creation..\" + \" len of test_loader = \" + str(len(test_loader)))\n",
    "    \n",
    "    \n",
    "    \n",
    "else:\n",
    "        train_loader = load_dataset(file_list_train,label_list_train, batch_size=batch_size)\n",
    "        val_loader = load_dataset(file_list_val,label_list_val ,batch_size=batch_size)\n",
    "        test_loader = load_dataset(file_list_test,label_list_test, batch_size=batch_size)\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f352d3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508fda40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d961a37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65fe56a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/convnextv2-large-22k-384 were not used when initializing ConvNextV2ForImageClassification: ['convnextv2.encoder.stages.2.layers.6.grn.weight', 'convnextv2.encoder.stages.2.layers.4.grn.weight', 'convnextv2.encoder.stages.2.layers.17.grn.bias', 'convnextv2.encoder.stages.2.layers.2.grn.weight', 'convnextv2.encoder.stages.2.layers.15.grn.bias', 'convnextv2.encoder.stages.1.layers.1.grn.weight', 'convnextv2.encoder.stages.2.layers.14.grn.weight', 'convnextv2.encoder.stages.2.layers.14.grn.bias', 'convnextv2.encoder.stages.2.layers.3.grn.bias', 'convnextv2.encoder.stages.2.layers.1.grn.weight', 'convnextv2.encoder.stages.0.layers.2.grn.bias', 'convnextv2.encoder.stages.2.layers.25.grn.weight', 'convnextv2.encoder.stages.2.layers.10.grn.weight', 'convnextv2.encoder.stages.2.layers.26.grn.bias', 'convnextv2.encoder.stages.0.layers.1.grn.bias', 'convnextv2.encoder.stages.1.layers.2.grn.weight', 'convnextv2.encoder.stages.3.layers.0.grn.bias', 'convnextv2.encoder.stages.2.layers.0.grn.weight', 'convnextv2.encoder.stages.2.layers.11.grn.weight', 'convnextv2.encoder.stages.2.layers.6.grn.bias', 'convnextv2.encoder.stages.2.layers.20.grn.bias', 'convnextv2.encoder.stages.3.layers.2.grn.weight', 'convnextv2.encoder.stages.2.layers.3.grn.weight', 'convnextv2.encoder.stages.2.layers.9.grn.bias', 'convnextv2.encoder.stages.2.layers.18.grn.weight', 'convnextv2.encoder.stages.2.layers.16.grn.weight', 'convnextv2.encoder.stages.2.layers.22.grn.weight', 'convnextv2.encoder.stages.3.layers.1.grn.bias', 'convnextv2.encoder.stages.2.layers.22.grn.bias', 'convnextv2.encoder.stages.2.layers.24.grn.weight', 'convnextv2.encoder.stages.2.layers.17.grn.weight', 'convnextv2.encoder.stages.2.layers.13.grn.weight', 'convnextv2.encoder.stages.2.layers.9.grn.weight', 'convnextv2.encoder.stages.0.layers.0.grn.weight', 'convnextv2.encoder.stages.2.layers.8.grn.bias', 'convnextv2.encoder.stages.2.layers.20.grn.weight', 'convnextv2.encoder.stages.0.layers.2.grn.weight', 'convnextv2.encoder.stages.2.layers.18.grn.bias', 'convnextv2.encoder.stages.2.layers.19.grn.bias', 'convnextv2.encoder.stages.2.layers.13.grn.bias', 'convnextv2.encoder.stages.2.layers.16.grn.bias', 'convnextv2.encoder.stages.1.layers.2.grn.bias', 'convnextv2.encoder.stages.2.layers.2.grn.bias', 'convnextv2.encoder.stages.0.layers.0.grn.bias', 'convnextv2.encoder.stages.2.layers.1.grn.bias', 'convnextv2.encoder.stages.1.layers.0.grn.weight', 'convnextv2.encoder.stages.2.layers.24.grn.bias', 'convnextv2.encoder.stages.2.layers.0.grn.bias', 'convnextv2.encoder.stages.2.layers.7.grn.bias', 'convnextv2.encoder.stages.2.layers.5.grn.bias', 'convnextv2.encoder.stages.2.layers.15.grn.weight', 'convnextv2.encoder.stages.2.layers.4.grn.bias', 'convnextv2.encoder.stages.2.layers.12.grn.bias', 'convnextv2.encoder.stages.2.layers.10.grn.bias', 'convnextv2.encoder.stages.2.layers.23.grn.weight', 'convnextv2.encoder.stages.0.layers.1.grn.weight', 'convnextv2.encoder.stages.2.layers.21.grn.weight', 'convnextv2.encoder.stages.3.layers.1.grn.weight', 'convnextv2.encoder.stages.2.layers.26.grn.weight', 'convnextv2.encoder.stages.2.layers.23.grn.bias', 'convnextv2.encoder.stages.2.layers.25.grn.bias', 'convnextv2.encoder.stages.2.layers.8.grn.weight', 'convnextv2.encoder.stages.2.layers.11.grn.bias', 'convnextv2.encoder.stages.2.layers.12.grn.weight', 'convnextv2.encoder.stages.2.layers.19.grn.weight', 'convnextv2.encoder.stages.3.layers.2.grn.bias', 'convnextv2.encoder.stages.2.layers.7.grn.weight', 'convnextv2.encoder.stages.3.layers.0.grn.weight', 'convnextv2.encoder.stages.2.layers.5.grn.weight', 'convnextv2.encoder.stages.1.layers.1.grn.bias', 'convnextv2.encoder.stages.1.layers.0.grn.bias', 'convnextv2.encoder.stages.2.layers.21.grn.bias']\n",
      "- This IS expected if you are initializing ConvNextV2ForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ConvNextV2ForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ConvNextV2ForImageClassification were not initialized from the model checkpoint at facebook/convnextv2-large-22k-384 and are newly initialized: ['convnextv2.encoder.stages.2.layers.22.grn.gamma', 'convnextv2.encoder.stages.2.layers.10.grn.beta', 'convnextv2.encoder.stages.2.layers.10.grn.gamma', 'convnextv2.encoder.stages.2.layers.1.grn.beta', 'convnextv2.encoder.stages.2.layers.25.grn.gamma', 'convnextv2.encoder.stages.2.layers.18.grn.beta', 'convnextv2.encoder.stages.2.layers.23.grn.gamma', 'convnextv2.encoder.stages.3.layers.0.grn.gamma', 'convnextv2.encoder.stages.2.layers.26.grn.gamma', 'convnextv2.encoder.stages.3.layers.0.grn.beta', 'convnextv2.encoder.stages.2.layers.8.grn.beta', 'convnextv2.encoder.stages.2.layers.19.grn.gamma', 'convnextv2.encoder.stages.2.layers.5.grn.gamma', 'convnextv2.encoder.stages.3.layers.1.grn.beta', 'convnextv2.encoder.stages.2.layers.26.grn.beta', 'convnextv2.encoder.stages.2.layers.2.grn.beta', 'convnextv2.encoder.stages.2.layers.13.grn.beta', 'convnextv2.encoder.stages.2.layers.16.grn.gamma', 'convnextv2.encoder.stages.2.layers.21.grn.gamma', 'convnextv2.encoder.stages.2.layers.13.grn.gamma', 'convnextv2.encoder.stages.2.layers.22.grn.beta', 'convnextv2.encoder.stages.1.layers.0.grn.gamma', 'convnextv2.encoder.stages.2.layers.1.grn.gamma', 'convnextv2.encoder.stages.2.layers.5.grn.beta', 'convnextv2.encoder.stages.2.layers.6.grn.beta', 'convnextv2.encoder.stages.2.layers.16.grn.beta', 'convnextv2.encoder.stages.2.layers.3.grn.beta', 'convnextv2.encoder.stages.2.layers.0.grn.gamma', 'convnextv2.encoder.stages.2.layers.24.grn.gamma', 'convnextv2.encoder.stages.3.layers.2.grn.gamma', 'convnextv2.encoder.stages.2.layers.7.grn.gamma', 'convnextv2.encoder.stages.1.layers.2.grn.gamma', 'convnextv2.encoder.stages.2.layers.15.grn.gamma', 'convnextv2.encoder.stages.2.layers.12.grn.gamma', 'convnextv2.encoder.stages.2.layers.2.grn.gamma', 'convnextv2.encoder.stages.1.layers.0.grn.beta', 'convnextv2.encoder.stages.2.layers.7.grn.beta', 'convnextv2.encoder.stages.2.layers.14.grn.beta', 'convnextv2.encoder.stages.1.layers.1.grn.beta', 'convnextv2.encoder.stages.2.layers.11.grn.gamma', 'convnextv2.encoder.stages.1.layers.1.grn.gamma', 'convnextv2.encoder.stages.2.layers.9.grn.gamma', 'convnextv2.encoder.stages.1.layers.2.grn.beta', 'convnextv2.encoder.stages.0.layers.1.grn.gamma', 'convnextv2.encoder.stages.2.layers.14.grn.gamma', 'convnextv2.encoder.stages.2.layers.8.grn.gamma', 'convnextv2.encoder.stages.2.layers.4.grn.gamma', 'convnextv2.encoder.stages.2.layers.3.grn.gamma', 'convnextv2.encoder.stages.2.layers.12.grn.beta', 'convnextv2.encoder.stages.2.layers.18.grn.gamma', 'convnextv2.encoder.stages.2.layers.11.grn.beta', 'convnextv2.encoder.stages.0.layers.1.grn.beta', 'convnextv2.encoder.stages.0.layers.2.grn.gamma', 'convnextv2.encoder.stages.2.layers.21.grn.beta', 'convnextv2.encoder.stages.2.layers.23.grn.beta', 'convnextv2.encoder.stages.2.layers.24.grn.beta', 'convnextv2.encoder.stages.2.layers.9.grn.beta', 'convnextv2.encoder.stages.0.layers.0.grn.gamma', 'convnextv2.encoder.stages.3.layers.2.grn.beta', 'convnextv2.encoder.stages.2.layers.17.grn.beta', 'convnextv2.encoder.stages.0.layers.0.grn.beta', 'convnextv2.encoder.stages.2.layers.6.grn.gamma', 'convnextv2.encoder.stages.2.layers.0.grn.beta', 'convnextv2.encoder.stages.2.layers.25.grn.beta', 'convnextv2.encoder.stages.2.layers.15.grn.beta', 'convnextv2.encoder.stages.2.layers.20.grn.gamma', 'convnextv2.encoder.stages.2.layers.4.grn.beta', 'convnextv2.encoder.stages.2.layers.19.grn.beta', 'convnextv2.encoder.stages.0.layers.2.grn.beta', 'convnextv2.encoder.stages.2.layers.17.grn.gamma', 'convnextv2.encoder.stages.3.layers.1.grn.gamma', 'convnextv2.encoder.stages.2.layers.20.grn.beta']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pre_tr_model =   ConvNextV2ForImageClassification.from_pretrained(\"facebook/convnextv2-large-22k-384\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82411854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, pre_tr_model ,input_size = 4, hidden_size = 768 , num_classes = 8 , image_size = 384 , batch_size = batch_size):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.backbone = pre_tr_model\n",
    "        self.spec_layer = features.STFT(n_fft=int(config.NFFT), freq_bins=None, hop_length=int(config.n_hop),\n",
    "                              window='hann', freq_scale='linear', center=True, pad_mode='reflect',\n",
    "                           sr=config.rate, output_format=\"Magnitude\", trainable=False,verbose = False)\n",
    "        #self.linear = nn.Linear(hidden_size , 1024)\n",
    "        self.output = nn.Linear(1000, num_classes)\n",
    "        self.sizer = VT.Resize((image_size,image_size))\n",
    "        self.aug_layer = ApplyAug()\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, input_ids,train = True ,attention_mask = False):\n",
    "        #this will hold the output\n",
    "        output_dict = {'probs':None , 'preds':None}\n",
    "        spec_gram = self.spec_layer(input_ids)\n",
    "        if train== True:\n",
    "            #apply_aug\n",
    "            rand_aug_choice = torch.randint(low=0, high=10, size=(1,1),device = 'cuda',dtype=torch.int32)\n",
    "            #print(\"rand_aug_choice = \",rand_aug_choice)\n",
    "            if rand_aug_choice %2 == 0 :\n",
    "                spec_gram = self.aug_layer(spec_gram , aug_flag = \"Y\")\n",
    "                #print(\"called aug with flag Y and shape post application = \" , spec_gram.shape)\n",
    "            spec_gram = self.aug_layer(spec_gram , aug_flag = \"N\")\n",
    "            #print(\"called aug with flag N and shape post application = \" , spec_gram.shape)\n",
    "        # now reshape to image_size\n",
    "        spec_gram = spec_gram.view(batch_size,1,-1)\n",
    "        spec_gram = self.sizer(spec_gram)\n",
    "        spec_gram = spec_gram.unsqueeze(dim = 1)\n",
    "        \n",
    "        #print(\"post sizer shape of spec_gram = \" , spec_gram.shape)\n",
    "        #now make it 3 channel \n",
    "        spec_gram = torch.cat((spec_gram, spec_gram, spec_gram), dim=1).to('cuda')\n",
    "        #print(\"post 3 channel shape of spec_gram = \" , spec_gram.shape)\n",
    "                \n",
    "        backbone_op = self.backbone(spec_gram)\n",
    "        #print(\"backbone_op shape \",backbone_op.logits.shape)\n",
    "        #linear_output = self.linear(backbone_op_reshp)\n",
    "        #print(linear_output.shape)\n",
    "        output = self.output(backbone_op['logits'])\n",
    "        #print(output)\n",
    "        #print(\"output shape = \" , output.shape)\n",
    "        out_smax = self.softmax(output)\n",
    "        out = torch.argmax(out_smax , dim = 1)\n",
    "        #print(\"out = \",out)\n",
    "        \n",
    "        output_dict['probs'] = out_smax\n",
    "        output_dict['preds'] = out\n",
    "        #print(\"^^^^^ inside forward^^^^^^^\")\n",
    "        #print(\"output_dict = \", output_dict)\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a56f86ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_t = torch.rand(4,2787)\n",
    "# x_t = x_t.view(4, 1, -1)\n",
    "# import torchvision.transforms as VT\n",
    "# sizer = VT.Resize((384,384))\n",
    "# x_t1 = sizer(x_t)\n",
    "# print(x_t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "366dd6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012431144714355469,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "epoc loop",
       "rate": null,
       "total": 400,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ce7cd0f9944d1b8ff2d9d33dbadf62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoc loop:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0batch = 0 of 2190duraation = 0.00606925884882609\n",
      "rand_aug_choice =  tensor([[1]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[4]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[3]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[5]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[4]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[5]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[0]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[5]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[0]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[2]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[6]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[4]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[0]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[3]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[4]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[9]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[3]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[7]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[0]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[7]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[1]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[0]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[6]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[8]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[6]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[3]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[5]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[6]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[2]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[6]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[8]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag Y and shape post application =  torch.Size([16, 1025, 31])\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[7]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[3]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[7]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[1]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[1]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n",
      "rand_aug_choice =  tensor([[7]], device='cuda:0', dtype=torch.int32)\n",
      "called aug with flag N and shape post application =  torch.Size([16, 1025, 31])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-987d6a2be46d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_tr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_tr_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_log\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_train_f1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_train_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_val_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_val_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_new\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-a8cd69b9f1b4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, val_loader, test_loader, model, classes, class_weights, num_epochs, n_channels)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;31m#train_loss += loss.item()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mall_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;31m#y_pred_cpu = preds.cpu().detach()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;31m#all_y_pred.append(preds.cpu().detach())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_new = MyModel(pre_tr_model = pre_tr_model)\n",
    "\n",
    "tr_model, lr_log,all_train_f1,all_train_loss,all_val_loss,all_val_f1 = train_model(train_loader,val_loader,test_loader,model_new ,classes = classes,class_weights = class_weights,num_epochs = num_epochs ,n_channels = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d942fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = \"./../data/audio/221208.wav\"\n",
    "\n",
    "t_list = []\n",
    "for i in range(0,10):\n",
    "    #print(i)\n",
    "    st = np.random.randint(1,50000)\n",
    "    en = np.random.randint(1,50000)\n",
    "    tup = (p1,st,en)\n",
    "    t_list.append(tup)\n",
    "    \n",
    "\n",
    "\n",
    "p,st,en = t_list[0]\n",
    "print(p , st , en)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5028cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(1,5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c29ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f2591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cba36e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f091c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed28da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee61862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfabb886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c8c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdce6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd97c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92327c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916e6de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e528d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb70ad22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8d11f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8f4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d84e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dadb92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ed2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990588c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
