{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd1d1aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.21.4)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.5.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (4.28.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (9.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (3.0.6)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (6.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (59.4.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (1.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f05e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Troubleshooting and visualisation\n",
    "import IPython.display as ipd\n",
    "from transformers import AutoProcessor, Wav2Vec2ConformerForCTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9eb0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "039a15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional pytorch tools\n",
    "import random\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torchvision.transforms as VT\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d248ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nnAudio\n",
    "from nnAudio import features\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90eaa2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hugging face\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ConformerForCTC\n",
    "from transformers import Wav2Vec2ConformerForSequenceClassification, Wav2Vec2Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e9a9f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# humbug lib imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "#from PyTorch import config_pytorch\n",
    "from datetime import datetime\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77ae5cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../../src'))\n",
    "import config ,config_pytorch\n",
    "from evaluate import get_results\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea65aa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/task/ComParE2022_VecNet/notebooks/DK\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad707e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Training variables \n",
    "import torch.multiprocessing as mp\n",
    "#\n",
    "\n",
    "#pool.map(worker_fn, range(4))\n",
    "USE_SHORT_AUDIO = True\n",
    "num_workers= 0\n",
    "pin_memory=True\n",
    "#train_size = 100\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "num_epochs = 200\n",
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    batch_size = 4\n",
    "    test_batch_size = 4\n",
    "    num_workers=0\n",
    "    num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b71c8",
   "metadata": {},
   "source": [
    "### Let's get the data in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a7c49c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates 1.92 secs rows of audio in a data frame format\n",
    "# This function creates 1.92 secs rows of audio in a data frame format\n",
    "def get_offsets_df(df, short_audio=False):\n",
    "    audio_offsets = []\n",
    "    #This is same as defined in config -min_duration = win_size * frame_duration\n",
    "    min_length = config.win_size*config.NFFT/(((1/config.n_hop)*config.NFFT)*config.rate)\n",
    "    step_frac = config.step_size/config.win_size\n",
    "    stride = step_frac*min_length\n",
    "#     print(\"min_length = \" +str(min_length))\n",
    "#     print(\"step_frac = \" +str(step_frac))\n",
    "#     print(\"stride = \" +str(stride))\n",
    "    for _,row in df.iterrows():\n",
    "        #processed_data keeps track of the tensor_values processed thus far\n",
    "        if row['length'] > min_length:\n",
    "            processed_data = 0\n",
    "            #total_data is the total tensor present in the audio\n",
    "            total_data = config.rate*row['length']\n",
    "            #print(\"********\")\n",
    "            count = 0\n",
    "#             print(\"count = \" +str(count))\n",
    "#             print(\"id = \" + str(row['id']) + \" duration = \" +str(row['length']) + \"total x vals = \" + str(total_data))\n",
    "            inner_loop_flag = False\n",
    "            #print(\"going into the inner loop to offset....\")\n",
    "            while(processed_data < total_data):\n",
    "                #print(\"inside inner loop.....\")\n",
    "                start = count*stride*config.rate\n",
    "                #now find out the row_len\n",
    "                if total_data - (start + min_length*config.rate) >= 0:\n",
    "                    #print(\"full chunk \")\n",
    "                    row_len = min_length\n",
    "                    end = start + row_len*config.rate\n",
    "                    audio_offsets.append({'id':row['id'], 'offset':count, 'length': row_len,'specie_ind': row['specie_ind'],'start':start,'end':end})\n",
    "                    #print(\"count = \" +str(count) + \"offset = \" +str(count) + \"start = \" +str(start) + \"end = \" +str(end))\n",
    "                    #print(\"for count.... = \" + str(count) + \"processed data = \" +str(processed_data))\n",
    "                    count+=1\n",
    "                    processed_data = (count*stride)*config.rate\n",
    "                    \n",
    "                else:\n",
    "                    inner_loop_flag = True\n",
    "                    break\n",
    "                    \n",
    "                                                       \n",
    "            #for processing residual data\n",
    "            if(inner_loop_flag):\n",
    "                #print(\"processing residual ....processed \" +str(processed_data) + \" of \" + str(total_data))\n",
    "                start = count*stride*config.rate\n",
    "                resid_durn = round((total_data - processed_data)/config.rate,2)\n",
    "                end = total_data\n",
    "                #print(\"for...\" + str(row['id']) + \" adding the residual data in the data frame with duration = \" + str(resid_durn))\n",
    "                audio_offsets.append({'id':row['id'], 'offset':count, 'length':resid_durn ,'specie_ind': row['specie_ind'],'start':start,'end':end})\n",
    "            \n",
    "        elif short_audio:\n",
    "            start = 0\n",
    "            end = row['length']*config.rate\n",
    "            audio_offsets.append({'id':row['id'], 'offset':0,'length': row['length'],'specie_ind': row['specie_ind'],'start':0 , 'end':end})\n",
    "    return pd.DataFrame(audio_offsets)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c00f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['an arabiensis','culex pipiens complex', 'ae aegypti','an funestus ss','an squamosus',\n",
    "               'an coustani','ma uniformis','ma africanus' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69209e2",
   "metadata": {},
   "source": [
    "### Read CSV and get train/test groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f0805fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>name</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>record_datetime</th>\n",
       "      <th>sound_type</th>\n",
       "      <th>species</th>\n",
       "      <th>gender</th>\n",
       "      <th>fed</th>\n",
       "      <th>plurality</th>\n",
       "      <th>age</th>\n",
       "      <th>method</th>\n",
       "      <th>mic_type</th>\n",
       "      <th>device_type</th>\n",
       "      <th>country</th>\n",
       "      <th>district</th>\n",
       "      <th>province</th>\n",
       "      <th>place</th>\n",
       "      <th>location_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>0.463456</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>0.170249</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>0.104041</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>0.274290</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56</td>\n",
       "      <td>0.420894</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>3562</td>\n",
       "      <td>6.083093</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000</th>\n",
       "      <td>3556</td>\n",
       "      <td>6.719908</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an maculatus</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9009</th>\n",
       "      <td>3553</td>\n",
       "      <td>6.128580</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an maculatus</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9011</th>\n",
       "      <td>3561</td>\n",
       "      <td>11.614280</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9012</th>\n",
       "      <td>3552</td>\n",
       "      <td>2.920249</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6008 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     length                             name  sample_rate  \\\n",
       "1       53   0.463456  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "2       57   0.170249  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "3       61   0.104041  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "4       69   0.274290  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "5       56   0.420894  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "...    ...        ...                              ...          ...   \n",
       "8999  3562   6.083093                    #988-1001.wav        44100   \n",
       "9000  3556   6.719908                    #988-1001.wav        44100   \n",
       "9009  3553   6.128580                    #988-1001.wav        44100   \n",
       "9011  3561  11.614280                    #988-1001.wav        44100   \n",
       "9012  3552   2.920249                    #988-1001.wav        44100   \n",
       "\n",
       "     record_datetime sound_type       species  gender  fed plurality  age  \\\n",
       "1      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "2      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "3      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "4      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "5      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Plural  NaN   \n",
       "...              ...        ...           ...     ...  ...       ...  ...   \n",
       "8999  1/7/2018 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "9000  1/7/2018 12:00   mosquito  an maculatus  Female    t    Single  NaN   \n",
       "9009  1/7/2018 12:00   mosquito  an maculatus  Female    t    Single  NaN   \n",
       "9011  1/7/2018 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "9012  1/7/2018 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "\n",
       "     method mic_type    device_type   country          district  \\\n",
       "1       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "2       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "3       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "4       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "5       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "...     ...      ...            ...       ...               ...   \n",
       "8999    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9000    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9009    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9011    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9012    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "\n",
       "                   province                            place location_type  \n",
       "1                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "2                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "3                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "4                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "5                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "...                     ...                              ...           ...  \n",
       "8999  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9000  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9009  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9011  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9012  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "\n",
       "[6008 rows x 19 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if DEBUG:\n",
    "#     df = pd.read_csv(config.data_df_msc_test)\n",
    "# else:\n",
    "df = pd.read_csv(config.data_df)\n",
    "\n",
    "#df = df.loc[df['Grade'].notnull()]\n",
    "df = df.loc[df['species'].notnull()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "608683c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a colum for specie encoding\n",
    "df['specie_ind'] = \"NULL_VAL\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31ebd8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specie = an arabiensisand its index = 0\n",
      "specie = culex pipiens complexand its index = 1\n",
      "specie = ae aegyptiand its index = 2\n",
      "specie = an funestus ssand its index = 3\n",
      "specie = an squamosusand its index = 4\n",
      "specie = an coustaniand its index = 5\n",
      "specie = ma uniformisand its index = 6\n",
      "specie = ma africanusand its index = 7\n"
     ]
    }
   ],
   "source": [
    "# Adding a new column to encode specie_index in the same order as the list \"classes\"\n",
    "ind = 0\n",
    "for specie in classes:\n",
    "    print(\"specie = \" + str(specie) + \"and its index = \" + str(ind) )\n",
    "    row_indexes=df[df['species']==specie].index \n",
    "    df.loc[row_indexes,'specie_ind']= ind\n",
    "    ind+=1\n",
    "\n",
    "    \n",
    "# other_df_ind = df[df['specie_ind'] == \"NULL_VAL\"].index\n",
    "# df.loc[other_df_ind,'specie_ind']= other_ind                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9763a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['specie_ind'] == \"NULL_VAL\"].index, inplace=True)\n",
    "#other_df_ind = df[df['specie_ind'] == \"NULL_VAL\"].index\n",
    "#df.loc[other_df_ind,'specie_ind']= other_ind        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92126396",
   "metadata": {},
   "source": [
    "At this stage we have all extracted the data with specie information and have encoded the specie encoding in a col = 'specie_ind'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62a1e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the TZ and Cup data- this is as per the humbug paper\n",
    "\n",
    "idx_multiclass = np.logical_and(df['country'] == 'Tanzania', df['location_type'] == 'cup')\n",
    "df_all = df[idx_multiclass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99b7f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07e81baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>name</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>record_datetime</th>\n",
       "      <th>sound_type</th>\n",
       "      <th>species</th>\n",
       "      <th>gender</th>\n",
       "      <th>fed</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>method</th>\n",
       "      <th>mic_type</th>\n",
       "      <th>device_type</th>\n",
       "      <th>country</th>\n",
       "      <th>district</th>\n",
       "      <th>province</th>\n",
       "      <th>place</th>\n",
       "      <th>location_type</th>\n",
       "      <th>specie_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1879</td>\n",
       "      <td>221103</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_24_664.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1880</td>\n",
       "      <td>221111</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_25_665.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1881</td>\n",
       "      <td>221110</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_25_665.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1882</td>\n",
       "      <td>221149</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_26_666.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an arabiensis</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1883</td>\n",
       "      <td>221150</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_26_666.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an arabiensis</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>4546</td>\n",
       "      <td>222615</td>\n",
       "      <td>30.72</td>\n",
       "      <td>IFA_86_39_3439.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>4547</td>\n",
       "      <td>222585</td>\n",
       "      <td>25.60</td>\n",
       "      <td>IFA_86_40_3440.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>4548</td>\n",
       "      <td>222586</td>\n",
       "      <td>40.90</td>\n",
       "      <td>IFA_87_10_3450.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>4549</td>\n",
       "      <td>222596</td>\n",
       "      <td>40.90</td>\n",
       "      <td>IFA_87_11_3451.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>4550</td>\n",
       "      <td>222614</td>\n",
       "      <td>38.40</td>\n",
       "      <td>IFA_87_12_3452.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2288 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      id  length                name  sample_rate record_datetime  \\\n",
       "0      1879  221103    2.56   IFA_17_24_664.wav        44100  30-01-20 00:00   \n",
       "1      1880  221111    2.56   IFA_17_25_665.wav        44100  30-01-20 00:00   \n",
       "2      1881  221110    2.56   IFA_17_25_665.wav        44100  30-01-20 00:00   \n",
       "3      1882  221149    2.56   IFA_17_26_666.wav        44100  30-01-20 00:00   \n",
       "4      1883  221150    2.56   IFA_17_26_666.wav        44100  30-01-20 00:00   \n",
       "...     ...     ...     ...                 ...          ...             ...   \n",
       "2283   4546  222615   30.72  IFA_86_39_3439.wav        44100  23-08-20 00:00   \n",
       "2284   4547  222585   25.60  IFA_86_40_3440.wav        44100  23-08-20 00:00   \n",
       "2285   4548  222586   40.90  IFA_87_10_3450.wav        44100  23-08-20 00:00   \n",
       "2286   4549  222596   40.90  IFA_87_11_3451.wav        44100  23-08-20 00:00   \n",
       "2287   4550  222614   38.40  IFA_87_12_3452.wav        44100  23-08-20 00:00   \n",
       "\n",
       "     sound_type         species  gender fed  ... age  method mic_type  \\\n",
       "0      mosquito    ma africanus  Female   f  ... NaN     HBN  telinga   \n",
       "1      mosquito    ma africanus  Female   f  ... NaN     HBN  telinga   \n",
       "2      mosquito    ma africanus  Female   f  ... NaN     HBN  telinga   \n",
       "3      mosquito   an arabiensis  Female   f  ... NaN     HBN  telinga   \n",
       "4      mosquito   an arabiensis  Female   f  ... NaN     HBN  telinga   \n",
       "...         ...             ...     ...  ..  ...  ..     ...      ...   \n",
       "2283   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2284   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2285   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2286   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2287   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "\n",
       "     device_type   country            district  province    place  \\\n",
       "0         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "1         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "3         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "4         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "...          ...       ...                 ...       ...      ...   \n",
       "2283      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2284      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2285      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2286      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2287      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "\n",
       "     location_type specie_ind  \n",
       "0              cup          7  \n",
       "1              cup          7  \n",
       "2              cup          7  \n",
       "3              cup          0  \n",
       "4              cup          0  \n",
       "...            ...        ...  \n",
       "2283           cup          3  \n",
       "2284           cup          3  \n",
       "2285           cup          3  \n",
       "2286           cup          3  \n",
       "2287           cup          3  \n",
       "\n",
       "[2288 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ffa6c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "import seaborn as sns\n",
    "sns.countplot(x = 'species', data = df_all , ax = ax , hue = 'gender',palette='dark')\n",
    "#ax.bar_label(ax.containers[0])\n",
    "#ax.bar_label(ax.containers[-1], fmt='Count:\\n%.2f', label_type='center')\n",
    "plt.xticks(rotation=90 )\n",
    "plt.title(\"Distribution of Species \")\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('axes', labelsize=15)\n",
    "plt.rc('figure', titlesize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f87ab8",
   "metadata": {},
   "source": [
    "### Train-Test split( avoiding sklearn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df0173ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "msk_test = np.random.rand(len(df_all)) < 0.2\n",
    "df_test = df_all[msk_test]\n",
    "df_train_temp  = df_all[~msk_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73c5e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "msk_train = np.random.rand(len(df_train_temp)) < 0.2\n",
    "df_val = df_train_temp[msk_train]\n",
    "df_train  = df_train_temp[~msk_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df34642",
   "metadata": {},
   "source": [
    "## Let's verify for data leakage by performing an inner-join on id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6029fd89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>length_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>sample_rate_x</th>\n",
       "      <th>record_datetime_x</th>\n",
       "      <th>sound_type_x</th>\n",
       "      <th>species_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>fed_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_y</th>\n",
       "      <th>method_y</th>\n",
       "      <th>mic_type_y</th>\n",
       "      <th>device_type_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>district_y</th>\n",
       "      <th>province_y</th>\n",
       "      <th>place_y</th>\n",
       "      <th>location_type_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, length_x, name_x, sample_rate_x, record_datetime_x, sound_type_x, species_x, gender_x, fed_x, plurality_x, age_x, method_x, mic_type_x, device_type_x, country_x, district_x, province_x, place_x, location_type_x, specie_ind_x, index_y, length_y, name_y, sample_rate_y, record_datetime_y, sound_type_y, species_y, gender_y, fed_y, plurality_y, age_y, method_y, mic_type_y, device_type_y, country_y, district_y, province_y, place_y, location_type_y, specie_ind_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_test,df_train, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72b4ea80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>length_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>sample_rate_x</th>\n",
       "      <th>record_datetime_x</th>\n",
       "      <th>sound_type_x</th>\n",
       "      <th>species_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>fed_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_y</th>\n",
       "      <th>method_y</th>\n",
       "      <th>mic_type_y</th>\n",
       "      <th>device_type_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>district_y</th>\n",
       "      <th>province_y</th>\n",
       "      <th>place_y</th>\n",
       "      <th>location_type_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, length_x, name_x, sample_rate_x, record_datetime_x, sound_type_x, species_x, gender_x, fed_x, plurality_x, age_x, method_x, mic_type_x, device_type_x, country_x, district_x, province_x, place_x, location_type_x, specie_ind_x, index_y, length_y, name_y, sample_rate_y, record_datetime_y, sound_type_y, species_y, gender_y, fed_y, plurality_y, age_y, method_y, mic_type_y, device_type_y, country_y, district_y, province_y, place_y, location_type_y, specie_ind_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_test,df_val, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5aa8289b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>length_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>sample_rate_x</th>\n",
       "      <th>record_datetime_x</th>\n",
       "      <th>sound_type_x</th>\n",
       "      <th>species_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>fed_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_y</th>\n",
       "      <th>method_y</th>\n",
       "      <th>mic_type_y</th>\n",
       "      <th>device_type_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>district_y</th>\n",
       "      <th>province_y</th>\n",
       "      <th>place_y</th>\n",
       "      <th>location_type_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, length_x, name_x, sample_rate_x, record_datetime_x, sound_type_x, species_x, gender_x, fed_x, plurality_x, age_x, method_x, mic_type_x, device_type_x, country_x, district_x, province_x, place_x, location_type_x, specie_ind_x, index_y, length_y, name_y, sample_rate_y, record_datetime_y, sound_type_y, species_y, gender_y, fed_y, plurality_y, age_y, method_y, mic_type_y, device_type_y, country_y, district_y, province_y, place_y, location_type_y, specie_ind_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_train,df_val, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c56a1",
   "metadata": {},
   "source": [
    "We've confirmed that there is no recording that is common in Train,Test,val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856193f9",
   "metadata": {},
   "source": [
    "### Next, we perform \"offsets\", spliting each(long) recording into multiple 1.92 secs chunk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b5570e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_offset = get_offsets_df(df_train)\n",
    "df_test_offset = get_offsets_df(df_test)\n",
    "df_val_offset = get_offsets_df(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "719b88c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train offset = 35043\n",
      "length of test offset = 11043\n",
      "length of val offset = 9466\n"
     ]
    }
   ],
   "source": [
    "print(\"length of train offset = \" +str(len(df_train_offset)))\n",
    "print(\"length of test offset = \" +str(len(df_test_offset)))\n",
    "print(\"length of val offset = \" +str(len(df_val_offset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7acfdebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_temp.reset_index(inplace = True)\n",
    "df_train_offset.reset_index(inplace = True)\n",
    "df_test_offset.reset_index(inplace = True)\n",
    "df_val_offset.reset_index(inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c135a610",
   "metadata": {},
   "source": [
    "### Let's check for data leakage in offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8779765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>offset_x</th>\n",
       "      <th>length_x</th>\n",
       "      <th>specie_ind_x</th>\n",
       "      <th>start_x</th>\n",
       "      <th>end_x</th>\n",
       "      <th>index_y</th>\n",
       "      <th>offset_y</th>\n",
       "      <th>length_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, offset_x, length_x, specie_ind_x, start_x, end_x, index_y, offset_y, length_y, specie_ind_y, start_y, end_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_train_offset , df_test_offset , on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70551bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>offset_x</th>\n",
       "      <th>length_x</th>\n",
       "      <th>specie_ind_x</th>\n",
       "      <th>start_x</th>\n",
       "      <th>end_x</th>\n",
       "      <th>index_y</th>\n",
       "      <th>offset_y</th>\n",
       "      <th>length_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, offset_x, length_x, specie_ind_x, start_x, end_x, index_y, offset_y, length_y, specie_ind_y, start_y, end_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_train_offset , df_val_offset , on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df57f07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>offset_x</th>\n",
       "      <th>length_x</th>\n",
       "      <th>specie_ind_x</th>\n",
       "      <th>start_x</th>\n",
       "      <th>end_x</th>\n",
       "      <th>index_y</th>\n",
       "      <th>offset_y</th>\n",
       "      <th>length_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, offset_x, length_x, specie_ind_x, start_x, end_x, index_y, offset_y, length_y, specie_ind_y, start_y, end_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_test_offset , df_val_offset , on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf3ebd0",
   "metadata": {},
   "source": [
    "### At this stage we've a dataframe of recordin ids and each row corresponds to a 1.92 secs recording or shorter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5afa2201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specie_distri(df , classes , type_df = None):\n",
    "    \"\"\"This function takes a dataframe and provides a count of each specie class\"\"\"\n",
    "    for i in range(len(classes)):\n",
    "        print(\"DF type = \" + str(type_df))\n",
    "        df_temp = df[df['specie_ind'] == i]\n",
    "        print(\"i = \" +str(i))\n",
    "        print(len(df_temp))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7921c749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32524317 0.56223527 3.61119126 0.62576786 1.97670352 4.1207667\n",
      " 3.00231323 5.25855342]\n"
     ]
    }
   ],
   "source": [
    "#Class imbalance \n",
    "np.array(df_train_offset.specie_ind)\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',classes=np.unique(np.array(df_train_offset.specie_ind)),y=np.array(np.array(df_train_offset.specie_ind)))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0a7df8",
   "metadata": {},
   "source": [
    "### Now we need to populate the lists of file_names and label_names for use in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1135339b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>specie_ind</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>221103</td>\n",
       "      <td>0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>221103</td>\n",
       "      <td>1</td>\n",
       "      <td>1.92</td>\n",
       "      <td>7</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>221103</td>\n",
       "      <td>2</td>\n",
       "      <td>1.28</td>\n",
       "      <td>7</td>\n",
       "      <td>10240.0</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>221111</td>\n",
       "      <td>0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>221111</td>\n",
       "      <td>1</td>\n",
       "      <td>1.92</td>\n",
       "      <td>7</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      id  offset  length  specie_ind    start      end\n",
       "0      0  221103       0    1.92           7      0.0  15360.0\n",
       "1      1  221103       1    1.92           7   5120.0  20480.0\n",
       "2      2  221103       2    1.28           7  10240.0  20480.0\n",
       "3      3  221111       0    1.92           7      0.0  15360.0\n",
       "4      4  221111       1    1.92           7   5120.0  20480.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_offset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb7bbda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/task/ComParE2022_VecNet/notebooks/DK\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78dcb569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/audio'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(\"..\",\"..\",\"data\",\"audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c66d207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lists(df):\n",
    "    #parent_dir = os.path.join(\"~\",\"ComParE2022_VecNet\",\"data\",\"audio\")\n",
    "    parent_dir = os.path.join(\"..\",\"..\",\"data\",\"audio\")\n",
    "    file_dict = {}\n",
    "    label = []\n",
    "    #print(\"inside get_lists\")\n",
    "    for ind,row in tqdm(df.iterrows()):\n",
    "        #print(row)\n",
    "        #print(row['id'])\n",
    "        wav = str(int(row['id']))+\".wav\"\n",
    "        final_path = parent_dir + \"/\"+wav\n",
    "        #print(\"wav file path = \",final_path)\n",
    "        start_offset = int(round((row['start'])))\n",
    "        end_offset = int(round((row['end'])))\n",
    "                                  \n",
    "        file_dict[ind] = (final_path ,(start_offset , end_offset))\n",
    "        label.append(int(row['specie_ind']))\n",
    "    return file_dict, label\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42c19105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272a35e9ebaf4a8383e1352631acc885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_trunc = df_train_offset.head()\n",
    "f,l = get_lists(df_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72a56315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa1aa32f379490995636b4155402679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76249c03663a441aa3f0da63bb994e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c659c2194f4b4638bf622afba4fa1c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_list_train , label_list_train = get_lists(df_train_offset)\n",
    "file_list_val , label_list_val = get_lists(df_val_offset)\n",
    "file_list_test , label_list_test = get_lists(df_test_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47ed453c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_list_train len =  35043\n",
      "label_list_train len =  35043\n",
      "file_list_val len =  9466\n",
      "label_list_val len =  9466\n",
      "file_list_test len =  11043\n",
      "label_list_test len =  11043\n"
     ]
    }
   ],
   "source": [
    "print(\"file_list_train len = \", len(file_list_train))\n",
    "print(\"label_list_train len = \", len(label_list_train))\n",
    "print(\"file_list_val len = \", len(file_list_val))\n",
    "print(\"label_list_val len = \", len(label_list_val))\n",
    "print(\"file_list_test len = \", len(file_list_test))\n",
    "print(\"label_list_test len = \", len(label_list_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbfdb23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_hat,y_true,classes):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_hat, y_true ,labels= range(len(classes)))\n",
    "    import seaborn as sns\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, fmt = 'g'); #annot=True to annotate cellsplt.xticks(rotation=90)\n",
    "    ax.xaxis.set_ticklabels(classes, fontsize = 10)\n",
    "    ax.xaxis.tick_bottom()\n",
    "    plt.xticks(rotation=90)\n",
    "    ax.set_ylabel('True', fontsize=20)\n",
    "    ax.yaxis.set_ticklabels(classes, fontsize = 10)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c8c38",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d8b88df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model(x)['prediction']\n",
    "#             y_pred_smax = softmax(y_pred)\n",
    "#             preds = torch.argmax(y_pred_smax, axis = 1)\n",
    "#             y_pred_cpu = y_pred.cpu().detach()\n",
    "#             if DEBUG:\n",
    "#                 print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "#             #preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "#             if DEBUG:\n",
    "#                 print(\"preds = \" +str(preds))\n",
    "#             all_y_pred.append(preds.cpu().detach())\n",
    "                                   \n",
    "#             loss = criterion(y_pred, y)\n",
    "#             test_loss += loss.item()\n",
    "#             all_y.append(y.cpu().detach())\n",
    "#             #all_y_pred.append(np.argmax(y_pred.cpu().detach().numpy()))\n",
    "            \n",
    "#             del x\n",
    "#             del y\n",
    "#             del y_pred\n",
    "#         all_y = torch.cat(all_y)\n",
    "#         all_y_pred = torch.cat(all_y_pred)\n",
    "#         if DEBUG:\n",
    "#             print(\"inside test....\")\n",
    "#             print(\"y = \" + str(all_y))\n",
    "#             print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "#         test_loss = test_loss/len(test_loader)\n",
    "#         test_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca86b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loader, criterion,  classes = classes,device=None , call = \"val\"):\n",
    "    softmax = nn.Softmax()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        test_loss = 0.0\n",
    "        model.eval()\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        counter = 1\n",
    "        for i, (inputs, labels) in tqdm(enumerate(loader), desc = \"inside test\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            y_pred = model(inputs).logits\n",
    "            y_pred_smax = softmax(y_pred)\n",
    "            preds = torch.argmax(y_pred_smax, axis = 1)\n",
    "            #_, preds = torch.max(outputs, 1)\n",
    "            #preds = torch.argmax(y_pred_smax, axis = 1)\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "                                   \n",
    "            loss = criterion(y_pred, labels)\n",
    "            test_loss += loss.item()\n",
    "            all_y.append(labels.cpu().detach())\n",
    "            #all_y_pred.append(np.argmax(y_pred.cpu().detach().numpy()))\n",
    "            if DEBUG:\n",
    "                print(\"inside test....\" + \"calling for \" + str(call))\n",
    "                print(\"inputs shape  = \" + str(inputs.shape))\n",
    "                print(\"labels shape  = \" + str(labels.shape))\n",
    "                print(\"y_pred  = \" + str(y_pred))\n",
    "                #print(\"y_pred_smax = \" +str(y_pred_smax))\n",
    "                print(\"preds = \" +str(preds))\n",
    "                            \n",
    "            \n",
    "            \n",
    "            del inputs\n",
    "            del labels\n",
    "            del y_pred,preds\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        test_loss = test_loss/len(test_loader)\n",
    "        test_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "        if DEBUG:\n",
    "            print(\"all_y_pred = \", all_y_pred)\n",
    "            print(\"all_y = \", all_y)\n",
    "            print(\"test_f1 = \", test_f1)\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    return test_loss, test_f1 , all_y,all_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69210e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the function for training the model\n",
    "# def train_model(model, train_loader, optimizer, loss_fn, device):\n",
    "#     model.train()\n",
    "#     for i, (inputs, labels) in enumerate(train_loader):\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         with autocast():\n",
    "#             outputs = model(inputs).logits\n",
    "#             loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "# # Define the function for evaluating the model\n",
    "# def eval_model(model, eval_loader, device):\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in eval_loader:\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "#             outputs = model(inputs).logits\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#     accuracy = 100 * correct / total\n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39a0b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for loading the dataset\n",
    "def load_dataset(file_list, labels, batch_size=batch_size):\n",
    "    dataset = AudioDataset(file_list, labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True,num_workers = num_workers)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2574e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_mean(x_temp,rate = config.rate, min_length = config.min_duration ):\n",
    "    if DEBUG:\n",
    "        print(\"inside padding mean...\")\n",
    "    x_mean = torch.mean(x_temp)\n",
    "    #x_mean.cuda()\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"X_mean = \" + str(x_mean))\n",
    "    left_pad_amt = int((rate*min_length-x_temp.shape[1])//2)\n",
    "    if DEBUG:\n",
    "        print(\"left_pad_amt = \" + str(left_pad_amt))\n",
    "    left_pad = torch.zeros(1,left_pad_amt) #+ (0.1**0.5)*torch.randn(1, left_pad_amt)\n",
    "    if DEBUG:\n",
    "        print(\"left_pad shape = \" + str(left_pad.shape))\n",
    "    left_pad_mean_add = left_pad + x_mean\n",
    "    if DEBUG:\n",
    "        print(\"left_pad_mean shape = \" + str(left_pad_mean_add))\n",
    "        print(\"sum of left pad mean add = \" + str(torch.sum(left_pad_mean_add)))\n",
    "    \n",
    "    right_pad_amt = int(rate*min_length-x_temp.shape[1]-left_pad_amt)\n",
    "    right_pad = torch.zeros(1,right_pad_amt)# + (0.1**0.5)*torch.randn(1, right_pad_amt)\n",
    "    if DEBUG:\n",
    "        print(\"right_pad shape = \" + str(right_pad.shape))\n",
    "    right_pad_mean_add = right_pad + x_mean\n",
    "    if DEBUG:\n",
    "        print(\"right_pad_mean shape = \" + str(right_pad_mean_add))\n",
    "        print(\"sum of right pad mean add = \"  + str(torch.sum(right_pad_mean_add)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    f = torch.cat([left_pad,x_temp,right_pad],dim=1)[0]\n",
    "    f = f.unsqueeze(dim = 0)\n",
    "    #print(\"returning a tensor of shape = \" + str(f.shape))\n",
    "    return(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9825e598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, file_list, labels):\n",
    "        self.file_list = file_list\n",
    "        self.labels = labels\n",
    "        #processor = processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-conformer-rope-large-960h-ft\")\n",
    "        self.processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-conformer-rope-large-960h-ft\",sampling_rate = 16000,return_tensors=\"pt\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        wav2_vec_rate = 16000\n",
    "        file_path,offset_tup = self.file_list[index]\n",
    "        start , end = offset_tup\n",
    "        if DEBUG:\n",
    "            print(\"file_path = \", file_path)\n",
    "            print(\"start = \", start)\n",
    "            print(\"end = \", end)\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        waveform.to('cuda')\n",
    "        #print(\"after loading . Wavform shape = \" , waveform.shape)\n",
    "              \n",
    "        \n",
    "        \n",
    "        if sample_rate != wav2_vec_rate:\n",
    "            if DEBUG:\n",
    "                print(\"file_path = \" + str(file_path) + \" Original sample rate = \" +str(sample_rate)+ \" resampling ...\")\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(sample_rate, wav2_vec_rate, dtype=waveform.dtype)\n",
    "            waveform = resampler(waveform)\n",
    "            if DEBUG:\n",
    "                print(\"waveform shape post resampling = \", waveform.shape)\n",
    "        \n",
    "        waveform = waveform[:,start:end]\n",
    "        if waveform.shape[1] < config.rate*config.min_duration:\n",
    "            #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "            waveform = pad_mean(waveform)\n",
    "            if DEBUG:\n",
    "                print(\"applying padding.. \" +str(file_path))\n",
    "                print(\"short file encountered . Post padding shape of wavform = \" ,waveform.shape)\n",
    "        \n",
    "        #print(\"final waveform shape being returned = \", waveform.shape)\n",
    "        input_values = self.processor(waveform, sampling_rate=wav2_vec_rate, return_tensors=\"pt\").input_values\n",
    "        if DEBUG:\n",
    "            print(\"input_values shape = \",input_values.shape)\n",
    "        label = self.labels[index]\n",
    "        return input_values.squeeze().to('cuda'), label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb2f6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = load_dataset(file_list_train, label_list_train, batch_size=batch_size)\n",
    "val_loader = load_dataset(file_list_val, label_list_val, batch_size=batch_size)\n",
    "test_loader = load_dataset(file_list_test, label_list_test, batch_size=batch_size)\n",
    "\n",
    "if DEBUG:\n",
    "    file_list_train = dict(list(file_list_train.items())[:10])\n",
    "    label_list_train = label_list_train[:10]\n",
    "    file_list_val = dict(list(file_list_val.items())[:6])\n",
    "    label_list_val = label_list_val[:6]\n",
    "    file_list_test = dict(list(file_list_test.items())[:4])\n",
    "    label_list_test = label_list_test[:4]\n",
    "    train_loader = load_dataset(file_list_train, label_list_train, batch_size=batch_size)\n",
    "    val_loader = load_dataset(file_list_val, label_list_val, batch_size=batch_size)\n",
    "    test_loader = load_dataset(file_list_test, label_list_test, batch_size=batch_size)\n",
    "    print(\"inside DEBUG for dataset creation..\" + \" len of train_loader = \" + str(len(train_loader)))\n",
    "    print(\"inside DEBUG for dataset creation..\" + \" len of val_loader = \" + str(len(val_loader)))\n",
    "    print(\"inside DEBUG for dataset creation..\" + \" len of test_loader = \" + str(len(test_loader)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5523838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_offset[df_train_offset['id']== 220895]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "945703c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#facebook/wav2vec2-conformer-rel-pos-large-960h-ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fce92bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_iter = iter(train_loader)\n",
    "# x, y  = data_iter.next()\n",
    "# print(\"^^^^^^^^^^^^^^^^^\")\n",
    "# print(x)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199e07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "897f5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loader, criterion,  classes = classes,device=None , call = \"val\"):\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        test_loss = 0.0\n",
    "        model.eval()\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        counter = 1\n",
    "        for i, (inputs, labels) in tqdm(enumerate(loader), desc = \"inside test\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            y_pred = model(inputs).logits\n",
    "            _, preds = torch.max(y_pred, dim=1)\n",
    "            #_, preds = torch.max(outputs, 1)\n",
    "            #preds = torch.argmax(y_pred_smax, axis = 1)\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "                                   \n",
    "            loss = criterion(y_pred, labels)\n",
    "            test_loss += loss.item()\n",
    "            all_y.append(labels.cpu().detach())\n",
    "            #all_y_pred.append(np.argmax(y_pred.cpu().detach().numpy()))\n",
    "            if DEBUG:\n",
    "                print(\"inside test....\" + \"calling for \" + str(call))\n",
    "                print(\"inputs shape  = \" + str(inputs.shape))\n",
    "                print(\"labels shape  = \" + str(labels.shape))\n",
    "                print(\"y_pred  = \" + str(y_pred))\n",
    "                print(\"y_pred_smax = \" +str(y_pred_smax))\n",
    "                print(\"preds = \" +str(preds))\n",
    "                            \n",
    "            \n",
    "            \n",
    "            del inputs\n",
    "            del labels\n",
    "            del y_pred,preds\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        test_loss = test_loss/len(test_loader)\n",
    "        test_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "        if DEBUG:\n",
    "            print(\"all_y_pred = \", all_y_pred)\n",
    "            print(\"all_y = \", all_y)\n",
    "            print(\"test_f1 = \", test_f1)\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    return test_loss, test_f1 , all_y,all_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ed035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "968fd2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader,val_loader,test_loader,model ,classes = classes,class_weights = class_weights,num_epochs = num_epochs ,n_channels = 1):\n",
    "    # Creates a GradScaler once at the beginning of training.\n",
    "    torch.manual_seed(0)\n",
    "    lr = 1e-2\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f'Training on {device}')    \n",
    "    model = model.to(device)\n",
    "    class_weights = class_weights\n",
    "    weights_adj = torch.tensor(class_weights).type(torch.float).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights_adj)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(weight=weights_adj)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    num_epochs = num_epochs\n",
    "    all_train_loss = []\n",
    "    all_train_f1 = []\n",
    "    all_val_loss = []\n",
    "    all_val_f1 = []\n",
    "    best_val_loss = np.inf\n",
    "    best_val_f1 = -np.inf\n",
    "    best_train_f1 = -np.inf\n",
    "    best_epoch = -1\n",
    "    checkpoint_name = None\n",
    "    overrun_counter = 0\n",
    "    #sigmoid = nn.Sigmoid()\n",
    "    softmax = nn.Softmax()\n",
    "    all_train_f1 = []\n",
    "    all_val_f1 = []\n",
    "    lr_log = []\n",
    "    for e in tqdm(range(num_epochs), desc = \"epoc loop\"):\n",
    "        start_time = time.time()\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        #tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "        for i, (inputs, labels) in tqdm(enumerate(train_loader), desc = \"batch loop\"):\n",
    "            if i % 200 == 0:\n",
    "                bat_time = time.time()\n",
    "                durn = (bat_time - start_time)/60\n",
    "                print(\"epoch = \" +str(e) + \"batch = \" +str(i) + \" of \" + str(len(train_loader)) + \"duraation = \" + str(durn))\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                y_pred = model(inputs).logits\n",
    "                #print(\"y_pred = \",y_pred)\n",
    "                #print(\"y_pred shape = \", y_pred.shape)\n",
    "                #y_pred_smax = softmax(y_pred)\n",
    "                _, preds = torch.max(y_pred, dim=1)\n",
    "                #print(\"outputs = \",preds)\n",
    "                if DEBUG:\n",
    "                    print(\"inputs shape = \", inputs.shape)\n",
    "                    print(\"labels shape = \", labels.shape)\n",
    "                    print(\"y_pred = \", y_pred)\n",
    "                    print(\"y_pred shape = \", y_pred.shape)\n",
    "                    \n",
    "                    #print(\"y_pred_smax = \", y_pred_smax)\n",
    "                    print(\"preds shape = \", preds.shape)\n",
    "                    print(\"preds  = \", preds)\n",
    "                    \n",
    "                    \n",
    "                loss = loss_fn(y_pred, labels)\n",
    "                                    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            train_loss += loss.item()\n",
    "            all_y.append(labels.cpu().detach())\n",
    "            y_pred_cpu = preds.cpu().detach()\n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "            del inputs\n",
    "            del labels\n",
    "            del y_pred,preds\n",
    "            \n",
    "                        \n",
    "            #optimiser.step()\n",
    "#         del inputs\n",
    "#         del labels\n",
    "        #del y_pred,outputs\n",
    "        \n",
    "        #lr_log.append(lr)\n",
    "        all_train_loss.append(train_loss/len(train_loader))\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "                   \n",
    "         \n",
    "        train_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "        if DEBUG:\n",
    "            print(\"all_y = \", all_y.numpy())\n",
    "            print(\"all_y_pred.numpy() = \", all_y_pred.numpy())\n",
    "            print(\"train f1  = \", train_f1)\n",
    "        all_train_f1.append(train_f1)\n",
    "        all_train_f1.append(train_f1)\n",
    "        val_loss, val_f1 , _,_ = test_model(model, val_loader, criterion = nn.CrossEntropyLoss(), classes = classes ,device=device, call = \"val\")\n",
    "        all_val_f1.append(val_f1)\n",
    "        all_val_loss.append(val_loss)\n",
    "        all_val_loss.append(val_loss)\n",
    "        all_val_f1.append(val_f1)\n",
    "        \n",
    "        acc_metric = val_f1\n",
    "        best_acc_metric = best_val_f1\n",
    "        if acc_metric > best_acc_metric:  \n",
    "            overrun_counter = -1\n",
    "            checkpoint_name = f'model_e{e}_{datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")}.pth'\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_dir,  checkpoint_name))\n",
    "            sys.stdout.flush()\n",
    "            print('Epoch: %d, Train Loss: %.8f, Train f1: %.8f, Val Loss: %.8f, Val f1: %.8f, overrun_counter %i' % (e, train_loss/len(train_loader), train_f1, val_loss/len(val_loader), val_f1,  overrun_counter))\n",
    "            print('Saving model to:', os.path.join(config.model_dir,  checkpoint_name)) \n",
    "            print(\"Now printing classification rport... \")\n",
    "            print(\"********************************\")\n",
    "            from sklearn.metrics import classification_report\n",
    "            _, _ , all_y_test,all_y_pred_test = test_model(model, test_loader, criterion = nn.CrossEntropyLoss(), classes = classes ,device=device, call = \"test\")\n",
    "            # at times output is not getting printed. Could be due to multi threading and hence adding sleep\n",
    "            time.sleep(2)\n",
    "            sys.stdout.flush()\n",
    "            print(classification_report(all_y_test.numpy(), all_y_pred_test.numpy(), target_names= classes))\n",
    "            print(\"********************************\")\n",
    "            time.sleep(2)\n",
    "            plot_confusion_matrix(all_y_pred_test.numpy(), all_y_test.numpy() , classes)\n",
    "            best_epoch = e\n",
    "            best_val_f1 = val_f1\n",
    "            best_val_loss = val_loss\n",
    "            \n",
    "        else:\n",
    "            print(\"..Overrun....no improvement\")\n",
    "            overrun_counter += 1\n",
    "            sys.stdout.flush()\n",
    "            print('Epoch: %d, Train Loss: %.8f, Train f1: %.8f, Val Loss: %.8f, Val f1: %.8f, overrun_counter %i' % (e, train_loss/len(train_loader), train_f1, val_loss/len(val_loader), val_f1,  overrun_counter))\n",
    "        if overrun_counter > config_pytorch.max_overrun:\n",
    "            break\n",
    "            \n",
    "    \n",
    "    return model, lr_log,all_train_f1,all_train_loss,all_val_loss,all_val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21b41122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-conformer-rope-large-960h-ft were not used when initializing Wav2Vec2ConformerForSequenceClassification: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing Wav2Vec2ConformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ConformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ConformerForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-conformer-rope-large-960h-ft and are newly initialized: ['classifier.weight', 'projector.weight', 'projector.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1849a9a07ce24bc9b071ea92dd1a4d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoc loop:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa1e6108aa84984825659e8dd0b8923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batch loop: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0batch = 0 of 548duraation = 0.030663839975992837\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1696658/2018352015.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2ConformerForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'facebook/wav2vec2-conformer-rope-large-960h-ft'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_log\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_train_f1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_train_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_val_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_val_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1696658/1425457608.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, val_loader, test_loader, model, classes, class_weights, num_epochs, n_channels)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mall_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#tk0 = tqdm(train_loader, total=int(len(train_loader)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"batch loop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mbat_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1696658/2773982680.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file_path = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Original sample rate = \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m\" resampling ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mresampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav2_vec_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mwaveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchaudio/transforms.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, orig_freq, new_freq, resampling_method, lowpass_filter_width, rolloff, beta, dtype)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_freq\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_freq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             kernel, self.width = _get_sinc_resample_kernel(\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchaudio/functional/functional.py\u001b[0m in \u001b[0;36m_get_sinc_resample_kernel\u001b[0;34m(orig_freq, new_freq, gcd, lowpass_filter_width, rolloff, resampling_method, beta, device, dtype)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnew_freq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0morig_freq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbase_freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlowpass_filter_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowpass_filter_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0;31m# we do not use built in torch windows here as we need to evaluate the window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = Wav2Vec2ConformerForSequenceClassification.from_pretrained('facebook/wav2vec2-conformer-rope-large-960h-ft' , num_labels = len(classes))\n",
    "tr_model, lr_log,all_train_f1,all_train_loss,all_val_loss,all_val_f1 = train_model(train_loader,val_loader,test_loader,model ,classes = classes,class_weights = class_weights,num_epochs = num_epochs ,n_channels = 1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac588099",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025bcf5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcef949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4190584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d2244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6eb50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9295162e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b72d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee231c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdc1f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bc8cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153b30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf4649b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe6cd52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b8057e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e7778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d58e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356d4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9957c8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e55d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
