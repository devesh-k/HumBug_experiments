{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af064697",
   "metadata": {},
   "source": [
    "### GOAL- check whether Label smoothing helps in improving perf\n",
    "- base R4_LabelSmoothing.ipynb\n",
    "- add Batch norm 2D\n",
    "- Explore Exponential learning rate\n",
    "- RandomChoice on Time and Freq Masking and RandomApply on all 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de126b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/task/ComParE2022_VecNet/notebooks/DK\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "223bc552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".CodeMirror{\n",
       "font-size: 14px;\n",
       "</style>\n",
       "CUDA_LAUNCH_BLOCKING=1\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "font-size: 14px;\n",
    "</style>\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a724934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.12.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.5.0)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.21.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.28.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.3.2)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (6.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.25->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib!=3.6.1,>=3.1->seaborn) (59.4.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib!=3.6.1,>=3.1->seaborn) (1.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92283690",
   "metadata": {},
   "source": [
    "### 1 Import the kitchen sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c6a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n"
     ]
    }
   ],
   "source": [
    "%env CUBLAS_WORKSPACE_CONFIG=:4096:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2cf671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# humbug main imports\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../../src'))\n",
    "import config ,config_pytorch\n",
    "from evaluate import get_results\n",
    "import numpy as np\n",
    "\n",
    "# Troubleshooting and visualisation\n",
    "import IPython.display as ipd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a8c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# humbug lib imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "#from PyTorch import config_pytorch\n",
    "from datetime import datetime\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b47dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional pytorch tools\n",
    "import random\n",
    "import torchaudio\n",
    "import torchaudio.transforms as AT\n",
    "import torchvision.transforms as VT\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "import timm\n",
    "import timm.optim\n",
    "from timm.loss import BinaryCrossEntropy\n",
    "from timm.utils import NativeScaler\n",
    "from timm.models import model_parameters\n",
    "from glob import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f7067e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/nnAudio/Spectrogram.py:4: Warning: importing Spectrogram subpackage will be deprecated soon. You should import the feature extractor from the feature subpackage. See actual documentation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## nnAudio\n",
    "from nnAudio import features,Spectrogram\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9dfe71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f170f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02232da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Training variables \n",
    "USE_SHORT_AUDIO = True\n",
    "num_workers= 8\n",
    "pin_memory=True\n",
    "#train_size = 100\n",
    "batch_size = 32\n",
    "test_batch_size = 32\n",
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    batch_size = 4\n",
    "    test_batch_size = 4\n",
    "    num_workers=1\n",
    "    \n",
    "     \n",
    "\n",
    "num_epochs = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d94b9f",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea466b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85e8e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['an arabiensis','culex pipiens complex', 'ae aegypti','an funestus ss','an squamosus',\n",
    "               'an coustani','ma uniformis','ma africanus' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b5f599",
   "metadata": {},
   "source": [
    "### Read CSV and get train/test groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc7f8c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loader, criterion,  classes = classes,device=None , call = \"val\"):\n",
    "    softmax = nn.Softmax()\n",
    "    if DEBUG:\n",
    "        print(\"calling for ...\" +str(call))\n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        sigmoid = nn.Sigmoid()\n",
    "        test_loss = 0.0\n",
    "        model.eval()\n",
    "        if DEBUG:\n",
    "            print(\"inside test....\")\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        counter = 1\n",
    "        if DEBUG:\n",
    "            print(\"length of loader = \" + str(len(loader)))\n",
    "        for idx,(x,y) in enumerate(loader):\n",
    "            if DEBUG:\n",
    "                print(\"loader index = \" + str(idx))\n",
    "                            \n",
    "            x = x.to(device).float() \n",
    "            y = y.type(torch.LongTensor).to(device)\n",
    "            if DEBUG:\n",
    "                print(\"y = \" + str(y))\n",
    "            y_pred = model(x,train = False)['prediction']\n",
    "            #y_pred_smax = softmax(y_pred)\n",
    "            preds = torch.argmax(y_pred, axis = 1)\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            if DEBUG:\n",
    "                print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "            #preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "            if DEBUG:\n",
    "                print(\"preds = \" +str(preds))\n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "                                   \n",
    "            loss = criterion(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            all_y.append(y.cpu().detach())\n",
    "            #all_y_pred.append(np.argmax(y_pred.cpu().detach().numpy()))\n",
    "            \n",
    "            del x\n",
    "            del y\n",
    "            del y_pred\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        if DEBUG:\n",
    "            print(\"inside test....\")\n",
    "            print(\"y = \" + str(all_y))\n",
    "            print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "        test_loss = test_loss/len(test_loader)\n",
    "        test_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "    \n",
    "    \n",
    "    return test_loss, test_f1 , all_y,all_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b89bde2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(train_loader, val_loader, test_loader,model, classes ,class_weights ,num_epochs = num_epochs )\n",
    "def train_model(model, num_epochs = num_epochs ,n_channels = 1,batch_size = batch_size):\n",
    "    # Creates a GradScaler once at the beginning of training.\n",
    "    loss_scaler = NativeScaler()\n",
    "    global_step = 0\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Training on {device}')    \n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using data parallel\")\n",
    "        model = nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "\n",
    "    model = model.to(device)\n",
    "    #weights_adj = torch.tensor(class_weights).type(torch.float).to(device)\n",
    "    criterion_1 = nn.CrossEntropyLoss(label_smoothing=.1)\n",
    "    criterion_2 = nn.CrossEntropyLoss()\n",
    "    lr = .000015\n",
    "    base_optimiser = timm.optim.AdamP(model.parameters(), lr= lr)\n",
    "    look_optimiser = timm.optim.Lookahead(base_optimiser)\n",
    "    cooldown_epoch = 50\n",
    "    \n",
    "    #optimiser = timm.optim.AdamW(model.parameters(), lr=config_pytorch.lr)\n",
    "    #timm.optim.Lookahead(optimiser, alpha=0.5, k=6)\n",
    "    scheduler = timm.scheduler.CosineLRScheduler(base_optimiser, t_initial= num_epochs,lr_min= lr/100,warmup_t = 5,warmup_lr_init= lr/10,noise_std=.075)\n",
    "    \n",
    "    \n",
    "    #optimiser = timm.optim.AdamW(model.parameters(), lr=config_pytorch.lr)\n",
    "    #timm.optim.Lookahead(optimiser, alpha=0.5, k=6)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #optimiser = timm.optim.RAdam(model.parameters(), lr=config_pytorch.lr/10)\n",
    "    num_epochs = num_epochs\n",
    "    all_train_loss = []\n",
    "    all_train_f1 = []\n",
    "    all_val_loss = []\n",
    "    all_val_f1 = []\n",
    "    best_val_loss = np.inf\n",
    "    best_val_f1 = -np.inf\n",
    "    best_train_f1 = -np.inf\n",
    "    best_epoch = -1\n",
    "    checkpoint_name = None\n",
    "    overrun_counter = 0\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    softmax = nn.Softmax()\n",
    "    all_train_f1 = []\n",
    "    all_val_f1 = []\n",
    "    \n",
    "    lr_log = []\n",
    "    for e in range(num_epochs + cooldown_epoch):\n",
    "        x,y = get_data()\n",
    "        start_time = time.time()\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        #tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "        if e%100 == 0:\n",
    "            print(\"e = \", e)\n",
    "            print(\"epalsed time = \",(start_time- time.time() )/60 )\n",
    "            print(\"LR = \",base_optimiser.param_groups[0]['lr'])\n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"inside train loop.. e = \" +str(e))\n",
    "        x = x.to(device).float()\n",
    "        if DEBUG:\n",
    "            print(\"inside train loop.. x device = \" +str(x.device))\n",
    "                \n",
    "            \n",
    "        y = y.type(torch.LongTensor).to(device)\n",
    "        #print(\"y shape = \", y.shape)\n",
    "        with autocast():\n",
    "            y_pred,backbone_nan = model(x,train = True)\n",
    "            #y_pred,backbone_nan = model(x,train = True)['prediction']\n",
    "            if backbone_nan == True:\n",
    "                return y_pred\n",
    "            #print(\"Y-pred shape = \",y_pred.shape)\n",
    "            #y_pred_smax = softmax(y_pred)\n",
    "            y_pred = y_pred['prediction']\n",
    "            preds = torch.argmax(y_pred, axis = 1)\n",
    "            if e < 20 :\n",
    "                loss = criterion_1(y_pred, y)\n",
    "            else:\n",
    "                loss = criterion_2(y_pred, y)\n",
    "            \n",
    "        if DEBUG:\n",
    "            print(\"y_pred  = \" +str(y_pred))\n",
    "            print(\"preds = \" +str(preds))\n",
    "                   \n",
    "        train_loss += loss.item()\n",
    "        all_y.append(y.cpu().detach())\n",
    "        y_pred_cpu = y_pred.cpu().detach()\n",
    "        #preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "        if DEBUG:\n",
    "            print(\"epoch = \" +str(e))\n",
    "            print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "        all_y_pred.append(preds.cpu().detach())\n",
    "        base_optimiser.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),error_if_nonfinite=False ,max_norm = 1.0 )\n",
    "        base_optimiser.step()\n",
    "        del x\n",
    "        del y\n",
    "        del y_pred,preds\n",
    "        \n",
    "        #lr_log.append(lr)\n",
    "        look_optimiser.sync_lookahead()\n",
    "        all_train_loss.append(train_loss/batch_size)\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        if DEBUG:\n",
    "            print(\"y = \" + str(all_y))\n",
    "            print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "        train_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "        all_train_f1.append(train_f1)\n",
    "        if DEBUG:\n",
    "            print(\"train acc = \" +str(train_f1))\n",
    "        all_train_f1.append(train_f1)\n",
    "        #all_val_f1.append(val_f1)\n",
    "        #all_val_loss.append(val_loss)\n",
    "       \n",
    "        #all_val_loss.append(val_loss)\n",
    "        #all_val_f1.append(val_f1)\n",
    "        \n",
    "        #acc_metric = val_f1\n",
    "        #best_acc_metric = best_val_f1\n",
    "        scheduler.step(e+1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2786ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model_name, image_size = 224):\n",
    "        super().__init__()\n",
    "        # num_classes=0 removes the pretrained head\n",
    "        self.backbone = timm.create_model(model_name,\n",
    "                        pretrained=True, num_classes=8, in_chans=1, \n",
    "                        drop_path_rate=0.2, global_pool='max',\n",
    "                        drop_rate=0.25)\n",
    "        #####  This section is model specific\n",
    "        #### It freezes some fo the layers by name\n",
    "        #### you'll have to inspect the model to see the names\n",
    "                #### end layer freezing\n",
    "        self.out = nn.Linear(self.backbone.num_features, 1)\n",
    "        self.sizer = VT.Resize((image_size,image_size),antialias = True)\n",
    "        self.spec_layer = features.STFT(n_fft=int(config.NFFT), freq_bins=None, hop_length=int(config.n_hop),\n",
    "                              window='hann', freq_scale='linear', center=True, pad_mode='reflect',\n",
    "                           sr=config.rate, output_format=\"Magnitude\", trainable=False,verbose = False).to('cuda')\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features= 1)\n",
    "        #self.augment_layer = augment_audio(trainable = True, sample_rate = config.rate)\n",
    "        \n",
    "    def forward(self, x,train = True):\n",
    "        # first compute spectrogram\n",
    "        spec_gram = self.spec_layer(x)\n",
    "        #print(\"post spec gram shape = \",spec_gram.shape)\n",
    "        spec_gram = self.batch_norm(spec_gram.unsqueeze(dim = 1))\n",
    "        #print(\"post norm shape = \",spec_gram.shape)\n",
    "        spec_gram_nan_check = torch.isnan(spec_gram).any().item()\n",
    "        assert not (spec_gram_nan_check) ,\"Tensor contains NaN values after spec gram creation.\"\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if train == True:\n",
    "                #generate a random number and if condition is met apply aug\n",
    "                ta_transformations_rndm_choice = VT.RandomChoice([AT.FrequencyMasking(freq_mask_param=100),AT.TimeMasking(time_mask_param=50)], p=[.4, .4])\n",
    "                ta_transformations_rndm_apply = VT.RandomApply([AT.FrequencyMasking(freq_mask_param=50),AT.TimeMasking(time_mask_param=25)],p = .15)\n",
    "                spec_gram = ta_transformations_rndm_choice(spec_gram)\n",
    "                spec_gram = ta_transformations_rndm_apply(spec_gram)\n",
    "                spec_gram_nan_check = torch.isnan(spec_gram).any().item()\n",
    "                assert not (spec_gram_nan_check) ,\"Tensor contains NaN values after augmentations  \"\n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "        x = self.sizer(spec_gram.squeeze(dim = 1))\n",
    "        #print(\"post sizer shape = \",x.shape)\n",
    "        x = x.unsqueeze(dim = 1)\n",
    "        #print(\"post unsqueeze shape = \",x.shape)\n",
    "        \n",
    "        # then repeat channels\n",
    "        del spec_gram,spec_gram_nan_check\n",
    "        if DEBUG:\n",
    "            print(\"Final shape that goes to backbone = \" + str(x.shape))\n",
    "                \n",
    "        backbone_nan = False\n",
    "        x = self.backbone(x)\n",
    "        backbone_op_nan_check = torch.isnan(x).any().item()\n",
    "        if backbone_op_nan_check:\n",
    "            backbone_nan = True\n",
    "            print(\"nan in the model op..\")\n",
    "            for param in self.backbone.parameters():\n",
    "                print(param)\n",
    "                return self.backbone.parameters() , backbone_nan\n",
    "        assert not (backbone_op_nan_check) ,\"Tensor contains NaN values in the backbone OP \"\n",
    "        #print(\"x shape = \" + str(x.shape))\n",
    "        #print(\"x = \" +str(x))\n",
    "        #pred = nn.Softmax(x)\n",
    "        pred = x\n",
    "        #print(np.argmax(pred.detach().cpu().numpy()))\n",
    "        #print(pred)\n",
    "        output = {\"prediction\": pred }\n",
    "        #print(\"output= \",output)\n",
    "        del x , backbone_op_nan_check\n",
    "        return output,backbone_nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04661e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size = batch_size):\n",
    "    #create a data of size (batch,1,15360)\n",
    "    x = torch.rand(batch_size ,1,15360 , device = 'cuda')\n",
    "    y = torch.randint(0, 8, (batch_size,1),device = 'cuda')\n",
    "    #print(\"y = \",y)\n",
    "    return x,y.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "434c1106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "x,y = get_data()\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "708f3708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n",
      "e =  0\n",
      "epalsed time =  -1.7209847768147787e-05\n",
      "LR =  5e-05\n",
      "e =  100\n",
      "epalsed time =  -2.248684565226237e-05\n",
      "LR =  0.00014999963359123796\n",
      "e =  200\n",
      "epalsed time =  -1.8799304962158202e-05\n",
      "LR =  0.00014999853436856815\n",
      "e =  300\n",
      "epalsed time =  -1.819928487141927e-05\n",
      "LR =  0.00014999670234283952\n",
      "e =  400\n",
      "epalsed time =  -1.8505255381266274e-05\n",
      "LR =  0.00014999413753213333\n",
      "e =  500\n",
      "epalsed time =  -1.8167495727539063e-05\n",
      "LR =  0.00014999083996176328\n",
      "e =  600\n",
      "epalsed time =  -2.2427241007486978e-05\n",
      "LR =  0.00014998680966427506\n",
      "e =  700\n",
      "epalsed time =  -1.9276142120361327e-05\n",
      "LR =  0.00014998204667944606\n",
      "e =  800\n",
      "epalsed time =  -1.863241195678711e-05\n",
      "LR =  0.000149976551054285\n",
      "e =  900\n",
      "epalsed time =  -1.8425782521565755e-05\n",
      "LR =  0.00014997032284303153\n",
      "e =  1000\n",
      "epalsed time =  -1.8493334452311197e-05\n",
      "LR =  0.00014996336210715557\n",
      "e =  1100\n",
      "epalsed time =  -1.8727779388427734e-05\n",
      "LR =  0.00014995566891535674\n",
      "e =  1200\n",
      "epalsed time =  -1.871188481648763e-05\n",
      "LR =  0.00014994724334356374\n",
      "e =  1300\n",
      "epalsed time =  -1.8990039825439454e-05\n",
      "LR =  0.00014993808547493357\n",
      "e =  1400\n",
      "epalsed time =  -1.8405914306640626e-05\n",
      "LR =  0.00014992819539985075\n",
      "e =  1500\n",
      "epalsed time =  -1.8755594889322918e-05\n",
      "LR =  0.00014991757321592626\n",
      "e =  1600\n",
      "epalsed time =  -1.883109410603841e-05\n",
      "LR =  0.0001499062190279968\n",
      "e =  1700\n",
      "epalsed time =  -1.8314520517985025e-05\n",
      "LR =  0.0001498941329481236\n",
      "e =  1800\n",
      "epalsed time =  -1.9097328186035155e-05\n",
      "LR =  0.0001498813150955914\n",
      "e =  1900\n",
      "epalsed time =  -1.8286705017089844e-05\n",
      "LR =  0.00014986776559690722\n",
      "e =  2000\n",
      "epalsed time =  -1.8819173177083334e-05\n",
      "LR =  0.00014985348458579914\n",
      "e =  2100\n",
      "epalsed time =  -1.9562244415283202e-05\n",
      "LR =  0.00014983847220321502\n",
      "e =  2200\n",
      "epalsed time =  -2.5200843811035157e-05\n",
      "LR =  0.00014982272859732096\n",
      "e =  2300\n",
      "epalsed time =  -1.885096232096354e-05\n",
      "LR =  0.00014980625392350003\n",
      "e =  2400\n",
      "epalsed time =  -1.8727779388427734e-05\n",
      "LR =  0.00014978904834435058\n",
      "e =  2500\n",
      "epalsed time =  -1.731713612874349e-05\n",
      "LR =  0.00014977111202968475\n",
      "e =  2600\n",
      "epalsed time =  -1.6597906748453774e-05\n",
      "LR =  0.0001497524451565267\n",
      "e =  2700\n",
      "epalsed time =  -1.6959508260091147e-05\n",
      "LR =  0.00014973304790911096\n",
      "e =  2800\n",
      "epalsed time =  -1.713832219441732e-05\n",
      "LR =  0.00014971292047888054\n",
      "e =  2900\n",
      "epalsed time =  -1.625219980875651e-05\n",
      "LR =  0.00014969206306448502\n",
      "e =  3000\n",
      "epalsed time =  -1.8298625946044922e-05\n",
      "LR =  0.00014967047587177866\n",
      "e =  3100\n",
      "epalsed time =  -1.866022745768229e-05\n",
      "LR =  0.0001496481591138184\n",
      "e =  3200\n",
      "epalsed time =  -1.8914540608723957e-05\n",
      "LR =  0.00014962511301086154\n",
      "e =  3300\n",
      "epalsed time =  -1.9220511118570962e-05\n",
      "LR =  0.00014960133779036384\n",
      "e =  3400\n",
      "epalsed time =  -2.3718674977620443e-05\n",
      "LR =  0.00014957683368697715\n",
      "e =  3500\n",
      "epalsed time =  -1.876354217529297e-05\n",
      "LR =  0.0001495516009425471\n",
      "e =  3600\n",
      "epalsed time =  -1.8727779388427734e-05\n",
      "LR =  0.00014952563980611061\n",
      "e =  3700\n",
      "epalsed time =  -1.811981201171875e-05\n",
      "LR =  0.00014949895053389367\n",
      "e =  3800\n",
      "epalsed time =  -1.808007558186849e-05\n",
      "LR =  0.00014947153338930864\n",
      "e =  3900\n",
      "epalsed time =  -1.8676122029622395e-05\n",
      "LR =  0.00014944338864295167\n",
      "e =  4000\n",
      "epalsed time =  -1.9085407257080077e-05\n",
      "LR =  0.00014941451657259997\n",
      "e =  4100\n",
      "epalsed time =  -1.9276142120361327e-05\n",
      "LR =  0.0001493849174632093\n",
      "e =  4200\n",
      "epalsed time =  -1.81118647257487e-05\n",
      "LR =  0.00014935459160691085\n",
      "e =  4300\n",
      "epalsed time =  -1.8958250681559245e-05\n",
      "LR =  0.00014932353930300864\n",
      "e =  4400\n",
      "epalsed time =  -1.820723215738932e-05\n",
      "LR =  0.00014929176085797633\n",
      "e =  4500\n",
      "epalsed time =  -1.7178058624267577e-05\n",
      "LR =  0.00014925925658545438\n",
      "e =  4600\n",
      "epalsed time =  -1.624425252278646e-05\n",
      "LR =  0.0001492260268062468\n",
      "e =  4700\n",
      "epalsed time =  -1.6705195109049478e-05\n",
      "LR =  0.00014919207184831815\n",
      "e =  4800\n",
      "epalsed time =  -1.7058849334716796e-05\n",
      "LR =  0.0001491573920467901\n",
      "e =  4900\n",
      "epalsed time =  -1.853307088216146e-05\n",
      "LR =  0.00014912198774393831\n",
      "e =  5000\n",
      "epalsed time =  -1.7905235290527342e-05\n",
      "LR =  0.00014908585928918896\n",
      "e =  5100\n",
      "epalsed time =  -1.8970171610514322e-05\n",
      "LR =  0.0001490490070391153\n",
      "e =  5200\n",
      "epalsed time =  -1.800855000813802e-05\n",
      "LR =  0.00014901143135743417\n",
      "e =  5300\n",
      "epalsed time =  -1.8278757731119793e-05\n",
      "LR =  0.00014897313261500242\n",
      "e =  5400\n",
      "epalsed time =  -1.863241195678711e-05\n",
      "LR =  0.0001489341111898131\n",
      "e =  5500\n",
      "epalsed time =  -1.8640359242757162e-05\n",
      "LR =  0.00014889436746699195\n",
      "e =  5600\n",
      "epalsed time =  -1.87834103902181e-05\n",
      "LR =  0.00014885390183879348\n",
      "e =  5700\n",
      "epalsed time =  -1.8596649169921875e-05\n",
      "LR =  0.0001488127147045971\n",
      "e =  5800\n",
      "epalsed time =  -1.910527547200521e-05\n",
      "LR =  0.00014877080647090322\n",
      "e =  5900\n",
      "epalsed time =  -1.6550223032633465e-05\n",
      "LR =  0.00014872817755132912\n",
      "e =  6000\n",
      "epalsed time =  -1.6903877258300783e-05\n",
      "LR =  0.00014868482836660513\n",
      "e =  6100\n",
      "epalsed time =  -1.715819040934245e-05\n",
      "LR =  0.00014864075934457012\n",
      "e =  6200\n",
      "epalsed time =  -1.782973607381185e-05\n",
      "LR =  0.00014859597092016754\n",
      "e =  6300\n",
      "epalsed time =  -1.851320266723633e-05\n",
      "LR =  0.0001485504635354411\n",
      "e =  6400\n",
      "epalsed time =  -1.857280731201172e-05\n",
      "LR =  0.00014850423763953033\n",
      "e =  6500\n",
      "epalsed time =  -1.8123785654703776e-05\n",
      "LR =  0.00014845729368866608\n",
      "e =  6600\n",
      "epalsed time =  -1.8596649169921875e-05\n",
      "LR =  0.00014840963214616629\n",
      "e =  6700\n",
      "epalsed time =  -1.8505255381266274e-05\n",
      "LR =  0.00014836125348243107\n",
      "e =  6800\n",
      "epalsed time =  -2.475579579671224e-05\n",
      "LR =  0.00014831215817493834\n",
      "e =  6900\n",
      "epalsed time =  -1.9145011901855468e-05\n",
      "LR =  0.00014826234670823897\n",
      "e =  7000\n",
      "epalsed time =  -1.705487569173177e-05\n",
      "LR =  0.00014821181957395198\n",
      "e =  7100\n",
      "epalsed time =  -1.6136964162190756e-05\n",
      "LR =  0.00014816057727075983\n",
      "e =  7200\n",
      "epalsed time =  -1.806020736694336e-05\n",
      "LR =  0.00014810862030440334\n",
      "e =  7300\n",
      "epalsed time =  -1.8175443013509115e-05\n",
      "LR =  0.0001480559491876768\n",
      "e =  7400\n",
      "epalsed time =  -1.8612543741861978e-05\n",
      "LR =  0.0001480025644404229\n",
      "e =  7500\n",
      "epalsed time =  -1.8624464670817056e-05\n",
      "LR =  0.00014794846658952747\n",
      "e =  7600\n",
      "epalsed time =  -1.8548965454101562e-05\n",
      "LR =  0.00014789365616891452\n",
      "e =  7700\n",
      "epalsed time =  -1.8346309661865235e-05\n",
      "LR =  0.00014783813371954077\n",
      "e =  7800\n",
      "epalsed time =  -2.031723658243815e-05\n",
      "LR =  0.00014778189978939034\n",
      "e =  7900\n",
      "epalsed time =  -1.6621748606363933e-05\n",
      "LR =  0.00014772495493346944\n",
      "e =  8000\n",
      "epalsed time =  -1.848936080932617e-05\n",
      "LR =  0.00014766729971380085\n",
      "e =  8100\n",
      "epalsed time =  -1.8302599589029948e-05\n",
      "LR =  0.00014760893469941823\n",
      "e =  8200\n",
      "epalsed time =  -1.8322467803955077e-05\n",
      "LR =  0.00014754986046636078\n",
      "e =  8300\n",
      "epalsed time =  -1.8366177876790364e-05\n",
      "LR =  0.00014749007759766732\n",
      "e =  8400\n",
      "epalsed time =  -1.8723805745442708e-05\n",
      "LR =  0.00014742958668337056\n",
      "e =  8500\n",
      "epalsed time =  -1.7094612121582032e-05\n",
      "LR =  0.0001473683883204915\n",
      "e =  8600\n",
      "epalsed time =  -1.66932741800944e-05\n",
      "LR =  0.0001473064831130332\n",
      "e =  8700\n",
      "epalsed time =  -1.829067866007487e-05\n",
      "LR =  0.00014724387167197513\n",
      "e =  8800\n",
      "epalsed time =  -1.8413861592610677e-05\n",
      "LR =  0.00014718055461526686\n",
      "e =  8900\n",
      "epalsed time =  -1.8588701883951823e-05\n",
      "LR =  0.00014711653256782223\n",
      "e =  9000\n",
      "epalsed time =  -1.8445650736490884e-05\n",
      "LR =  0.00014705180616151302\n",
      "e =  9100\n",
      "epalsed time =  -1.853307088216146e-05\n",
      "LR =  0.00014698637603516266\n",
      "e =  9200\n",
      "epalsed time =  -1.873970031738281e-05\n",
      "LR =  0.00014692024283454014\n",
      "e =  9300\n",
      "epalsed time =  -1.694361368815104e-05\n",
      "LR =  0.00014685340721235342\n",
      "e =  9400\n",
      "epalsed time =  -1.7972787221272788e-05\n",
      "LR =  0.00014678586982824315\n",
      "e =  9500\n",
      "epalsed time =  -1.930395762125651e-05\n",
      "LR =  0.00014671763134877598\n",
      "e =  9600\n",
      "epalsed time =  -2.3563702901204426e-05\n",
      "LR =  0.00014664869244743824\n",
      "e =  9700\n",
      "epalsed time =  -1.8811225891113283e-05\n",
      "LR =  0.00014657905380462897\n",
      "e =  9800\n",
      "epalsed time =  -1.885096232096354e-05\n",
      "LR =  0.0001465087161076535\n",
      "e =  9900\n",
      "epalsed time =  -1.8727779388427734e-05\n",
      "LR =  0.00014643768005071647\n",
      "e =  10000\n",
      "epalsed time =  -1.7523765563964844e-05\n",
      "LR =  0.00014636594633491513\n",
      "e =  10100\n",
      "epalsed time =  -1.8878777821858725e-05\n",
      "LR =  0.00014629351566823227\n",
      "e =  10200\n",
      "epalsed time =  -1.9196669260660807e-05\n",
      "LR =  0.00014622038876552936\n",
      "e =  10300\n",
      "epalsed time =  -1.902182896931966e-05\n",
      "LR =  0.00014614656634853935\n",
      "e =  10400\n",
      "epalsed time =  -1.9176801045735678e-05\n",
      "LR =  0.00014607204914585977\n",
      "e =  10500\n",
      "epalsed time =  -1.7325083414713543e-05\n",
      "LR =  0.00014599683789294523\n",
      "e =  10600\n",
      "epalsed time =  -1.7321109771728517e-05\n",
      "LR =  0.0001459209333321005\n",
      "e =  10700\n",
      "epalsed time =  -1.820723215738932e-05\n",
      "LR =  0.00014584433621247294\n",
      "e =  10800\n",
      "epalsed time =  -1.8827120463053386e-05\n",
      "LR =  0.00014576704729004516\n",
      "e =  10900\n",
      "epalsed time =  -1.9085407257080077e-05\n",
      "LR =  0.0001456890673276277\n",
      "e =  11000\n",
      "epalsed time =  -1.6931692759195963e-05\n",
      "LR =  0.00014561039709485123\n",
      "e =  11100\n",
      "epalsed time =  -1.918474833170573e-05\n",
      "LR =  0.00014553103736815923\n",
      "e =  11200\n",
      "epalsed time =  -2.2844473520914713e-05\n",
      "LR =  0.00014545098893080014\n",
      "e =  11300\n",
      "epalsed time =  -1.8898646036783854e-05\n",
      "LR =  0.00014537025257281973\n",
      "e =  11400\n",
      "epalsed time =  -1.6637643178304036e-05\n",
      "LR =  0.00014528882909105328\n",
      "e =  11500\n",
      "epalsed time =  -1.6891956329345702e-05\n",
      "LR =  0.00014520671928911765\n",
      "e =  11600\n",
      "epalsed time =  -1.8827120463053386e-05\n",
      "LR =  0.00014512392397740345\n",
      "e =  11700\n",
      "epalsed time =  -1.852114995320638e-05\n",
      "LR =  0.00014504044397306695\n",
      "e =  11800\n",
      "epalsed time =  -1.888275146484375e-05\n",
      "LR =  0.00014495628010002216\n",
      "nan in the model op..\n",
      "Parameter containing:\n",
      "tensor([[[[ 4.2180e-03,  9.5649e-02, -4.9583e-03,  8.1819e-03],\n",
      "          [-5.8911e-02,  1.3602e-02,  2.5282e-02,  2.0166e-02],\n",
      "          [-6.2506e-03,  1.1354e-02, -4.0258e-03,  1.3933e-02],\n",
      "          [-2.3168e-02, -2.0627e-02, -1.7175e-02, -2.1060e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.0651e-03,  3.1312e-03,  1.9952e-03,  3.1591e-03],\n",
      "          [-2.4839e-03,  1.0722e-02, -1.1426e-02, -2.6469e-03],\n",
      "          [ 6.1442e-03,  9.3519e-04, -3.2319e-03, -1.0976e-03],\n",
      "          [-1.4338e-02, -3.4933e-03, -1.9621e-02, -9.2841e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5193e-02,  7.1082e-02, -1.5788e-02, -9.3810e-02],\n",
      "          [-1.2157e-01, -1.5314e-01,  1.9260e-01,  4.5854e-02],\n",
      "          [-6.7268e-03, -8.6742e-02,  1.0379e-01,  6.2118e-02],\n",
      "          [ 1.3663e-01,  3.5050e-02, -1.6570e-01, -3.3725e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 7.2856e-04,  8.8309e-03,  3.5304e-03, -9.1638e-05],\n",
      "          [ 5.3541e-03,  7.8226e-03, -5.3321e-03,  3.8263e-03],\n",
      "          [ 2.7961e-03,  7.1013e-03,  9.7385e-04,  6.5752e-03],\n",
      "          [-1.7144e-03,  4.0382e-03, -3.9342e-03, -3.5589e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0695e-03, -2.6520e-02, -4.3573e-02,  1.4357e-02],\n",
      "          [ 3.6722e-02, -2.9083e-02, -3.3756e-02,  1.2545e-02],\n",
      "          [-2.1870e-02, -8.9321e-02, -4.0081e-02,  1.0872e-01],\n",
      "          [-4.3786e-02, -5.6566e-02, -1.3231e-02,  2.8022e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2382e-02,  1.5871e-02,  1.0204e-02, -3.0950e-03],\n",
      "          [-4.6975e-02,  5.5391e-02, -1.2474e-02,  7.1921e-03],\n",
      "          [-7.8356e-02,  7.8053e-02, -1.4650e-04,  1.5364e-02],\n",
      "          [ 1.6606e-02,  6.6075e-02, -5.2945e-02, -3.4883e-02]]]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ebdb3de68c0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#filepath = \"../../models/model_e73_2022_10_08_07_44_27.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model_epcoh_99 = load_model(filepath,model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbackbone_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model =MyModel('convnext_xlarge_in22k',224)\n",
    "#model =Model('convnext_small',224)\n",
    "#filepath = \"../../models/model_e73_2022_10_08_07_44_27.pth\"\n",
    "#model_epcoh_99 = load_model(filepath,model)\n",
    "backbone_param,_ = train_model(model, num_epochs = num_epochs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939fbec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath, model=Model('convnext_small',224)):\n",
    "    # Instantiate model to inspect\n",
    "    print(\"Filepath = \" + str(filepath))\n",
    "    print(\"model = \" +str(model))\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    print(f'Training on {device}')\n",
    "        \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using data parallel\")\n",
    "        model = nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "    model = model.to(device)\n",
    "    # Load trained parameters from checkpoint (may need to download from S3 first)\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        map_location=lambda storage, loc: storage.cuda()\n",
    "    else:\n",
    "        map_location='cpu'\n",
    "        \n",
    "    checkpoint = model.load_state_dict(torch.load(filepath))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90622a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len of all_train_f1 = \"+str(len(all_train_f1)))\n",
    "print(\"len of all_val_f1 = \"+str(len(all_val_f1)))\n",
    "print(\"len of all_val_loss = \"+str(len(all_val_loss)))\n",
    "print(\"len of all_train_loss = \"+str(len(all_train_loss)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0c5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53fad76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aae1996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d318f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eef370",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_val_f1_final =  [v for i, v in enumerate(all_val_f1) if i % 2 == 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d80496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_val_loss_final =  [v for i, v in enumerate(all_val_loss) if i % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b5ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_f1_final =  [v for i, v in enumerate(all_train_f1) if i % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b73b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_train_f1_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ccc789",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_train_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80958cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame({'train_loss':all_train_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e38c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df['val_f1'] = all_val_f1_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f162c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df['train_f1'] = all_train_f1_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df['val_loss'] = all_val_loss_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d65a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.fillna(0)\n",
    "plot_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebcc76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.iloc[129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3cec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lineplot(plot_df['train_f1','val_f1']);\n",
    "plt.figure(figsize=(8,6)) \n",
    "sns.lineplot(plot_df[['train_f1','val_f1']])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"F1 Score - ConvNext Small\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b15ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6)) \n",
    "sns.lineplot(plot_df[['train_loss','val_loss']])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss - ConvNext Small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97eaac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('file1.csv')\n",
    "plot_df.to_csv(\"plot_df_convNext_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffcc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ede88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_train_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e815f846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0473576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_new = MozTestDataset(df_val_offset,  config.data_dir, min_length)\n",
    "val_loader_new = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=2,\n",
    "        num_workers=0, pin_memory=pin_memory  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ca29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error = df_val_offset\n",
    "model = model_epcoh_10\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "for idx,(x,y) in enumerate(val_dataset):\n",
    "    print(idx)\n",
    "    print(y)\n",
    "    x = x.to('cuda').float()\n",
    "    print(\"x shape = \" +str(x.shape))\n",
    "    #x_new = x.unsqueeze(dim = 1)\n",
    "    print(\"x_new shape = \" +str(x_new.shape))\n",
    "    x_new = x.to('cuda')\n",
    "    y_pred = model(x_new)['prediction']\n",
    "    y_pred_cpu = y_pred.cpu().detach()\n",
    "    preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "    df_erroriloc[idx]['y_hat'] = preds\n",
    "    del x_new\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e953bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,15360)\n",
    "x = x.unsqueeze(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70bb82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_offset.head()\n",
    "path_temp = \"../data/audio/\"\n",
    "for i,row in df_val_offset.iterrows():\n",
    "    print(\"i = \" +str(i))\n",
    "    print(\"id = \" + str(int(row['id'])))\n",
    "    file = str(int(row['id']))+\".wav\"\n",
    "    print(file)\n",
    "    path = path_temp + file\n",
    "    waveform, inp_rate = torchaudio.load(path)\n",
    "    if inp_rate != config.rate:\n",
    "        import torchaudio.transforms as T\n",
    "        resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "        waveform = resampler(waveform)\n",
    "    if waveform.shape[1] < config.rate*min_length:\n",
    "        #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "        f_out = pad_mean(waveform)\n",
    "    else:\n",
    "        f = waveform[0]\n",
    "        f_out = f.unsqueeze(0)\n",
    "    \n",
    "    \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc8a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor(df):\n",
    "    \n",
    "    path_name = \"../data/audio/\"\n",
    "    file = df.loc[idx]['id'])}.wav\")\n",
    "    waveform, inp_rate = torchaudio.load(path)\n",
    "        \n",
    "        if inp_rate != config.rate:\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "            waveform = resampler(waveform)\n",
    "    \n",
    "        \n",
    "        #waveform, rate = torchaudio.load(path)\n",
    "                \n",
    "        if waveform.shape[1] < config.rate*self.min_length:\n",
    "            #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "            f_out = pad_mean(waveform)\n",
    "        else:\n",
    "            f = waveform[0]\n",
    "            f_out = f.unsqueeze(0)\n",
    "            \n",
    "        return f_out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #real_idx = idx % len(self.audio_df)\n",
    "        if DEBUG:\n",
    "            print(\"\")\n",
    "            print(\"idx = \" + str(idx))\n",
    "        x = self._get_sample_(os.path.join(self.data_dir,f\"{int(self.audio_df.loc[idx]['id'])}.wav\"), resample=config.rate)\n",
    "        \n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"shape of x post augmentation = \" + str(x.shape))\n",
    "            \n",
    "        \n",
    "        # random noise on even number indexes\n",
    "        offset = int(self.audio_df.loc[idx]['offset'])\n",
    "        if DEBUG:\n",
    "            print(\"returning x of shape ...\" + str(x[:,offset:int(offset+config.rate*self.min_length)].shape))\n",
    "        \n",
    "        return (x[:,offset:int(offset+config.rate*self.min_length)],self.audio_df.loc[idx]['specie_ind'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a2b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the model checkpoint as a parameter as input\n",
    "# read the val df\n",
    "#get the tensor rep for the offset.\n",
    "#pass it to the model get add get the prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "pred = []\n",
    "for i in range(10):\n",
    "    label.append(np.random.rand(9))\n",
    "    pred.append(np.random.rand(9))\n",
    "print(label)\n",
    "print(pred)\n",
    "print(classification_report(label, pred, target_names= classes, labels= classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23411d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.tensor(8, device = \"cuda\")\n",
    "print(label)\n",
    "label_cpu = label.cpu().detach()\n",
    "print(label_cpu)\n",
    "label_np = label_cpu.numpy()\n",
    "print(type(label_np))\n",
    "label_np_item = label_np.item()\n",
    "print(type(label_np_item))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd6d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.randn(4,9)\n",
    "y_pred.shape\n",
    "#y_pred_np = y_pred.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15506fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_np\n",
    "# y_pred_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b43d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(y_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee48a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeeb555",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,(x,y) in enumerate(test_loader):\n",
    "    print(\"idx = \" + str(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c69d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea36c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ddfaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
