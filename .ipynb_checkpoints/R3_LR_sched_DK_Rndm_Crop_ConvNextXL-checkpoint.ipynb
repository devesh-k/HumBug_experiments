{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7bc7b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/task/ComParE2022_VecNet/notebooks/DK\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9af3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".CodeMirror{\n",
       "font-size: 14px;\n",
       "</style>\n",
       "CUDA_LAUNCH_BLOCKING=1\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "font-size: 14px;\n",
    "</style>\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f68fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41321f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://zenodo.org/record/4904800/files/humbugdb_neurips_2021_1.zip?download=1\n",
    "# !wget https://zenodo.org/record/4904800/files/humbugdb_neurips_2021_2.zip?download=1\n",
    "# !wget https://zenodo.org/record/4904800/files/humbugdb_neurips_2021_3.zip?download=1\n",
    "# !wget https://zenodo.org/record/4904800/files/humbugdb_neurips_2021_4.zip?download=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd636f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip /content/humbugdb_neurips_2021_1.zip?download=1 -d '/content/HumBugDB/data/audio'\n",
    "# !unzip /content/humbugdb_neurips_2021_2.zip?download=1 -d '/content/HumBugDB/data/audio'\n",
    "# !unzip /content/humbugdb_neurips_2021_3.zip?download=1 -d '/content/HumBugDB/data/audio'\n",
    "# !unzip /content/humbugdb_neurips_2021_4.zip?download=1 -d '/content/HumBugDB/data/audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7446688e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch_audiomentations in /opt/conda/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: torchaudio>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from torch_audiomentations) (0.11.0+cu113)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in /opt/conda/lib/python3.8/site-packages (from torch_audiomentations) (0.2.7)\n",
      "Requirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.8/site-packages (from torch_audiomentations) (1.11.0+cu113)\n",
      "Requirement already satisfied: librosa>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from torch_audiomentations) (0.8.1)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /opt/conda/lib/python3.8/site-packages (from torch_audiomentations) (1.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (21.3)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (2.1.9)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (5.1.0)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (1.6.3)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (0.24.0)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (0.10.3.post1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (0.2.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (1.21.4)\n",
      "Requirement already satisfied: numba>=0.43.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (0.53.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from numba>=0.43.0->librosa>=0.6.0->torch_audiomentations) (59.4.0)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/lib/python3.8/site-packages (from numba>=0.43.0->librosa>=0.6.0->torch_audiomentations) (0.36.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->librosa>=0.6.0->torch_audiomentations) (3.0.6)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (1.4.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (2.26.0)\n",
      "Requirement already satisfied: six>=1.3 in /opt/conda/lib/python3.8/site-packages (from resampy>=0.2.2->librosa>=0.6.0->torch_audiomentations) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.6.0->torch_audiomentations) (3.0.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.8/site-packages (from soundfile>=0.10.2->librosa>=0.6.0->torch_audiomentations) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.6.0->torch_audiomentations) (2.21)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.0->torch_audiomentations) (4.0.1)\n",
      "Requirement already satisfied: primePy>=1.3 in /opt/conda/lib/python3.8/site-packages (from torch-pitch-shift>=1.2.2->torch_audiomentations) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (1.26.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.21.4)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.5.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.3.2)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (6.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.28.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.25->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib!=3.6.1,>=3.1->seaborn) (1.2.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib!=3.6.1,>=3.1->seaborn) (59.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_audiomentations\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d67b4d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_audiomentations import Compose,AddBackgroundNoise , AddColoredNoise , ApplyImpulseResponse,PeakNormalization,TimeInversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95500997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to find the right version of pytorch with the widget here https://pytorch.org/\n",
    "# I *think* this will work with AWS\n",
    "#!pip3 install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e60512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other dependencies\n",
    "#!pip install timm ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "421ec65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nnAudio\n",
    "#!pip install git+https://github.com/KinWaiCheuk/nnAudio.git#subdirectory=Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f87296a",
   "metadata": {},
   "source": [
    "### 1 Import the kitchen sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6cb6ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n"
     ]
    }
   ],
   "source": [
    "%env CUBLAS_WORKSPACE_CONFIG=:4096:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a32470a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/task/ComParE2022_VecNet/notebooks/DK\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf9bb16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# humbug main imports\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../../src'))\n",
    "import config ,config_pytorch\n",
    "from evaluate import get_results\n",
    "import numpy as np\n",
    "\n",
    "# Troubleshooting and visualisation\n",
    "import IPython.display as ipd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bfb3b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# humbug lib imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "#from PyTorch import config_pytorch\n",
    "from datetime import datetime\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a883daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional pytorch tools\n",
    "import random\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torchvision.transforms as VT\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "import timm\n",
    "import timm.optim\n",
    "from timm.loss import BinaryCrossEntropy\n",
    "from timm.utils import NativeScaler\n",
    "from timm.models import model_parameters\n",
    "from glob import glob\n",
    "from torch_audiomentations import Compose, Gain, PolarityInversion,AddColoredNoise,ApplyImpulseResponse,PeakNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b43ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nnAudio\n",
    "from nnAudio import features\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "087c4fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8b4255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "591b90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Training variables \n",
    "USE_SHORT_AUDIO = True\n",
    "num_workers= 8\n",
    "pin_memory=True\n",
    "#train_size = 100\n",
    "batch_size = 32\n",
    "test_batch_size = 32\n",
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    batch_size = 4\n",
    "    test_batch_size = 4\n",
    "    num_workers=1\n",
    "    \n",
    "     \n",
    "\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75adb0f",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f83ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d5874ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates 1.92 secs rows of audio in a data frame format\n",
    "def get_offsets_df(df, short_audio=False):\n",
    "    audio_offsets = []\n",
    "    #This is same as defined in config -min_duration = win_size * frame_duration\n",
    "    min_length = config.win_size*config.NFFT/(((1/config.n_hop)*config.NFFT)*config.rate)\n",
    "    step_frac = config.step_size/config.win_size\n",
    "    stride = step_frac*min_length\n",
    "#     print(\"min_length = \" +str(min_length))\n",
    "#     print(\"step_frac = \" +str(step_frac))\n",
    "#     print(\"stride = \" +str(stride))\n",
    "    for _,row in df.iterrows():\n",
    "        #processed_data keeps track of the tensor_values processed thus far\n",
    "        if row['length'] > min_length:\n",
    "            processed_data = 0\n",
    "            #total_data is the total tensor present in the audio\n",
    "            total_data = config.rate*row['length']\n",
    "            #print(\"********\")\n",
    "            count = 0\n",
    "            #print(\"count = \" +str(count))\n",
    "            #print(\"id = \" + str(row['id']) + \" duration = \" +str(row['length']) + \"total x vals = \" + str(total_data))\n",
    "            inner_loop_flag = False\n",
    "            #print(\"going into the inner loop to offset....\")\n",
    "            while(processed_data < total_data):\n",
    "                #print(\"inside inner loop.....\")\n",
    "                start = count*stride*config.rate\n",
    "                #now find out the row_len\n",
    "                if total_data - (start + min_length*config.rate) >= 0:\n",
    "                    #print(\"full chunk \")\n",
    "                    row_len = min_length\n",
    "                    end = start + row_len*config.rate\n",
    "                    audio_offsets.append({'id':row['id'], 'offset':count, 'length': row_len,'specie_ind': row['specie_ind'],'start':start,'end':end})\n",
    "                    #print(\"count = \" +str(count) + \"offset = \" +str(count) + \"start = \" +str(start) + \"end = \" +str(end))\n",
    "                    #print(\"for count.... = \" + str(count) + \"processed data = \" +str(processed_data))\n",
    "                    count+=1\n",
    "                    processed_data = (count*stride)*config.rate\n",
    "                    \n",
    "                else:\n",
    "                    inner_loop_flag = True\n",
    "                    break\n",
    "                    \n",
    "                                                       \n",
    "            #for processing residual data\n",
    "            if(inner_loop_flag):\n",
    "                #print(\"processing residual ....processed \" +str(processed_data) + \" of \" + str(total_data))\n",
    "                start = count*stride*config.rate\n",
    "                resid_durn = round((total_data - processed_data)/config.rate,2)\n",
    "                end = total_data\n",
    "                #print(\"for...\" + str(row['id']) + \" adding the residual data in the data frame with duration = \" + str(resid_durn))\n",
    "                audio_offsets.append({'id':row['id'], 'offset':count, 'length':resid_durn ,'specie_ind': row['specie_ind'],'start':start,'end':end})\n",
    "            \n",
    "        elif short_audio:\n",
    "            start = 0\n",
    "            end = row['length']*config.rate\n",
    "            audio_offsets.append({'id':row['id'], 'offset':0,'length': row['length'],'specie_ind': row['specie_ind'],'start':0 , 'end':end})\n",
    "    return pd.DataFrame(audio_offsets)       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27224876",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['an arabiensis','culex pipiens complex', 'ae aegypti','an funestus ss','an squamosus',\n",
    "               'an coustani','ma uniformis','ma africanus' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d875a60",
   "metadata": {},
   "source": [
    "### Read CSV and get train/test groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab0181d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>name</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>record_datetime</th>\n",
       "      <th>sound_type</th>\n",
       "      <th>species</th>\n",
       "      <th>gender</th>\n",
       "      <th>fed</th>\n",
       "      <th>plurality</th>\n",
       "      <th>age</th>\n",
       "      <th>method</th>\n",
       "      <th>mic_type</th>\n",
       "      <th>device_type</th>\n",
       "      <th>country</th>\n",
       "      <th>district</th>\n",
       "      <th>province</th>\n",
       "      <th>place</th>\n",
       "      <th>location_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>0.463456</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>0.170249</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>0.104041</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>0.274290</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56</td>\n",
       "      <td>0.420894</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>3562</td>\n",
       "      <td>6.083093</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000</th>\n",
       "      <td>3556</td>\n",
       "      <td>6.719908</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an maculatus</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9009</th>\n",
       "      <td>3553</td>\n",
       "      <td>6.128580</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an maculatus</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9011</th>\n",
       "      <td>3561</td>\n",
       "      <td>11.614280</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9012</th>\n",
       "      <td>3552</td>\n",
       "      <td>2.920249</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6008 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     length                             name  sample_rate  \\\n",
       "1       53   0.463456  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "2       57   0.170249  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "3       61   0.104041  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "4       69   0.274290  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "5       56   0.420894  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "...    ...        ...                              ...          ...   \n",
       "8999  3562   6.083093                    #988-1001.wav        44100   \n",
       "9000  3556   6.719908                    #988-1001.wav        44100   \n",
       "9009  3553   6.128580                    #988-1001.wav        44100   \n",
       "9011  3561  11.614280                    #988-1001.wav        44100   \n",
       "9012  3552   2.920249                    #988-1001.wav        44100   \n",
       "\n",
       "     record_datetime sound_type       species  gender  fed plurality  age  \\\n",
       "1      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "2      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "3      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "4      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "5      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Plural  NaN   \n",
       "...              ...        ...           ...     ...  ...       ...  ...   \n",
       "8999  1/7/2018 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "9000  1/7/2018 12:00   mosquito  an maculatus  Female    t    Single  NaN   \n",
       "9009  1/7/2018 12:00   mosquito  an maculatus  Female    t    Single  NaN   \n",
       "9011  1/7/2018 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "9012  1/7/2018 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "\n",
       "     method mic_type    device_type   country          district  \\\n",
       "1       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "2       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "3       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "4       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "5       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "...     ...      ...            ...       ...               ...   \n",
       "8999    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9000    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9009    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9011    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9012    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "\n",
       "                   province                            place location_type  \n",
       "1                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "2                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "3                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "4                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "5                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "...                     ...                              ...           ...  \n",
       "8999  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9000  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9009  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9011  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9012  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "\n",
       "[6008 rows x 19 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if DEBUG:\n",
    "#     df = pd.read_csv(config.data_df_msc_test)\n",
    "# else:\n",
    "df = pd.read_csv(config.data_df)\n",
    "\n",
    "#df = df.loc[df['Grade'].notnull()]\n",
    "df = df.loc[df['species'].notnull()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d457609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a colum for specie encoding\n",
    "df['specie_ind'] = \"NULL_VAL\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2a72fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specie = an arabiensisand its index = 0\n",
      "specie = culex pipiens complexand its index = 1\n",
      "specie = ae aegyptiand its index = 2\n",
      "specie = an funestus ssand its index = 3\n",
      "specie = an squamosusand its index = 4\n",
      "specie = an coustaniand its index = 5\n",
      "specie = ma uniformisand its index = 6\n",
      "specie = ma africanusand its index = 7\n"
     ]
    }
   ],
   "source": [
    "# Adding a new column to encode specie_index in the same order as the list \"classes\"\n",
    "ind = 0\n",
    "for specie in classes:\n",
    "    print(\"specie = \" + str(specie) + \"and its index = \" + str(ind) )\n",
    "    row_indexes=df[df['species']==specie].index \n",
    "    df.loc[row_indexes,'specie_ind']= ind\n",
    "    ind+=1\n",
    "\n",
    "    \n",
    "# other_df_ind = df[df['specie_ind'] == \"NULL_VAL\"].index\n",
    "# df.loc[other_df_ind,'specie_ind']= other_ind                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "579c2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['specie_ind'] == \"NULL_VAL\"].index, inplace=True)\n",
    "#other_df_ind = df[df['specie_ind'] == \"NULL_VAL\"].index\n",
    "#df.loc[other_df_ind,'specie_ind']= other_ind        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f2a77a",
   "metadata": {},
   "source": [
    "At this stage we have all extracted the data with specie information and have encoded the specie encoding in a col = 'specie_ind'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e20d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3c35951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the TZ and Cup data- this is as per the humbug paper\n",
    "\n",
    "idx_multiclass = np.logical_and(df['country'] == 'Tanzania', df['location_type'] == 'cup')\n",
    "df_all = df[idx_multiclass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "628dd76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d98841a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>name</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>record_datetime</th>\n",
       "      <th>sound_type</th>\n",
       "      <th>species</th>\n",
       "      <th>gender</th>\n",
       "      <th>fed</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>method</th>\n",
       "      <th>mic_type</th>\n",
       "      <th>device_type</th>\n",
       "      <th>country</th>\n",
       "      <th>district</th>\n",
       "      <th>province</th>\n",
       "      <th>place</th>\n",
       "      <th>location_type</th>\n",
       "      <th>specie_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1879</td>\n",
       "      <td>221103</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_24_664.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1880</td>\n",
       "      <td>221111</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_25_665.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1881</td>\n",
       "      <td>221110</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_25_665.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1882</td>\n",
       "      <td>221149</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_26_666.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an arabiensis</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1883</td>\n",
       "      <td>221150</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_26_666.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an arabiensis</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>4546</td>\n",
       "      <td>222615</td>\n",
       "      <td>30.72</td>\n",
       "      <td>IFA_86_39_3439.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>4547</td>\n",
       "      <td>222585</td>\n",
       "      <td>25.60</td>\n",
       "      <td>IFA_86_40_3440.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>4548</td>\n",
       "      <td>222586</td>\n",
       "      <td>40.90</td>\n",
       "      <td>IFA_87_10_3450.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>4549</td>\n",
       "      <td>222596</td>\n",
       "      <td>40.90</td>\n",
       "      <td>IFA_87_11_3451.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>4550</td>\n",
       "      <td>222614</td>\n",
       "      <td>38.40</td>\n",
       "      <td>IFA_87_12_3452.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2288 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      id  length                name  sample_rate record_datetime  \\\n",
       "0      1879  221103    2.56   IFA_17_24_664.wav        44100  30-01-20 00:00   \n",
       "1      1880  221111    2.56   IFA_17_25_665.wav        44100  30-01-20 00:00   \n",
       "2      1881  221110    2.56   IFA_17_25_665.wav        44100  30-01-20 00:00   \n",
       "3      1882  221149    2.56   IFA_17_26_666.wav        44100  30-01-20 00:00   \n",
       "4      1883  221150    2.56   IFA_17_26_666.wav        44100  30-01-20 00:00   \n",
       "...     ...     ...     ...                 ...          ...             ...   \n",
       "2283   4546  222615   30.72  IFA_86_39_3439.wav        44100  23-08-20 00:00   \n",
       "2284   4547  222585   25.60  IFA_86_40_3440.wav        44100  23-08-20 00:00   \n",
       "2285   4548  222586   40.90  IFA_87_10_3450.wav        44100  23-08-20 00:00   \n",
       "2286   4549  222596   40.90  IFA_87_11_3451.wav        44100  23-08-20 00:00   \n",
       "2287   4550  222614   38.40  IFA_87_12_3452.wav        44100  23-08-20 00:00   \n",
       "\n",
       "     sound_type         species  gender fed  ... age  method mic_type  \\\n",
       "0      mosquito    ma africanus  Female   f  ... NaN     HBN  telinga   \n",
       "1      mosquito    ma africanus  Female   f  ... NaN     HBN  telinga   \n",
       "2      mosquito    ma africanus  Female   f  ... NaN     HBN  telinga   \n",
       "3      mosquito   an arabiensis  Female   f  ... NaN     HBN  telinga   \n",
       "4      mosquito   an arabiensis  Female   f  ... NaN     HBN  telinga   \n",
       "...         ...             ...     ...  ..  ...  ..     ...      ...   \n",
       "2283   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2284   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2285   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2286   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2287   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "\n",
       "     device_type   country            district  province    place  \\\n",
       "0         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "1         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "3         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "4         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "...          ...       ...                 ...       ...      ...   \n",
       "2283      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2284      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2285      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2286      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2287      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "\n",
       "     location_type specie_ind  \n",
       "0              cup          7  \n",
       "1              cup          7  \n",
       "2              cup          7  \n",
       "3              cup          0  \n",
       "4              cup          0  \n",
       "...            ...        ...  \n",
       "2283           cup          3  \n",
       "2284           cup          3  \n",
       "2285           cup          3  \n",
       "2286           cup          3  \n",
       "2287           cup          3  \n",
       "\n",
       "[2288 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acea444c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "import seaborn as sns\n",
    "sns.countplot(x = 'species', data = df_all , ax = ax , hue = 'gender',palette='dark')\n",
    "#ax.bar_label(ax.containers[0])\n",
    "#ax.bar_label(ax.containers[-1], fmt='Count:\\n%.2f', label_type='center')\n",
    "plt.xticks(rotation=90 )\n",
    "plt.title(\"Distribution of Species \")\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('axes', labelsize=15)\n",
    "plt.rc('figure', titlesize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd1ef8d",
   "metadata": {},
   "source": [
    "### Train-Test split( avoiding sklearn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82dc1434",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "msk_test = np.random.rand(len(df_all)) < 0.2\n",
    "df_test = df_all[msk_test]\n",
    "df_train_temp  = df_all[~msk_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24df62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "msk_train = np.random.rand(len(df_train_temp)) < 0.2\n",
    "df_val = df_train_temp[msk_train]\n",
    "df_train  = df_train_temp[~msk_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09f9c6d",
   "metadata": {},
   "source": [
    "## Let's verify for data leakage by performing an inner-join on id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e6b1b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>length_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>sample_rate_x</th>\n",
       "      <th>record_datetime_x</th>\n",
       "      <th>sound_type_x</th>\n",
       "      <th>species_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>fed_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_y</th>\n",
       "      <th>method_y</th>\n",
       "      <th>mic_type_y</th>\n",
       "      <th>device_type_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>district_y</th>\n",
       "      <th>province_y</th>\n",
       "      <th>place_y</th>\n",
       "      <th>location_type_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, length_x, name_x, sample_rate_x, record_datetime_x, sound_type_x, species_x, gender_x, fed_x, plurality_x, age_x, method_x, mic_type_x, device_type_x, country_x, district_x, province_x, place_x, location_type_x, specie_ind_x, index_y, length_y, name_y, sample_rate_y, record_datetime_y, sound_type_y, species_y, gender_y, fed_y, plurality_y, age_y, method_y, mic_type_y, device_type_y, country_y, district_y, province_y, place_y, location_type_y, specie_ind_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_test,df_train, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d963aaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>length_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>sample_rate_x</th>\n",
       "      <th>record_datetime_x</th>\n",
       "      <th>sound_type_x</th>\n",
       "      <th>species_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>fed_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_y</th>\n",
       "      <th>method_y</th>\n",
       "      <th>mic_type_y</th>\n",
       "      <th>device_type_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>district_y</th>\n",
       "      <th>province_y</th>\n",
       "      <th>place_y</th>\n",
       "      <th>location_type_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, length_x, name_x, sample_rate_x, record_datetime_x, sound_type_x, species_x, gender_x, fed_x, plurality_x, age_x, method_x, mic_type_x, device_type_x, country_x, district_x, province_x, place_x, location_type_x, specie_ind_x, index_y, length_y, name_y, sample_rate_y, record_datetime_y, sound_type_y, species_y, gender_y, fed_y, plurality_y, age_y, method_y, mic_type_y, device_type_y, country_y, district_y, province_y, place_y, location_type_y, specie_ind_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_test,df_val, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50ffcc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>length_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>sample_rate_x</th>\n",
       "      <th>record_datetime_x</th>\n",
       "      <th>sound_type_x</th>\n",
       "      <th>species_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>fed_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_y</th>\n",
       "      <th>method_y</th>\n",
       "      <th>mic_type_y</th>\n",
       "      <th>device_type_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>district_y</th>\n",
       "      <th>province_y</th>\n",
       "      <th>place_y</th>\n",
       "      <th>location_type_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, length_x, name_x, sample_rate_x, record_datetime_x, sound_type_x, species_x, gender_x, fed_x, plurality_x, age_x, method_x, mic_type_x, device_type_x, country_x, district_x, province_x, place_x, location_type_x, specie_ind_x, index_y, length_y, name_y, sample_rate_y, record_datetime_y, sound_type_y, species_y, gender_y, fed_y, plurality_y, age_y, method_y, mic_type_y, device_type_y, country_y, district_y, province_y, place_y, location_type_y, specie_ind_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_train,df_val, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b9845",
   "metadata": {},
   "source": [
    "We've confirmed that there is no recording that is common in Train,Test,val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0cc7dc",
   "metadata": {},
   "source": [
    "### Next, we perform \"offsets\", spliting each(long) recording into multiple 1.92 secs chunk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b3e5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_offset = get_offsets_df(df_train, short_audio=USE_SHORT_AUDIO)\n",
    "df_test_offset = get_offsets_df(df_test, short_audio=USE_SHORT_AUDIO)\n",
    "df_val_offset = get_offsets_df(df_val, short_audio=USE_SHORT_AUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "365954cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train offset = 35043\n",
      "length of test offset = 11043\n",
      "length of val offset = 9466\n"
     ]
    }
   ],
   "source": [
    "print(\"length of train offset = \" +str(len(df_train_offset)))\n",
    "print(\"length of test offset = \" +str(len(df_test_offset)))\n",
    "print(\"length of val offset = \" +str(len(df_val_offset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10076959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957efd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca88769e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "842bacee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_temp.reset_index(inplace = True)\n",
    "df_train_offset.reset_index(inplace = True)\n",
    "df_test_offset.reset_index(inplace = True)\n",
    "df_val_offset.reset_index(inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d37167",
   "metadata": {},
   "source": [
    "### Let's check for data leakage in offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2bd7e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>offset_x</th>\n",
       "      <th>length_x</th>\n",
       "      <th>specie_ind_x</th>\n",
       "      <th>start_x</th>\n",
       "      <th>end_x</th>\n",
       "      <th>index_y</th>\n",
       "      <th>offset_y</th>\n",
       "      <th>length_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, offset_x, length_x, specie_ind_x, start_x, end_x, index_y, offset_y, length_y, specie_ind_y, start_y, end_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_train_offset , df_test_offset , on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bedf9605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>offset_x</th>\n",
       "      <th>length_x</th>\n",
       "      <th>specie_ind_x</th>\n",
       "      <th>start_x</th>\n",
       "      <th>end_x</th>\n",
       "      <th>index_y</th>\n",
       "      <th>offset_y</th>\n",
       "      <th>length_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, offset_x, length_x, specie_ind_x, start_x, end_x, index_y, offset_y, length_y, specie_ind_y, start_y, end_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_train_offset , df_val_offset , on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb8a8faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>offset_x</th>\n",
       "      <th>length_x</th>\n",
       "      <th>specie_ind_x</th>\n",
       "      <th>start_x</th>\n",
       "      <th>end_x</th>\n",
       "      <th>index_y</th>\n",
       "      <th>offset_y</th>\n",
       "      <th>length_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, offset_x, length_x, specie_ind_x, start_x, end_x, index_y, offset_y, length_y, specie_ind_y, start_y, end_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_test_offset , df_val_offset , on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d6cc5",
   "metadata": {},
   "source": [
    "### At this stage we've a dataframe of recordin ids and each row corresponds to a 1.92 secs recording or shorter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13b2ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specie_distri(df , classes , type_df = None):\n",
    "    \"\"\"This function takes a dataframe and provides a count of each specie class\"\"\"\n",
    "    for i in range(len(classes)):\n",
    "        print(\"DF type = \" + str(type_df))\n",
    "        df_temp = df[df['specie_ind'] == i]\n",
    "        print(\"i = \" +str(i))\n",
    "        print(len(df_temp))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15dd3eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32524317 0.56223527 3.61119126 0.62576786 1.97670352 4.1207667\n",
      " 3.00231323 5.25855342]\n"
     ]
    }
   ],
   "source": [
    "#Class imbalance \n",
    "np.array(df_train_offset.specie_ind)\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',classes=np.unique(np.array(df_train_offset.specie_ind)),y=np.array(np.array(df_train_offset.specie_ind)))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b44b26d",
   "metadata": {},
   "source": [
    "Let us now get the class distribution for each of the dataframes- train,test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2195b1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "879b8034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF type = train\n",
      "i = 0\n",
      "13468\n",
      "DF type = train\n",
      "i = 1\n",
      "7791\n",
      "DF type = train\n",
      "i = 2\n",
      "1213\n",
      "DF type = train\n",
      "i = 3\n",
      "7000\n",
      "DF type = train\n",
      "i = 4\n",
      "2216\n",
      "DF type = train\n",
      "i = 5\n",
      "1063\n",
      "DF type = train\n",
      "i = 6\n",
      "1459\n",
      "DF type = train\n",
      "i = 7\n",
      "833\n"
     ]
    }
   ],
   "source": [
    "get_specie_distri(df_train_offset , classes , type_df = \"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e8bab9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF type = Val\n",
      "i = 0\n",
      "3908\n",
      "DF type = Val\n",
      "i = 1\n",
      "2175\n",
      "DF type = Val\n",
      "i = 2\n",
      "264\n",
      "DF type = Val\n",
      "i = 3\n",
      "1981\n",
      "DF type = Val\n",
      "i = 4\n",
      "318\n",
      "DF type = Val\n",
      "i = 5\n",
      "260\n",
      "DF type = Val\n",
      "i = 6\n",
      "478\n",
      "DF type = Val\n",
      "i = 7\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "get_specie_distri(df_val_offset , classes , type_df = \"Val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8b0ec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF type = test\n",
      "i = 0\n",
      "4717\n",
      "DF type = test\n",
      "i = 1\n",
      "2105\n",
      "DF type = test\n",
      "i = 2\n",
      "484\n",
      "DF type = test\n",
      "i = 3\n",
      "2114\n",
      "DF type = test\n",
      "i = 4\n",
      "559\n",
      "DF type = test\n",
      "i = 5\n",
      "350\n",
      "DF type = test\n",
      "i = 6\n",
      "491\n",
      "DF type = test\n",
      "i = 7\n",
      "223\n"
     ]
    }
   ],
   "source": [
    "get_specie_distri(df_test_offset , classes , type_df = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb61438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77342f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function pads a short-audio tensor with its mean to ensure that it becomes a 1.92 sec long audio equivalent\n",
    "def pad_mean(x_temp,rate = config.rate, min_length = config.min_duration ):\n",
    "    if DEBUG:\n",
    "        print(\"inside padding mean...\")\n",
    "    x_mean = torch.mean(x_temp)\n",
    "    #x_mean.cuda()\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"X_mean = \" + str(x_mean))\n",
    "    left_pad_amt = int((rate*min_length-x_temp.shape[1])//2)\n",
    "    if DEBUG:\n",
    "        print(\"left_pad_amt = \" + str(left_pad_amt))\n",
    "    left_pad = torch.zeros(1,left_pad_amt) #+ (0.1**0.5)*torch.randn(1, left_pad_amt)\n",
    "    if DEBUG:\n",
    "        print(\"left_pad shape = \" + str(left_pad.shape))\n",
    "    left_pad_mean_add = left_pad + x_mean\n",
    "    if DEBUG:\n",
    "        print(\"left_pad_mean shape = \" + str(left_pad_mean_add))\n",
    "        print(\"sum of left pad mean add = \" + str(torch.sum(left_pad_mean_add)))\n",
    "    \n",
    "    right_pad_amt = int(rate*min_length-x_temp.shape[1]-left_pad_amt)\n",
    "    right_pad = torch.zeros(1,right_pad_amt)# + (0.1**0.5)*torch.randn(1, right_pad_amt)\n",
    "    if DEBUG:\n",
    "        print(\"right_pad shape = \" + str(right_pad.shape))\n",
    "    right_pad_mean_add = right_pad + x_mean\n",
    "    if DEBUG:\n",
    "        print(\"right_pad_mean shape = \" + str(right_pad_mean_add))\n",
    "        print(\"sum of right pad mean add = \"  + str(torch.sum(right_pad_mean_add)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    f = torch.cat([left_pad,x_temp,right_pad],dim=1)[0]\n",
    "    f = f.unsqueeze(dim = 0)\n",
    "    #print(\"returning a tensor of shape = \" + str(f.shape))\n",
    "    return(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57465ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "089d70a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_hat,y_true,classes):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_hat, y_true ,labels= range(len(classes)))\n",
    "    import seaborn as sns\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, fmt = 'g'); #annot=True to annotate cellsplt.xticks(rotation=90)\n",
    "    ax.xaxis.set_ticklabels(classes, fontsize = 10)\n",
    "    ax.xaxis.tick_bottom()\n",
    "    plt.xticks(rotation=90)\n",
    "    ax.set_ylabel('True', fontsize=20)\n",
    "    ax.yaxis.set_ticklabels(classes, fontsize = 10)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e1a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8a94bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.92"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the min length based on config params\n",
    "min_length = (config.win_size * config.n_hop) / config.rate\n",
    "min_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bd9feb",
   "metadata": {},
   "source": [
    "### Class Defintions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "881315ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_aug(spec_gram , aug_flag = \"Y\", newsize = (1025, 31)):\n",
    "        \n",
    "        from torchvision.transforms.autoaugment import AutoAugmentPolicy\n",
    "        import torchvision.transforms as transforms\n",
    "        \n",
    "        aug_flag_y = transforms.Compose([\n",
    "            transforms.GaussianBlur(3),#image conversion\n",
    "            transforms.RandomErasing(),\n",
    "            transforms.Normalize(mean = 2.7360104e-05 , std = .0061507192)\n",
    "            ])\n",
    "        \n",
    "        \n",
    "        aug_flag_n = transforms.Compose([\n",
    "            transforms.Normalize(mean = 2.7360104e-05 , std = .0061507192)\n",
    "            ])\n",
    "        \n",
    "            \n",
    "        \n",
    "        if (aug_flag == \"Y\"):\n",
    "            rgb_img_auto_aug = aug_flag_y(spec_gram)\n",
    "            #print(\"type(rgb_img_auto_aug) = \" +str(type(rgb_img_auto_aug)))\n",
    "            \n",
    "            return rgb_img_auto_aug\n",
    "        else:\n",
    "            \n",
    "            img_tensor = aug_flag_n(spec_gram)\n",
    "            #print(\"type(img_tensor) = \" +str(type(img_tensor)))\n",
    "            return img_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06c7742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalization():\n",
    "    \"\"\"This class is for normalizing the spectrograms batch by batch. The normalization used is min-max, two modes 'framewise' and 'imagewise' can be selected. In this paper, we found that 'imagewise' normalization works better than 'framewise'\"\"\"\n",
    "    def __init__(self, mode='framewise'):\n",
    "        if mode == 'framewise':\n",
    "            def normalize(x):\n",
    "                size = x.shape\n",
    "                x_max = x.max(1, keepdim=True)[0] # Finding max values for each frame\n",
    "                x_min = x.min(1, keepdim=True)[0]  \n",
    "                output = (x-x_min)/(x_max-x_min) # If there is a column with all zero, nan will occur\n",
    "                output[torch.isnan(output)]=0 # Making nan to 0\n",
    "                return output\n",
    "        elif mode == 'imagewise':\n",
    "            def normalize(x):\n",
    "                size = x.shape\n",
    "                x_max = x.reshape(size[0], size[1]*size[2]).max(1, keepdim=True)[0]\n",
    "                x_min = x.reshape(size[0], size[1]*size[2]).min(1, keepdim=True)[0]\n",
    "                x_max = x_max.unsqueeze(1) # Make it broadcastable\n",
    "                x_min = x_min.unsqueeze(1) # Make it broadcastable \n",
    "                return (x-x_min)/(x_max-x_min)\n",
    "        else:\n",
    "            print(f'please choose the correct mode')\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "462a054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcen(x, eps=1e-6, s=0.025, alpha=0.98, delta=2, r=0.5, training=False):\n",
    "    frames = x.split(1, -2)\n",
    "    m_frames = []\n",
    "    last_state = None\n",
    "    for frame in frames:\n",
    "        if last_state is None:\n",
    "            last_state = s * frame\n",
    "            m_frames.append(last_state)\n",
    "            continue\n",
    "        if training:\n",
    "            m_frame = ((1 - s) * last_state).add_(s * frame)\n",
    "        else:\n",
    "            m_frame = (1 - s) * last_state + s * frame\n",
    "        last_state = m_frame\n",
    "        m_frames.append(m_frame)\n",
    "    M = torch.cat(m_frames, 1)\n",
    "    if training:\n",
    "        pcen_ = (x / (M + eps).pow(alpha) + delta).pow(r) - delta ** r\n",
    "    else:\n",
    "        pcen_ = x.div_(M.add_(eps).pow_(alpha)).add_(delta).pow_(r).sub_(delta ** r)\n",
    "    return pcen_\n",
    "\n",
    "\n",
    "class PCENTransform(nn.Module):\n",
    "\n",
    "    def __init__(self, eps=1e-6, s=0.025, alpha=0.98, delta=2, r=0.5, trainable=True):\n",
    "        super().__init__()\n",
    "        if trainable:\n",
    "            self.log_s = nn.Parameter(torch.log(torch.Tensor([s])))\n",
    "            self.log_alpha = nn.Parameter(torch.log(torch.Tensor([alpha])))\n",
    "            self.log_delta = nn.Parameter(torch.log(torch.Tensor([delta])))\n",
    "            self.log_r = nn.Parameter(torch.log(torch.Tensor([r])))\n",
    "        else:\n",
    "            self.s = s\n",
    "            self.alpha = alpha\n",
    "            self.delta = delta\n",
    "            self.r = r\n",
    "        self.eps = eps\n",
    "        self.trainable = trainable\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = x.permute((0,2,1)).squeeze(dim=1)\n",
    "        if self.trainable:\n",
    "            x = pcen(x, self.eps, torch.exp(self.log_s), torch.exp(self.log_alpha), torch.exp(self.log_delta), torch.exp(self.log_r), self.training and self.trainable)\n",
    "        else:\n",
    "            x = pcen(x, self.eps, self.s, self.alpha, self.delta, self.r, self.training and self.trainable)\n",
    "#         x = x.unsqueeze(dim=1).permute((0,1,3,2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cac165b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>specie_ind</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>221103</td>\n",
       "      <td>0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>221103</td>\n",
       "      <td>1</td>\n",
       "      <td>1.92</td>\n",
       "      <td>7</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>221103</td>\n",
       "      <td>2</td>\n",
       "      <td>1.28</td>\n",
       "      <td>7</td>\n",
       "      <td>10240.0</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>221111</td>\n",
       "      <td>0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>221111</td>\n",
       "      <td>1</td>\n",
       "      <td>1.92</td>\n",
       "      <td>7</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      id  offset  length  specie_ind    start      end\n",
       "0      0  221103       0    1.92           7      0.0  15360.0\n",
       "1      1  221103       1    1.92           7   5120.0  20480.0\n",
       "2      2  221103       2    1.28           7  10240.0  20480.0\n",
       "3      3  221111       0    1.92           7      0.0  15360.0\n",
       "4      4  221111       1    1.92           7   5120.0  20480.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_offset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cdace53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_df(loader , trained_model, DEBUG = False):\n",
    "    err_dict = {'id': None,\n",
    "               'label': None,\n",
    "               'offset':None,\n",
    "               'y_hat':None}\n",
    "    model = trained_model\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        model.eval()\n",
    "        if DEBUG:\n",
    "            print(\"inside test....\")\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        all_wav_id = []\n",
    "        all_offset = []\n",
    "        if DEBUG:\n",
    "            print(\"length of loader = \" + str(len(loader)))\n",
    "        for idx,(x,y,offset,wav_id) in enumerate(loader):\n",
    "            if DEBUG:\n",
    "                print(\"loader index = \" + str(idx))\n",
    "                print(\"y = \" + str(y))\n",
    "                print(\"offset = \" + str(offset))\n",
    "                print(\"wav_id = \" + str(wav_id))\n",
    "                \n",
    "            x = x.to(device).float() \n",
    "            y = y.type(torch.LongTensor).to(device)\n",
    "            y_pred = model(x)['prediction']\n",
    "            preds = torch.argmax(y_pred, axis = 1)\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            if DEBUG:\n",
    "                print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "            preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "            if DEBUG:\n",
    "                print(\"preds = \" +str(preds))\n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "            all_y.append(y.cpu().detach())\n",
    "            all_wav_id.append(wav_id.cpu().detach())\n",
    "            all_offset.append(offset.cpu().detach())\n",
    "            #all_y_pred.append(np.argmax(y_pred.cpu().detach().numpy()))\n",
    "            \n",
    "            del x\n",
    "            del y\n",
    "            del y_pred\n",
    "        all_y = torch.cat(all_y).numpy()\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        all_wav_id = torch.cat(all_wav_id)\n",
    "        all_offset = torch.cat(all_offset)\n",
    "        \n",
    "        err_dict['id'] = all_wav_id\n",
    "        err_dict['label'] = all_y\n",
    "        err_dict['offset'] = all_offset\n",
    "        err_dict['y_hat'] = all_y_pred\n",
    "        df_err = pd.DataFrame.from_dict(err_dict)\n",
    "        df_err_uniq = df_err[df_err['label']!= df_err['y_hat']]\n",
    "        df_err_uniq.sort_values(by=['id','offset'])\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"inside error ....\")\n",
    "            print(\"y = \" + str(all_y))\n",
    "            print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "        #test_loss = test_loss/len(test_loader)\n",
    "        #test_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "    \n",
    "    \n",
    "    return df_err_uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca198527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loader, criterion,  classes = classes,device=None , call = \"val\"):\n",
    "    softmax = nn.Softmax()\n",
    "    if DEBUG:\n",
    "        print(\"calling for ...\" +str(call))\n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        sigmoid = nn.Sigmoid()\n",
    "        test_loss = 0.0\n",
    "        model.eval()\n",
    "        if DEBUG:\n",
    "            print(\"inside test....\")\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        counter = 1\n",
    "        if DEBUG:\n",
    "            print(\"length of loader = \" + str(len(loader)))\n",
    "        for idx,(x,y) in enumerate(loader):\n",
    "            if DEBUG:\n",
    "                print(\"loader index = \" + str(idx))\n",
    "                            \n",
    "            x = x.to(device).float() \n",
    "            y = y.type(torch.LongTensor).to(device)\n",
    "            if DEBUG:\n",
    "                print(\"y = \" + str(y))\n",
    "            y_pred = model(x)['prediction']\n",
    "            y_pred_smax = softmax(y_pred)\n",
    "            preds = torch.argmax(y_pred_smax, axis = 1)\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            if DEBUG:\n",
    "                print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "            #preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "            if DEBUG:\n",
    "                print(\"preds = \" +str(preds))\n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "                                   \n",
    "            loss = criterion(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            all_y.append(y.cpu().detach())\n",
    "            #all_y_pred.append(np.argmax(y_pred.cpu().detach().numpy()))\n",
    "            \n",
    "            del x\n",
    "            del y\n",
    "            del y_pred\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        if DEBUG:\n",
    "            print(\"inside test....\")\n",
    "            print(\"y = \" + str(all_y))\n",
    "            print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "        test_loss = test_loss/len(test_loader)\n",
    "        test_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "    \n",
    "    \n",
    "    return test_loss, test_f1 , all_y,all_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8ba0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(train_loader, val_loader, test_loader,model, classes ,class_weights ,num_epochs = num_epochs )\n",
    "def train_model(train_loader, val_loader,test_loader, model = None,  classes = classes,class_weights = class_weights,num_epochs = num_epochs ,n_channels = 1):\n",
    "    # Creates a GradScaler once at the beginning of training.\n",
    "    loss_scaler = NativeScaler()\n",
    "    global_step = 0\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Training on {device}')    \n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using data parallel\")\n",
    "        model = nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "\n",
    "    model = model.to(device)\n",
    "    weights_adj = torch.tensor(class_weights).type(torch.float).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights_adj)\n",
    "    optimiser = timm.optim.create_optimizer_v2(model.parameters(), lr=config_pytorch.lr/10,opt = 'lookahead_adam')\n",
    "    #optimiser = timm.optim.AdamW(model.parameters(), lr=config_pytorch.lr)\n",
    "    timm.optim.Lookahead(optimiser, alpha=0.5, k=6)\n",
    "    scheduler = timm.scheduler.CosineLRScheduler(optimiser, t_initial=num_epochs/2,lr_min= 1e-6)\n",
    "    \n",
    "    \n",
    "    #optimiser = timm.optim.RAdam(model.parameters(), lr=config_pytorch.lr/10)\n",
    "    num_epochs = num_epochs\n",
    "    all_train_loss = []\n",
    "    all_train_f1 = []\n",
    "    all_val_loss = []\n",
    "    all_val_f1 = []\n",
    "    best_val_loss = np.inf\n",
    "    best_val_f1 = -np.inf\n",
    "    best_train_f1 = -np.inf\n",
    "    best_epoch = -1\n",
    "    checkpoint_name = None\n",
    "    overrun_counter = 0\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    softmax = nn.Softmax()\n",
    "    all_train_f1 = []\n",
    "    all_val_f1 = []\n",
    "    \n",
    "    lr_log = []\n",
    "    for e in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        #tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "        for batch_i, inputs in enumerate(train_loader):\n",
    "            if DEBUG:\n",
    "                print(\"inside train loop.. batch_ind = \" +str(batch_i))\n",
    "            if batch_i % 200 == 0:\n",
    "                bat_time = time.time()\n",
    "                durn = (bat_time - start_time)/60\n",
    "                print(\"epoch = \" +str(e) + \"batch = \" +str(batch_i) + \" of \" + str(len(train_loader)) + \"duraation = \" + str(durn))\n",
    "            x = inputs[0].to(device).float()\n",
    "            if DEBUG:\n",
    "                print(\"inside train loop.. x device = \" +str(x.device))\n",
    "                \n",
    "            y = inputs[1].type(torch.LongTensor).to(device)\n",
    "            #global_step += 1\n",
    "            # AMP\n",
    "            x_sum = torch.sum(x,axis = 1)\n",
    "            x_sum.unsqueeze(dim = 1)\n",
    "            zero_chk = torch.where((x_sum == 0))[0]\n",
    "            if len(zero_chk) > 0:\n",
    "                print(\"ZERO ENCOUNTER\")\n",
    "                print(\"x = \" +str(x))\n",
    "                break\n",
    "                       \n",
    "            with autocast():\n",
    "                y_pred = model(x)['prediction']\n",
    "                y_pred_smax = softmax(y_pred)\n",
    "                preds = torch.argmax(y_pred_smax, axis = 1)\n",
    "                loss = criterion(y_pred, y)\n",
    "            \n",
    "            if DEBUG:\n",
    "                    print(\"y_pred  = \" +str(y_pred))\n",
    "                    print(\"preds = \" +str(preds))\n",
    "                \n",
    "                \n",
    "            #loss_scaler(loss, optimiser,parameters=model_parameters(model))\n",
    "            if loss.item() > 10000:\n",
    "                print(\"^^^^^^^^^^^^^^^^^ EXPLOSION^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "                print(\"x sum = \" + str(torch.sum(x)))\n",
    "                print(\"current loss = \" + str(loss.item()))\n",
    "            train_loss += loss.item()\n",
    "            all_y.append(y.cpu().detach())\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            #preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "            if DEBUG:\n",
    "                print(\"batch_ind = \" +str(batch_i))\n",
    "                print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "                \n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),error_if_nonfinite=False ,max_norm = 5.0 )\n",
    "            optimiser.step()\n",
    "            del x\n",
    "            del y\n",
    "            del y_pred,preds\n",
    "        \n",
    "        #lr_log.append(lr)\n",
    "        optimiser.sync_lookahead()\n",
    "        all_train_loss.append(train_loss/len(train_loader))\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        if DEBUG:\n",
    "            print(\"y = \" + str(all_y))\n",
    "            print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "        train_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "        all_train_f1.append(train_f1)\n",
    "        if DEBUG:\n",
    "            print(\"train acc = \" +str(train_acc))\n",
    "        all_train_f1.append(train_f1)\n",
    "        val_loss, val_f1 , _,_ = test_model(model, val_loader, criterion = nn.CrossEntropyLoss(), classes = classes ,device=device, call = \"val\")\n",
    "        all_val_f1.append(val_f1)\n",
    "        all_val_loss.append(val_loss)\n",
    "        if DEBUG:\n",
    "            print(\"val F1 = \" + str(val_f1))\n",
    "        all_val_loss.append(val_loss)\n",
    "        all_val_f1.append(val_f1)\n",
    "        \n",
    "        acc_metric = val_f1\n",
    "        best_acc_metric = best_val_f1\n",
    "        if acc_metric > best_acc_metric:  \n",
    "            overrun_counter = -1\n",
    "            checkpoint_name = f'model_e{e}_{datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")}.pth'\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_dir,  checkpoint_name))\n",
    "            sys.stdout.flush()\n",
    "            print('Epoch: %d, Train Loss: %.8f, Train f1: %.8f, Val Loss: %.8f, Val f1: %.8f, overrun_counter %i' % (e, train_loss/len(train_loader), train_f1, val_loss/len(val_loader), val_f1,  overrun_counter))\n",
    "            print('Saving model to:', os.path.join(config.model_dir,  checkpoint_name)) \n",
    "            print(\"Now printing classification rport... \")\n",
    "            print(\"********************************\")\n",
    "            from sklearn.metrics import classification_report\n",
    "            _, _ , all_y_test,all_y_pred_test = test_model(model, test_loader, criterion = nn.CrossEntropyLoss(), classes = classes ,device=device, call = \"test\")\n",
    "            # at times output is not getting printed. Could be due to multi threading and hence adding sleep\n",
    "            time.sleep(2)\n",
    "            sys.stdout.flush()\n",
    "            print(classification_report(all_y_test.numpy(), all_y_pred_test.numpy(), target_names= classes))\n",
    "            print(\"********************************\")\n",
    "            time.sleep(2)\n",
    "            plot_confusion_matrix(all_y_pred_test.numpy(), all_y_test.numpy() , classes)\n",
    "            best_epoch = e\n",
    "            best_val_f1 = val_f1\n",
    "            best_val_loss = val_loss\n",
    "            \n",
    "        else:\n",
    "            print(\"..Overrun....no improvement\")\n",
    "            overrun_counter += 1\n",
    "            sys.stdout.flush()\n",
    "            print('Epoch: %d, Train Loss: %.8f, Train f1: %.8f, Val Loss: %.8f, Val f1: %.8f, overrun_counter %i' % (e, train_loss/len(train_loader), train_f1, val_loss/len(val_loader), val_f1,  overrun_counter))\n",
    "        scheduler.step(e+1)\n",
    "        if overrun_counter > config_pytorch.max_overrun:\n",
    "            break\n",
    "            \n",
    "    \n",
    "    return model, lr_log,all_train_f1,all_train_loss,all_val_loss,all_val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fcfa992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_audiomentations import Compose, Gain, PolarityInversion,AddColoredNoise,ApplyImpulseResponse,PeakNormalization\n",
    "# #apply_augmentation = Compose(transforms=[PolarityInversion(p=0.5 ,output_type = 'tensor'),AddColoredNoise(), PeakNormalization(apply_to=\"only_too_loud_sounds\"),TimeInversion(output_type = 'tensor')  ])\n",
    "\n",
    "\n",
    "# apply_augmentation = Compose(transforms=[AddColoredNoise(p = 1) ,TimeInversion( p = 1) ,PolarityInversion(p = 1)])\n",
    "\n",
    "# #apply_augmentation = Compose(transforms=[PolarityInversion(p=0.5 ,output_type = 'tensor'),AddColoredNoise(), PeakNormalization(apply_to=\"only_too_loud_sounds\"),TimeInversion(output_type = 'tensor')  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26973e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MozTrainDataset(Dataset):\n",
    "\n",
    "    def __init__(self, audio_df, data_dir, min_length, cache=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            audio_df (DataFrame): from get_offsets_df function \n",
    "            noise_df (DataFrame): the df of noise files and lengths\n",
    "            data_dir (string): Directory with all the wavs.\n",
    "            cache (dict): Empty dictionary used as cache\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.audio_df = audio_df\n",
    "        #self.noise_df = noise_df\n",
    "        self.data_dir = data_dir\n",
    "        self.min_length = min_length\n",
    "        self.transform = transform\n",
    "        self.cache = cache\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_df)\n",
    "    \n",
    "    def _get_sample_(self, path, resample=None):\n",
    "        \n",
    "        waveform, inp_rate = torchaudio.load(path)\n",
    "        \n",
    "        if inp_rate != config.rate:\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "            waveform = resampler(waveform)\n",
    "    \n",
    "        \n",
    "        #waveform, rate = torchaudio.load(path)\n",
    "                \n",
    "        if waveform.shape[1] < config.rate*self.min_length:\n",
    "            #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "            f_out = pad_mean(waveform)\n",
    "        else:\n",
    "            f = waveform[0]\n",
    "            f_out = f.unsqueeze(0)\n",
    "            \n",
    "        return f_out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #real_idx = idx % len(self.audio_df)\n",
    "                   \n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        x = self._get_sample_(os.path.join(self.data_dir,f\"{int(self.audio_df.loc[idx]['id'])}.wav\"), resample=config.rate)\n",
    "       # random noise on even number indexes\n",
    "        offset = int(self.audio_df.loc[idx]['offset'])\n",
    "        if DEBUG:\n",
    "            print(\"idx = \" + str(idx))\n",
    "            print(\"offset = \" + str(offset))\n",
    "            print(\"shape of x post augmentation = \" + str(x.shape))\n",
    "            print(\"from get_item of train, returning  x of shape = \" +str(x[:,offset:int(offset+config.rate*self.min_length)].shape))\n",
    "        \n",
    "        x_val = x[:,offset:int(offset+config.rate*self.min_length)]\n",
    "        #now that we have final x- let's create specgram and add augmentations.\n",
    "        spec_generator = features.STFT(n_fft=int(config.NFFT), freq_bins=None, hop_length=int(config.n_hop),\n",
    "                              window='hann', freq_scale='linear', center=True, pad_mode='reflect',\n",
    "                           sr=config.rate, output_format=\"Magnitude\", trainable=False,verbose = False)\n",
    "        spec_gram = spec_generator(x_val)\n",
    "        #generate a random number and if condition is met apply aug\n",
    "        \n",
    "        \n",
    "        rand_aug_choice = np.random.randint(0,9)\n",
    "        \n",
    "        if rand_aug_choice %2 == 0 :\n",
    "            spec_gram = apply_aug(spec_gram , aug_flag = \"Y\")\n",
    "        else:\n",
    "            spec_gram = apply_aug(spec_gram , aug_flag = \"N\")\n",
    "             \n",
    "            \n",
    "        return (spec_gram,self.audio_df.loc[idx]['specie_ind'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "704c4567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MozTestDataset(Dataset):\n",
    "\n",
    "    def __init__(self, audio_df, data_dir, min_length, cache=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            audio_df (DataFrame): from get_offsets_df function \n",
    "            noise_df (DataFrame): the df of noise files and lengths\n",
    "            data_dir (string): Directory with all the wavs.\n",
    "            cache (dict): Empty dictionary used as cache\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.audio_df = audio_df\n",
    "        #self.noise_df = noise_df\n",
    "        self.data_dir = data_dir\n",
    "        self.min_length = min_length\n",
    "        self.transform = transform\n",
    "        self.cache = cache\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_df)\n",
    "    \n",
    "    def _get_sample_(self, path, resample=None):\n",
    "        \n",
    "        waveform, inp_rate = torchaudio.load(path)\n",
    "        \n",
    "        if inp_rate != config.rate:\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "            waveform = resampler(waveform)\n",
    "    \n",
    "        \n",
    "        #waveform, rate = torchaudio.load(path)\n",
    "                \n",
    "        if waveform.shape[1] < config.rate*self.min_length:\n",
    "            #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "            f_out = pad_mean(waveform)\n",
    "        else:\n",
    "            f = waveform[0]\n",
    "            #mu = torch.std_mean(f)[1]\n",
    "            #st = torch.std_mean(f)[0]\n",
    "            # clip amplitudes\n",
    "            f_out = f.unsqueeze(0)\n",
    "            if self.cache is not None:\n",
    "                self.cache[path] = f_out\n",
    "        return f_out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #real_idx = idx % len(self.audio_df)\n",
    "        x = self._get_sample_(os.path.join(self.data_dir,f\"{int(self.audio_df.loc[idx]['id'])}.wav\"), resample=config.rate)\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "        # random noise on even number indexes\n",
    "        offset = int(self.audio_df.loc[idx]['offset'])\n",
    "        if DEBUG:\n",
    "            print(\"idx = \" + str(idx))\n",
    "            print(\"shape of x post augmentation = \" + str(x.shape))\n",
    "            print(\"offset = \" + str(offset))\n",
    "            print(\"from get_item of train, returning  x of shape = \" +str(x[:,offset:int(offset+config.rate*self.min_length)].shape))\n",
    "            \n",
    "        x_val = x[:,offset:int(offset+config.rate*self.min_length)]\n",
    "        \n",
    "        spec_generator = features.STFT(n_fft=int(config.NFFT), freq_bins=None, hop_length=int(config.n_hop),\n",
    "                              window='hann', freq_scale='linear', center=True, pad_mode='reflect',\n",
    "                           sr=config.rate, output_format=\"Magnitude\", trainable=False,verbose = False)\n",
    "        spec_gram = spec_generator(x_val)\n",
    "        #generate a random number and if condition is met apply aug\n",
    "        spec_gram\n",
    "        spec_gram = apply_aug(spec_gram , aug_flag = \"N\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        return (spec_gram,self.audio_df.loc[idx]['specie_ind'])\n",
    "        \n",
    "        \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043a220a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bb2944e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass the pretrained model and make it a binary classification\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name, image_size):\n",
    "        super().__init__()\n",
    "        # num_classes=0 removes the pretrained head\n",
    "        self.backbone = timm.create_model(model_name,\n",
    "                        pretrained=True, num_classes=8, in_chans=1, \n",
    "                        drop_path_rate=0.2, global_pool='max',\n",
    "                        drop_rate=0.25)\n",
    "        #####  This section is model specific\n",
    "        #### It freezes some fo the layers by name\n",
    "        #### you'll have to inspect the model to see the names\n",
    "                #### end layer freezing\n",
    "        self.out = nn.Linear(self.backbone.num_features, 1)\n",
    "        self.sizer = VT.Resize((image_size,image_size))\n",
    "        #self.augment_layer = augment_audio(trainable = True, sample_rate = config.rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # first compute spectrogram\n",
    "        \n",
    "        x = self.sizer(x)\n",
    "        #x = spec.unsqueeze(1)\n",
    "        # then repeat channels\n",
    "        if DEBUG:\n",
    "            print(\"Final shape that goes to backbone = \" + str(x.shape))\n",
    "        if torch.sum(x) == 0:\n",
    "            print(\"ZERO INPUT in forward\")\n",
    "            x  = x+torch.tensor(1e-6)\n",
    "            \n",
    "            \n",
    "        x = self.backbone(x)\n",
    "        #print(\"x shape = \" + str(x.shape))\n",
    "        #print(\"x = \" +str(x))\n",
    "        #pred = nn.Softmax(x)\n",
    "        pred = x\n",
    "        #print(np.argmax(pred.detach().cpu().numpy()))\n",
    "        #print(pred)\n",
    "        output = {\"prediction\": pred }\n",
    "        #print(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09cc4ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/audio\n"
     ]
    }
   ],
   "source": [
    "print(config.data_dir)\n",
    "train_dataset = MozTrainDataset(df_train_offset,  config.data_dir, min_length , transform = None)\n",
    "val_dataset = MozTestDataset(df_val_offset,  config.data_dir, min_length)\n",
    "test_dataset = MozTestDataset(df_test_offset,  config.data_dir, min_length)\n",
    "#error_dataset = MozErrAnalysisDataset(df_val_offset,  config.data_dir, min_length = config.min_duration)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, num_workers=num_workers,batch_size = batch_size,shuffle = True\n",
    "    , pin_memory=True )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=batch_size,\n",
    "        num_workers= num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf0d224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a45fbe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset = 35043\n",
      "Length of train loader = 1096\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train dataset = \" +str(len(train_dataset)))\n",
    "print(\"Length of train loader = \" +str(len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1590bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_itr = iter(train_loader)\n",
    "# a,b = train_itr.next()\n",
    "# print(a.shape)\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "368642d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec_layer = features.STFT(n_fft=int(config.NFFT), freq_bins=None, hop_length=int(config.n_hop),\n",
    "#                               window='hann', freq_scale='linear', center=True, pad_mode='reflect',\n",
    "#                            sr=config.rate, output_format=\"Magnitude\", trainable=True,)\n",
    "# x = spec_layer(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba384ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_mod = Model('convnext_small',224)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e34d2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mod(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a829ec",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ff0d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath, model=Model('convnext_small',224)):\n",
    "    # Instantiate model to inspect\n",
    "    print(\"Filepath = \" + str(filepath))\n",
    "    print(\"model = \" +str(model))\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    print(f'Training on {device}')\n",
    "        \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using data parallel\")\n",
    "        model = nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "    model = model.to(device)\n",
    "    # Load trained parameters from checkpoint (may need to download from S3 first)\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        map_location=lambda storage, loc: storage.cuda()\n",
    "    else:\n",
    "        map_location='cpu'\n",
    "        \n",
    "    checkpoint = model.load_state_dict(torch.load(filepath))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfbbe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n",
      "epoch = 0batch = 0 of 1096duraation = 0.23370211919148762\n",
      "epoch = 0batch = 200 of 1096duraation = 5.659919389088949\n",
      "epoch = 0batch = 400 of 1096duraation = 11.043041388193766\n",
      "epoch = 0batch = 600 of 1096duraation = 16.457376209894814\n",
      "epoch = 0batch = 800 of 1096duraation = 21.866720561186472\n",
      "epoch = 0batch = 1000 of 1096duraation = 27.240448113282522\n",
      "Epoch: 0, Train Loss: 0.56268963, Train f1: 0.78098335, Val Loss: 0.00416929, Val f1: 0.59422999, overrun_counter -1\n",
      "Saving model to: ../../models/model_e0_2023_04_17_00_09_03.pth\n",
      "Now printing classification rport... \n",
      "********************************\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.69      0.71      0.70      4717\n",
      "culex pipiens complex       0.50      0.59      0.54      2105\n",
      "           ae aegypti       0.55      0.05      0.09       484\n",
      "       an funestus ss       0.55      0.57      0.56      2114\n",
      "         an squamosus       0.09      0.09      0.09       559\n",
      "          an coustani       0.18      0.02      0.04       350\n",
      "         ma uniformis       0.31      0.31      0.31       491\n",
      "         ma africanus       0.17      0.37      0.24       223\n",
      "\n",
      "             accuracy                           0.55     11043\n",
      "            macro avg       0.38      0.34      0.32     11043\n",
      "         weighted avg       0.55      0.55      0.54     11043\n",
      "\n",
      "********************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1batch = 0 of 1096duraation = 0.21714764436086018\n",
      "epoch = 1batch = 200 of 1096duraation = 5.904819488525391\n",
      "epoch = 1batch = 400 of 1096duraation = 11.238421301047007\n",
      "epoch = 1batch = 600 of 1096duraation = 16.720000894864402\n",
      "epoch = 1batch = 800 of 1096duraation = 22.25006667772929\n",
      "epoch = 1batch = 1000 of 1096duraation = 27.698454729715984\n",
      "..Overrun....no improvement\n",
      "Epoch: 1, Train Loss: 0.02836140, Train f1: 0.99126879, Val Loss: 0.00458676, Val f1: 0.58115348, overrun_counter 0\n",
      "epoch = 2batch = 0 of 1096duraation = 0.20086148579915364\n",
      "epoch = 2batch = 200 of 1096duraation = 5.607207810878753\n",
      "epoch = 2batch = 400 of 1096duraation = 11.044347238540649\n",
      "epoch = 2batch = 600 of 1096duraation = 16.4766077876091\n",
      "epoch = 2batch = 800 of 1096duraation = 21.896196488539378\n",
      "epoch = 2batch = 1000 of 1096duraation = 27.31782517830531\n",
      "..Overrun....no improvement\n",
      "Epoch: 2, Train Loss: 0.01327531, Train f1: 0.99514975, Val Loss: 0.00557125, Val f1: 0.56127096, overrun_counter 1\n",
      "epoch = 3batch = 0 of 1096duraation = 0.2189866582552592\n",
      "epoch = 3batch = 200 of 1096duraation = 5.551449966430664\n",
      "epoch = 3batch = 400 of 1096duraation = 10.928490213553111\n",
      "epoch = 3batch = 600 of 1096duraation = 16.33420025507609\n",
      "epoch = 3batch = 800 of 1096duraation = 21.75453213453293\n",
      "epoch = 3batch = 1000 of 1096duraation = 27.160693192481993\n",
      "..Overrun....no improvement\n",
      "Epoch: 3, Train Loss: 0.01238207, Train f1: 0.99583488, Val Loss: 0.00534722, Val f1: 0.59002999, overrun_counter 2\n",
      "epoch = 4batch = 0 of 1096duraation = 0.23175295193990073\n",
      "epoch = 4batch = 200 of 1096duraation = 5.706595408916473\n",
      "epoch = 4batch = 400 of 1096duraation = 11.205113033453623\n"
     ]
    }
   ],
   "source": [
    "model =Model('convnext_xlarge_in22k',224)\n",
    "#model =Model('convnext_small',224)\n",
    "#filepath = \"../../models/model_e73_2022_10_08_07_44_27.pth\"\n",
    "#model_epcoh_99 = load_model(filepath,model)\n",
    "model, lr_log,all_train_f1,all_train_loss,all_val_loss,all_val_f1 = train_model(train_loader, val_loader, test_loader,model, classes ,class_weights ,num_epochs = num_epochs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1628ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len of all_train_f1 = \"+str(len(all_train_f1)))\n",
    "print(\"len of all_val_f1 = \"+str(len(all_val_f1)))\n",
    "print(\"len of all_val_loss = \"+str(len(all_val_loss)))\n",
    "print(\"len of all_train_loss = \"+str(len(all_train_loss)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0cdd95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437c6cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c396b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e45f100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a31718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_val_f1_final =  [v for i, v in enumerate(all_val_f1) if i % 2 == 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be9b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_val_loss_final =  [v for i, v in enumerate(all_val_loss) if i % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf9133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_f1_final =  [v for i, v in enumerate(all_train_f1) if i % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb34875",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_train_f1_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c203f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_train_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0064ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame({'train_loss':all_train_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e3e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df['val_f1'] = all_val_f1_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d495b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df['train_f1'] = all_train_f1_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b1e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df['val_loss'] = all_val_loss_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.fillna(0)\n",
    "plot_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b8f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.iloc[129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a90450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lineplot(plot_df['train_f1','val_f1']);\n",
    "plt.figure(figsize=(8,6)) \n",
    "sns.lineplot(plot_df[['train_f1','val_f1']])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"F1 Score - ConvNext Small\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5ffeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6)) \n",
    "sns.lineplot(plot_df[['train_loss','val_loss']])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss - ConvNext Small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4fc49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('file1.csv')\n",
    "plot_df.to_csv(\"plot_df_convNext_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68300691",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e75d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_train_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da109c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90fd7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_new = MozTestDataset(df_val_offset,  config.data_dir, min_length)\n",
    "val_loader_new = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=2,\n",
    "        num_workers=0, pin_memory=pin_memory  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd2fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error = df_val_offset\n",
    "model = model_epcoh_10\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "for idx,(x,y) in enumerate(val_dataset):\n",
    "    print(idx)\n",
    "    print(y)\n",
    "    x = x.to('cuda').float()\n",
    "    print(\"x shape = \" +str(x.shape))\n",
    "    #x_new = x.unsqueeze(dim = 1)\n",
    "    print(\"x_new shape = \" +str(x_new.shape))\n",
    "    x_new = x.to('cuda')\n",
    "    y_pred = model(x_new)['prediction']\n",
    "    y_pred_cpu = y_pred.cpu().detach()\n",
    "    preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "    df_erroriloc[idx]['y_hat'] = preds\n",
    "    del x_new\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc8094",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,15360)\n",
    "x = x.unsqueeze(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a786b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_offset.head()\n",
    "path_temp = \"../data/audio/\"\n",
    "for i,row in df_val_offset.iterrows():\n",
    "    print(\"i = \" +str(i))\n",
    "    print(\"id = \" + str(int(row['id'])))\n",
    "    file = str(int(row['id']))+\".wav\"\n",
    "    print(file)\n",
    "    path = path_temp + file\n",
    "    waveform, inp_rate = torchaudio.load(path)\n",
    "    if inp_rate != config.rate:\n",
    "        import torchaudio.transforms as T\n",
    "        resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "        waveform = resampler(waveform)\n",
    "    if waveform.shape[1] < config.rate*min_length:\n",
    "        #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "        f_out = pad_mean(waveform)\n",
    "    else:\n",
    "        f = waveform[0]\n",
    "        f_out = f.unsqueeze(0)\n",
    "    \n",
    "    \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a445b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor(df):\n",
    "    \n",
    "    path_name = \"../data/audio/\"\n",
    "    file = df.loc[idx]['id'])}.wav\")\n",
    "    waveform, inp_rate = torchaudio.load(path)\n",
    "        \n",
    "        if inp_rate != config.rate:\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "            waveform = resampler(waveform)\n",
    "    \n",
    "        \n",
    "        #waveform, rate = torchaudio.load(path)\n",
    "                \n",
    "        if waveform.shape[1] < config.rate*self.min_length:\n",
    "            #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "            f_out = pad_mean(waveform)\n",
    "        else:\n",
    "            f = waveform[0]\n",
    "            f_out = f.unsqueeze(0)\n",
    "            \n",
    "        return f_out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #real_idx = idx % len(self.audio_df)\n",
    "        if DEBUG:\n",
    "            print(\"\")\n",
    "            print(\"idx = \" + str(idx))\n",
    "        x = self._get_sample_(os.path.join(self.data_dir,f\"{int(self.audio_df.loc[idx]['id'])}.wav\"), resample=config.rate)\n",
    "        \n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"shape of x post augmentation = \" + str(x.shape))\n",
    "            \n",
    "        \n",
    "        # random noise on even number indexes\n",
    "        offset = int(self.audio_df.loc[idx]['offset'])\n",
    "        if DEBUG:\n",
    "            print(\"returning x of shape ...\" + str(x[:,offset:int(offset+config.rate*self.min_length)].shape))\n",
    "        \n",
    "        return (x[:,offset:int(offset+config.rate*self.min_length)],self.audio_df.loc[idx]['specie_ind'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41cc306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the model checkpoint as a parameter as input\n",
    "# read the val df\n",
    "#get the tensor rep for the offset.\n",
    "#pass it to the model get add get the prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d79c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "pred = []\n",
    "for i in range(10):\n",
    "    label.append(np.random.rand(9))\n",
    "    pred.append(np.random.rand(9))\n",
    "print(label)\n",
    "print(pred)\n",
    "print(classification_report(label, pred, target_names= classes, labels= classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985a6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.tensor(8, device = \"cuda\")\n",
    "print(label)\n",
    "label_cpu = label.cpu().detach()\n",
    "print(label_cpu)\n",
    "label_np = label_cpu.numpy()\n",
    "print(type(label_np))\n",
    "label_np_item = label_np.item()\n",
    "print(type(label_np_item))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cf810",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.randn(4,9)\n",
    "y_pred.shape\n",
    "#y_pred_np = y_pred.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6134f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_np\n",
    "# y_pred_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d224abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(y_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de9733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d98406",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,(x,y) in enumerate(test_loader):\n",
    "    print(\"idx = \" + str(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad82885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd9801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9013d98b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
