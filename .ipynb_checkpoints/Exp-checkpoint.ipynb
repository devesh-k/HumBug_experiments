{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ee3cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d57acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../../src'))\n",
    "sys.path.insert(0, os.path.abspath('ComParE2022_VecNet/src'))\n",
    "import config,config_pytorch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score ,confusion_matrix, classification_report\n",
    "\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import random\n",
    "import torchaudio\n",
    "import torchaudio.transforms as AT\n",
    "import torchvision.transforms as VT\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "#from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "import timm\n",
    "import timm.optim\n",
    "from timm.models import model_parameters\n",
    "from glob import glob\n",
    "## nnAudio\n",
    "from nnAudio import features\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import argparse\n",
    "## DDp Import\n",
    "import torch.distributed as dist\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import argparse\n",
    "#import deepspeed\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "import torch.profiler\n",
    "from contextlib import ExitStack\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42692126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_size =8, hidden_size =8, output_size=8):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Gate(nn.Module):\n",
    "    def __init__(self, input_size=8, num_experts = 8):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.softmax(x, dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b5c72ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model_name, image_size = 224):\n",
    "        super().__init__()\n",
    "        # num_classes=0 removes the pretrained head\n",
    "        self.backbone = timm.create_model(model_name,\n",
    "                        pretrained=True, num_classes=8, in_chans=1, \n",
    "                        drop_path_rate=0.2, global_pool='max',\n",
    "                        drop_rate=0.25)\n",
    "        #####  This section is model specific\n",
    "        #### It freezes some fo the layers by name\n",
    "        #### you'll have to inspect the model to see the names\n",
    "                #### end layer freezing\n",
    "        self.out = nn.Linear(self.backbone.num_features, 1)\n",
    "        self.sizer = VT.Resize((image_size,image_size),antialias = True)\n",
    "        self.spec_layer = features.STFT(n_fft=int(config.NFFT), freq_bins=None, hop_length=int(config.n_hop),\n",
    "                              window='hann', freq_scale='linear', center=True, pad_mode='reflect',\n",
    "                           sr=config.rate, output_format=\"Magnitude\", trainable=False,verbose = False).to('cuda')\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features= 1)\n",
    "        #self.augment_layer = augment_audio(trainable = True, sample_rate = config.rate)\n",
    "        \n",
    "    def forward(self, x,train = True):\n",
    "        # first compute spectrogram\n",
    "        spec_gram = self.spec_layer(x)\n",
    "        output = {}\n",
    "        #print(\"post spec gram shape = \",spec_gram.shape)\n",
    "        spec_gram = self.batch_norm(spec_gram.unsqueeze(dim = 1))\n",
    "        #print(\"post norm shape = \",spec_gram.shape)\n",
    "        spec_gram_nan_check = torch.isnan(spec_gram).any().item()\n",
    "        assert not (spec_gram_nan_check) ,\"Tensor contains NaN values after spec gram creation.\"\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if train == True:\n",
    "                #generate a random number and if condition is met apply aug\n",
    "                ta_transformations_rndm_choice = VT.RandomChoice([AT.FrequencyMasking(freq_mask_param=100),AT.TimeMasking(time_mask_param=50)], p=[.4, .4])\n",
    "                ta_transformations_rndm_apply = VT.RandomApply([AT.FrequencyMasking(freq_mask_param=50),AT.TimeMasking(time_mask_param=25)],p = .15)\n",
    "                spec_gram = ta_transformations_rndm_choice(spec_gram)\n",
    "                spec_gram = ta_transformations_rndm_apply(spec_gram)\n",
    "                spec_gram_nan_check = torch.isnan(spec_gram).any().item()\n",
    "                assert not (spec_gram_nan_check) ,\"Tensor contains NaN values after augmentations  \"\n",
    "                aug_bat = [ta_transformations_rndm_choice(spec_gram),ta_transformations_rndm_apply(spec_gram)]\n",
    "                output['feat'] = aug_bat\n",
    "                \n",
    "        x = self.sizer(spec_gram.squeeze(dim = 1))\n",
    "        #print(\"post sizer shape = \",x.shape)\n",
    "        x = x.unsqueeze(dim = 1)\n",
    "        #print(\"post unsqueeze shape = \",x.shape)\n",
    "        \n",
    "        # then repeat channels\n",
    "        del spec_gram,spec_gram_nan_check\n",
    "        if DEBUG:\n",
    "            print(\"Final shape that goes to backbone = \" + str(x.shape))\n",
    "                \n",
    "        x = self.backbone(x)\n",
    "        backbone_op_nan_check = torch.isnan(x).any().item()\n",
    "        assert not (backbone_op_nan_check) ,\"Tensor contains NaN values in the backbone OP \"\n",
    "        #print(\"x shape = \" + str(x.shape))\n",
    "        #print(\"x = \" +str(x))\n",
    "        #pred = nn.Softmax(x)\n",
    "        pred = x\n",
    "        #print(np.argmax(pred.detach().cpu().numpy()))\n",
    "        #print(pred)\n",
    "        output[\"prediction\"]=  pred \n",
    "        #print(output)\n",
    "        del x , backbone_op_nan_check\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66655111",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,15360,device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cad4b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b =MyModel('convnext_xlarge_in22k',224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0ddbeab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cuda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_76/1128134076.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cuda' is not defined"
     ]
    }
   ],
   "source": [
    "model_b.to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d520afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea13666c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348159443"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a468c80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DEBUG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_76/4274442179.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_76/3068367235.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, train)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# then repeat channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mspec_gram\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspec_gram_nan_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final shape that goes to backbone = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DEBUG' is not defined"
     ]
    }
   ],
   "source": [
    "o = model_b(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "052d19ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0905],\n",
      "         [-0.1756],\n",
      "         [-0.0890],\n",
      "         [ 0.0043],\n",
      "         [-0.0442],\n",
      "         [ 0.0535],\n",
      "         [ 0.1331],\n",
      "         [-0.0163]]], grad_fn=<BmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47432910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size , num_classes , num_experts):\n",
    "        super().__init__()\n",
    "        self.experts = nn.ModuleList([Expert(input_size, hidden_size, num_classes) for _ in range(num_experts)])\n",
    "        self.gate = Gate(input_size, num_experts)\n",
    "        self.input = MyModel('convnext_xlarge_in22k',224)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        print(\"shape post cnn = \",x.shape)\n",
    "        expert_outputs = [expert(x) for expert in self.experts]\n",
    "        print(\"expert_outputs = \",expert_outputs)\n",
    "        expert_outputs = torch.stack(expert_outputs, dim=1)\n",
    "        print(\"expert_outputs post stack = \",expert_outputs)\n",
    "        print(\"post stack shape  = \",expert_outputs.shape)\n",
    "        \n",
    "        gate_outputs = self.gate(x)\n",
    "        print(\" gate_outputs= \",gate_outputs)\n",
    "        print(\" gate_outputs shape = \",gate_outputs.shape)\n",
    "        \n",
    "        gate_outputs = gate_outputs.unsqueeze(2)\n",
    "        print(\"post unsqueeze gate_outputs =  \",gate_outputs.shape)\n",
    "        weighted_sum = torch.bmm(expert_outputs, gate_outputs)\n",
    "        print(\"weighted_sum = \",weighted_sum)\n",
    "        \n",
    "        return weighted_sum.squeeze(2)\n",
    "\n",
    "# Example usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be8f6439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post spec gram shape =  torch.Size([1, 1025, 121])\n",
      "post norm shape =  torch.Size([1, 1, 1025, 121])\n",
      "post sizer shape =  torch.Size([1, 224, 224])\n",
      "post unsqueeze shape =  torch.Size([1, 1, 224, 224])\n",
      "x shape = torch.Size([1, 8])\n",
      "shape post cnn =  torch.Size([1, 8])\n",
      "expert_outputs =  [tensor([[ 0.2929,  0.0893, -0.2214, -0.0515,  0.0937,  0.0526,  0.2732, -0.0616]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.1425, -0.2046,  0.1789,  0.2661,  0.3432,  0.1691,  0.1548, -0.0121]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.4719, -0.1176, -0.2985, -0.2853,  0.0560, -0.2683,  0.6084, -0.0822]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0644, -0.1544, -0.1961,  0.0087,  0.0336, -0.2573,  0.2496,  0.1691]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.4718,  0.4125, -0.2638, -0.1281,  0.3371, -0.2907,  0.1157,  0.3006]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.3383, -0.2543,  0.2033,  0.1455,  0.0376,  0.0285, -0.2432, -0.3004]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.3286, -0.1048,  0.2065, -0.0592, -0.4057,  0.0907,  0.4603,  0.2600]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.4004,  0.3137, -0.1371,  0.1570,  0.1382, -0.0024, -0.2622,  0.1794]],\n",
      "       grad_fn=<AddmmBackward0>)]\n",
      "expert_outputs post stack =  tensor([[[ 0.2929,  0.0893, -0.2214, -0.0515,  0.0937,  0.0526,  0.2732,\n",
      "          -0.0616],\n",
      "         [ 0.1425, -0.2046,  0.1789,  0.2661,  0.3432,  0.1691,  0.1548,\n",
      "          -0.0121],\n",
      "         [ 0.4719, -0.1176, -0.2985, -0.2853,  0.0560, -0.2683,  0.6084,\n",
      "          -0.0822],\n",
      "         [-0.0644, -0.1544, -0.1961,  0.0087,  0.0336, -0.2573,  0.2496,\n",
      "           0.1691],\n",
      "         [-0.4718,  0.4125, -0.2638, -0.1281,  0.3371, -0.2907,  0.1157,\n",
      "           0.3006],\n",
      "         [-0.3383, -0.2543,  0.2033,  0.1455,  0.0376,  0.0285, -0.2432,\n",
      "          -0.3004],\n",
      "         [-0.3286, -0.1048,  0.2065, -0.0592, -0.4057,  0.0907,  0.4603,\n",
      "           0.2600],\n",
      "         [ 0.4004,  0.3137, -0.1371,  0.1570,  0.1382, -0.0024, -0.2622,\n",
      "           0.1794]]], grad_fn=<StackBackward0>)\n",
      "post stack shape  =  torch.Size([1, 8, 8])\n",
      " gate_outputs=  tensor([[0.1587, 0.0981, 0.1216, 0.0599, 0.1327, 0.1474, 0.1833, 0.0982]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      " gate_outputs shape =  torch.Size([1, 8])\n",
      "post unsqueeze gate_outputs =   torch.Size([1, 8, 1])\n",
      "weighted_sum =  tensor([[[ 0.0894],\n",
      "         [ 0.1379],\n",
      "         [ 0.0813],\n",
      "         [-0.0198],\n",
      "         [-0.0216],\n",
      "         [-0.1101],\n",
      "         [ 0.0286],\n",
      "         [ 0.0746]]], grad_fn=<BmmBackward0>)\n",
      "output =  tensor([[ 0.0894,  0.1379,  0.0813, -0.0198, -0.0216, -0.1101,  0.0286,  0.0746]],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "model = MoE(input_size=8, hidden_size=8, num_classes=8, num_experts=8)\n",
    "input_data = torch.randn(1, 15360)\n",
    "output = model(input_data)\n",
    "print(\"output = \",output)  # (32, 5)\n",
    "pred = torch.argmax(output, dim = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d5df371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de816b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Expert, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "class Gate(nn.Module):\n",
    "    def __init__(self, input_size, num_experts):\n",
    "        super(Gate, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, num_experts)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "class MixtureOfExperts(nn.Module):\n",
    "    def __init__(self, input_size =8 , hidden_size = 8, num_experts = 8):\n",
    "        super(MixtureOfExperts, self).__init__()\n",
    "        self.experts = nn.ModuleList([Expert(input_size, hidden_size) for i in range(num_experts)])\n",
    "        self.gate = Gate(input_size, num_experts)\n",
    "        self.input = MyModel('convnext_xlarge_in22k',224)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        gates = self.gate(x)\n",
    "        print(\"shape after gates is = \",gates.shape)\n",
    "        print(\"output of gates = \",gates)\n",
    "        expert_outputs = [expert(x) for expert in self.experts]\n",
    "        print(\"expert_outputs = \",expert_outputs)\n",
    "        output = torch.stack(expert_outputs, dim=1)\n",
    "        print(\"output post stack  = \",output)\n",
    "        print(\"post stack shape   = \",output.shape)\n",
    "        output = torch.bmm(gates.unsqueeze(1), output).squeeze(1)\n",
    "        print(\"Final output = \",output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46764a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "moe_model = MixtureOfExperts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab752b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post spec gram shape =  torch.Size([1, 1025, 121])\n",
      "post norm shape =  torch.Size([1, 1, 1025, 121])\n",
      "post sizer shape =  torch.Size([1, 224, 224])\n",
      "post unsqueeze shape =  torch.Size([1, 1, 224, 224])\n",
      "x shape = torch.Size([1, 8])\n",
      "shape after gates is =  torch.Size([1, 8])\n",
      "output of gates =  tensor([[0.1725, 0.0945, 0.0841, 0.1015, 0.1362, 0.1459, 0.1654, 0.0999]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "expert_outputs =  [tensor([[0.0326]], grad_fn=<AddmmBackward0>), tensor([[-0.1055]], grad_fn=<AddmmBackward0>), tensor([[0.4171]], grad_fn=<AddmmBackward0>), tensor([[-0.0510]], grad_fn=<AddmmBackward0>), tensor([[0.2768]], grad_fn=<AddmmBackward0>), tensor([[0.2766]], grad_fn=<AddmmBackward0>), tensor([[0.6636]], grad_fn=<AddmmBackward0>), tensor([[-0.1350]], grad_fn=<AddmmBackward0>)]\n",
      "output post stack  =  tensor([[[ 0.0326],\n",
      "         [-0.1055],\n",
      "         [ 0.4171],\n",
      "         [-0.0510],\n",
      "         [ 0.2768],\n",
      "         [ 0.2766],\n",
      "         [ 0.6636],\n",
      "         [-0.1350]]], grad_fn=<StackBackward0>)\n",
      "post stack shape   =  torch.Size([1, 8, 1])\n",
      "Final output =  tensor([[0.1999]], grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1999]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moe_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d298e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
