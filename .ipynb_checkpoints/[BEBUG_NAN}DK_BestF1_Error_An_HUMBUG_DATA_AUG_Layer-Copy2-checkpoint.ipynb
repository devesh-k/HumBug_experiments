{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b740a532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/task/ComParE2022_VecNet/notebooks/DK\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddbee4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".CodeMirror{\n",
       "font-size: 14px;\n",
       "</style>\n",
       "CUDA_LAUNCH_BLOCKING=1\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "font-size: 14px;\n",
    "</style>\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ce597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8605cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://zenodo.org/record/4904800/files/humbugdb_neurips_2021_1.zip?download=1\n",
    "# !wget https://zenodo.org/record/4904800/files/humbugdb_neurips_2021_2.zip?download=1\n",
    "# !wget https://zenodo.org/record/4904800/files/humbugdb_neurips_2021_3.zip?download=1\n",
    "# !wget https://zenodo.org/record/4904800/files/humbugdb_neurips_2021_4.zip?download=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41406478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip /content/humbugdb_neurips_2021_1.zip?download=1 -d '/content/HumBugDB/data/audio'\n",
    "# !unzip /content/humbugdb_neurips_2021_2.zip?download=1 -d '/content/HumBugDB/data/audio'\n",
    "# !unzip /content/humbugdb_neurips_2021_3.zip?download=1 -d '/content/HumBugDB/data/audio'\n",
    "# !unzip /content/humbugdb_neurips_2021_4.zip?download=1 -d '/content/HumBugDB/data/audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36765d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch_audiomentations in /opt/conda/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: torchaudio>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from torch_audiomentations) (0.11.0+cu113)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /opt/conda/lib/python3.8/site-packages (from torch_audiomentations) (1.2.2)\n",
      "Requirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.8/site-packages (from torch_audiomentations) (1.11.0+cu113)\n",
      "Requirement already satisfied: librosa>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from torch_audiomentations) (0.8.1)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in /opt/conda/lib/python3.8/site-packages (from torch_audiomentations) (0.2.6)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (1.6.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (1.21.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (21.3)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (2.1.9)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (0.24.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (5.1.0)\n",
      "Requirement already satisfied: numba>=0.43.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (0.53.1)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (0.10.3.post1)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (1.5.2)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (0.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from numba>=0.43.0->librosa>=0.6.0->torch_audiomentations) (59.4.0)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/lib/python3.8/site-packages (from numba>=0.43.0->librosa>=0.6.0->torch_audiomentations) (0.36.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->librosa>=0.6.0->torch_audiomentations) (3.0.6)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (1.4.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (2.26.0)\n",
      "Requirement already satisfied: six>=1.3 in /opt/conda/lib/python3.8/site-packages (from resampy>=0.2.2->librosa>=0.6.0->torch_audiomentations) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.6.0->torch_audiomentations) (3.0.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.8/site-packages (from soundfile>=0.10.2->librosa>=0.6.0->torch_audiomentations) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.6.0->torch_audiomentations) (2.21)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.0->torch_audiomentations) (4.0.1)\n",
      "Requirement already satisfied: primePy>=1.3 in /opt/conda/lib/python3.8/site-packages (from torch-pitch-shift>=1.2.2->torch_audiomentations) (1.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (1.26.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.6.3)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.21.4)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (9.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (4.28.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (3.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (6.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (1.2.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (59.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_audiomentations\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f4e9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_audiomentations import Compose,AddBackgroundNoise , AddColoredNoise , ApplyImpulseResponse,PeakNormalization,TimeInversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a336159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to find the right version of pytorch with the widget here https://pytorch.org/\n",
    "# I *think* this will work with AWS\n",
    "#!pip3 install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7751a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other dependencies\n",
    "#!pip install timm ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3708c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nnAudio\n",
    "#!pip install git+https://github.com/KinWaiCheuk/nnAudio.git#subdirectory=Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeb3c1e",
   "metadata": {},
   "source": [
    "### 1 Import the kitchen sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c5bb941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n"
     ]
    }
   ],
   "source": [
    "%env CUBLAS_WORKSPACE_CONFIG=:4096:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20e59bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/task/ComParE2022_VecNet/notebooks/DK\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a6717ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# humbug main imports\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../../src'))\n",
    "import config ,config_pytorch\n",
    "from evaluate import get_results\n",
    "import numpy as np\n",
    "\n",
    "# Troubleshooting and visualisation\n",
    "import IPython.display as ipd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27a65eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# humbug lib imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "#from PyTorch import config_pytorch\n",
    "from datetime import datetime\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5921f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional pytorch tools\n",
    "import random\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torchvision.transforms as VT\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "import timm\n",
    "import timm.optim\n",
    "from timm.loss import BinaryCrossEntropy\n",
    "from timm.utils import NativeScaler\n",
    "from timm.models import model_parameters\n",
    "from glob import glob\n",
    "from torch_audiomentations import Compose, Gain, PolarityInversion,AddColoredNoise,ApplyImpulseResponse,PeakNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2da97bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nnAudio\n",
    "from nnAudio import features\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "308be9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4419bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f410d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Training variables \n",
    "USE_SHORT_AUDIO = True\n",
    "num_workers=8\n",
    "pin_memory=True\n",
    "#train_size = 100\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "DEBUG = True\n",
    "if DEBUG:\n",
    "    batch_size = 64\n",
    "    test_batch_size = 64\n",
    "    num_workers=1\n",
    "    \n",
    "     \n",
    "\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d07a8c",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "376006db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates 1.92 secs rows of audio in a data frame format\n",
    "def get_offsets_df(df, short_audio=False):\n",
    "    audio_offsets = []\n",
    "    min_length = config.win_size*config.NFFT/(((1/config.n_hop)*config.NFFT)*config.rate)\n",
    "    step_frac = config.step_size/config.win_size\n",
    "    for _,row in df.iterrows():\n",
    "        if row['length'] > min_length:\n",
    "            step_size = step_frac*min_length\n",
    "            audio_offsets.append({'id':row['id'], 'offset':0, 'length': row['length'],'specie_ind': row['specie_ind']})\n",
    "            for i in range(1, int((row['length']-min_length)//step_size)):\n",
    "                audio_offsets.append({'id': row['id'], 'offset':int(min_length+(i*step_size)*config.rate), 'length': row['length'],'specie_ind': row['specie_ind']})\n",
    "        elif short_audio:\n",
    "            audio_offsets.append({'id':row['id'], 'offset':0,'length': row['length'],'specie_ind': row['specie_ind']})\n",
    "    return pd.DataFrame(audio_offsets)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55d3a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['an arabiensis','culex pipiens complex', 'ae aegypti','an funestus ss','an squamosus',\n",
    "               'an coustani','ma uniformis','ma africanus' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1883c6",
   "metadata": {},
   "source": [
    "### Read CSV and get train/test groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c67b0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>name</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>record_datetime</th>\n",
       "      <th>sound_type</th>\n",
       "      <th>species</th>\n",
       "      <th>gender</th>\n",
       "      <th>fed</th>\n",
       "      <th>plurality</th>\n",
       "      <th>age</th>\n",
       "      <th>method</th>\n",
       "      <th>mic_type</th>\n",
       "      <th>device_type</th>\n",
       "      <th>country</th>\n",
       "      <th>district</th>\n",
       "      <th>province</th>\n",
       "      <th>place</th>\n",
       "      <th>location_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>0.463456</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>0.170249</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>0.104041</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>0.274290</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56</td>\n",
       "      <td>0.420894</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>3562</td>\n",
       "      <td>6.083093</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000</th>\n",
       "      <td>3556</td>\n",
       "      <td>6.719908</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an maculatus</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9009</th>\n",
       "      <td>3553</td>\n",
       "      <td>6.128580</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an maculatus</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9011</th>\n",
       "      <td>3561</td>\n",
       "      <td>11.614280</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9012</th>\n",
       "      <td>3552</td>\n",
       "      <td>2.920249</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6008 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     length                             name  sample_rate  \\\n",
       "1       53   0.463456  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "2       57   0.170249  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "3       61   0.104041  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "4       69   0.274290  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "5       56   0.420894  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "...    ...        ...                              ...          ...   \n",
       "8999  3562   6.083093                    #988-1001.wav        44100   \n",
       "9000  3556   6.719908                    #988-1001.wav        44100   \n",
       "9009  3553   6.128580                    #988-1001.wav        44100   \n",
       "9011  3561  11.614280                    #988-1001.wav        44100   \n",
       "9012  3552   2.920249                    #988-1001.wav        44100   \n",
       "\n",
       "     record_datetime sound_type       species  gender  fed plurality  age  \\\n",
       "1      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "2      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "3      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "4      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "5      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Plural  NaN   \n",
       "...              ...        ...           ...     ...  ...       ...  ...   \n",
       "8999  1/7/2018 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "9000  1/7/2018 12:00   mosquito  an maculatus  Female    t    Single  NaN   \n",
       "9009  1/7/2018 12:00   mosquito  an maculatus  Female    t    Single  NaN   \n",
       "9011  1/7/2018 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "9012  1/7/2018 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "\n",
       "     method mic_type    device_type   country          district  \\\n",
       "1       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "2       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "3       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "4       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "5       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "...     ...      ...            ...       ...               ...   \n",
       "8999    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9000    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9009    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9011    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9012    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "\n",
       "                   province                            place location_type  \n",
       "1                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "2                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "3                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "4                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "5                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "...                     ...                              ...           ...  \n",
       "8999  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9000  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9009  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9011  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9012  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "\n",
       "[6008 rows x 19 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if DEBUG:\n",
    "#     df = pd.read_csv(config.data_df_msc_test)\n",
    "# else:\n",
    "df = pd.read_csv(config.data_df)\n",
    "\n",
    "#df = df.loc[df['Grade'].notnull()]\n",
    "df = df.loc[df['species'].notnull()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bb632d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a colum for specie encoding\n",
    "df['specie_ind'] = \"NULL_VAL\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b51e3e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specie = an arabiensisand its index = 0\n",
      "specie = culex pipiens complexand its index = 1\n",
      "specie = ae aegyptiand its index = 2\n",
      "specie = an funestus ssand its index = 3\n",
      "specie = an squamosusand its index = 4\n",
      "specie = an coustaniand its index = 5\n",
      "specie = ma uniformisand its index = 6\n",
      "specie = ma africanusand its index = 7\n"
     ]
    }
   ],
   "source": [
    "# Adding a new column to encode specie_index in the same order as the list \"classes\"\n",
    "ind = 0\n",
    "for specie in classes:\n",
    "    print(\"specie = \" + str(specie) + \"and its index = \" + str(ind) )\n",
    "    row_indexes=df[df['species']==specie].index \n",
    "    df.loc[row_indexes,'specie_ind']= ind\n",
    "    ind+=1\n",
    "\n",
    "    \n",
    "# other_df_ind = df[df['specie_ind'] == \"NULL_VAL\"].index\n",
    "# df.loc[other_df_ind,'specie_ind']= other_ind                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e82211cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['specie_ind'] == \"NULL_VAL\"].index, inplace=True)\n",
    "#other_df_ind = df[df['specie_ind'] == \"NULL_VAL\"].index\n",
    "#df.loc[other_df_ind,'specie_ind']= other_ind        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d9a409",
   "metadata": {},
   "source": [
    "At this stage we have all extracted the data with specie information and have encoded the specie encoding in a col = 'specie_ind'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "225525c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the TZ and Cup data- this is as per the humbug paper\n",
    "\n",
    "idx_multiclass = np.logical_and(df['country'] == 'Tanzania', df['location_type'] == 'cup')\n",
    "df_all = df[idx_multiclass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb8c3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f758f6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>name</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>record_datetime</th>\n",
       "      <th>sound_type</th>\n",
       "      <th>species</th>\n",
       "      <th>gender</th>\n",
       "      <th>fed</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>method</th>\n",
       "      <th>mic_type</th>\n",
       "      <th>device_type</th>\n",
       "      <th>country</th>\n",
       "      <th>district</th>\n",
       "      <th>province</th>\n",
       "      <th>place</th>\n",
       "      <th>location_type</th>\n",
       "      <th>specie_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1879</td>\n",
       "      <td>221103</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_24_664.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1880</td>\n",
       "      <td>221111</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_25_665.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1881</td>\n",
       "      <td>221110</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_25_665.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1882</td>\n",
       "      <td>221149</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_26_666.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an arabiensis</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1883</td>\n",
       "      <td>221150</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_26_666.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an arabiensis</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>4546</td>\n",
       "      <td>222615</td>\n",
       "      <td>30.72</td>\n",
       "      <td>IFA_86_39_3439.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>4547</td>\n",
       "      <td>222585</td>\n",
       "      <td>25.60</td>\n",
       "      <td>IFA_86_40_3440.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>4548</td>\n",
       "      <td>222586</td>\n",
       "      <td>40.90</td>\n",
       "      <td>IFA_87_10_3450.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>4549</td>\n",
       "      <td>222596</td>\n",
       "      <td>40.90</td>\n",
       "      <td>IFA_87_11_3451.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>4550</td>\n",
       "      <td>222614</td>\n",
       "      <td>38.40</td>\n",
       "      <td>IFA_87_12_3452.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2288 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      id  length                name  sample_rate record_datetime  \\\n",
       "0      1879  221103    2.56   IFA_17_24_664.wav        44100  30-01-20 00:00   \n",
       "1      1880  221111    2.56   IFA_17_25_665.wav        44100  30-01-20 00:00   \n",
       "2      1881  221110    2.56   IFA_17_25_665.wav        44100  30-01-20 00:00   \n",
       "3      1882  221149    2.56   IFA_17_26_666.wav        44100  30-01-20 00:00   \n",
       "4      1883  221150    2.56   IFA_17_26_666.wav        44100  30-01-20 00:00   \n",
       "...     ...     ...     ...                 ...          ...             ...   \n",
       "2283   4546  222615   30.72  IFA_86_39_3439.wav        44100  23-08-20 00:00   \n",
       "2284   4547  222585   25.60  IFA_86_40_3440.wav        44100  23-08-20 00:00   \n",
       "2285   4548  222586   40.90  IFA_87_10_3450.wav        44100  23-08-20 00:00   \n",
       "2286   4549  222596   40.90  IFA_87_11_3451.wav        44100  23-08-20 00:00   \n",
       "2287   4550  222614   38.40  IFA_87_12_3452.wav        44100  23-08-20 00:00   \n",
       "\n",
       "     sound_type         species  gender fed  ... age  method mic_type  \\\n",
       "0      mosquito    ma africanus  Female   f  ... NaN     HBN  telinga   \n",
       "1      mosquito    ma africanus  Female   f  ... NaN     HBN  telinga   \n",
       "2      mosquito    ma africanus  Female   f  ... NaN     HBN  telinga   \n",
       "3      mosquito   an arabiensis  Female   f  ... NaN     HBN  telinga   \n",
       "4      mosquito   an arabiensis  Female   f  ... NaN     HBN  telinga   \n",
       "...         ...             ...     ...  ..  ...  ..     ...      ...   \n",
       "2283   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2284   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2285   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2286   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2287   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "\n",
       "     device_type   country            district  province    place  \\\n",
       "0         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "1         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "3         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "4         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "...          ...       ...                 ...       ...      ...   \n",
       "2283      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2284      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2285      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2286      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2287      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "\n",
       "     location_type specie_ind  \n",
       "0              cup          7  \n",
       "1              cup          7  \n",
       "2              cup          7  \n",
       "3              cup          0  \n",
       "4              cup          0  \n",
       "...            ...        ...  \n",
       "2283           cup          3  \n",
       "2284           cup          3  \n",
       "2285           cup          3  \n",
       "2286           cup          3  \n",
       "2287           cup          3  \n",
       "\n",
       "[2288 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1993bb3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b2e3d91",
   "metadata": {},
   "source": [
    "### Train-Test split( avoiding sklearn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04da3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "msk_test = np.random.rand(len(df_all)) < 0.2\n",
    "df_test = df_all[msk_test]\n",
    "df_train_temp  = df_all[~msk_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afa28566",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "msk_train = np.random.rand(len(df_train_temp)) < 0.2\n",
    "df_val = df_train_temp[msk_train]\n",
    "df_train  = df_train_temp[~msk_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa01a91",
   "metadata": {},
   "source": [
    "## Let's verify for data leakage by performing an inner-join on id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7f0f04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>length_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>sample_rate_x</th>\n",
       "      <th>record_datetime_x</th>\n",
       "      <th>sound_type_x</th>\n",
       "      <th>species_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>fed_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_y</th>\n",
       "      <th>method_y</th>\n",
       "      <th>mic_type_y</th>\n",
       "      <th>device_type_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>district_y</th>\n",
       "      <th>province_y</th>\n",
       "      <th>place_y</th>\n",
       "      <th>location_type_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, length_x, name_x, sample_rate_x, record_datetime_x, sound_type_x, species_x, gender_x, fed_x, plurality_x, age_x, method_x, mic_type_x, device_type_x, country_x, district_x, province_x, place_x, location_type_x, specie_ind_x, index_y, length_y, name_y, sample_rate_y, record_datetime_y, sound_type_y, species_y, gender_y, fed_y, plurality_y, age_y, method_y, mic_type_y, device_type_y, country_y, district_y, province_y, place_y, location_type_y, specie_ind_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_test,df_train, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c3e9b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>length_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>sample_rate_x</th>\n",
       "      <th>record_datetime_x</th>\n",
       "      <th>sound_type_x</th>\n",
       "      <th>species_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>fed_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_y</th>\n",
       "      <th>method_y</th>\n",
       "      <th>mic_type_y</th>\n",
       "      <th>device_type_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>district_y</th>\n",
       "      <th>province_y</th>\n",
       "      <th>place_y</th>\n",
       "      <th>location_type_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, length_x, name_x, sample_rate_x, record_datetime_x, sound_type_x, species_x, gender_x, fed_x, plurality_x, age_x, method_x, mic_type_x, device_type_x, country_x, district_x, province_x, place_x, location_type_x, specie_ind_x, index_y, length_y, name_y, sample_rate_y, record_datetime_y, sound_type_y, species_y, gender_y, fed_y, plurality_y, age_y, method_y, mic_type_y, device_type_y, country_y, district_y, province_y, place_y, location_type_y, specie_ind_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_test,df_val, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1cb3a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>length_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>sample_rate_x</th>\n",
       "      <th>record_datetime_x</th>\n",
       "      <th>sound_type_x</th>\n",
       "      <th>species_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>fed_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_y</th>\n",
       "      <th>method_y</th>\n",
       "      <th>mic_type_y</th>\n",
       "      <th>device_type_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>district_y</th>\n",
       "      <th>province_y</th>\n",
       "      <th>place_y</th>\n",
       "      <th>location_type_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, length_x, name_x, sample_rate_x, record_datetime_x, sound_type_x, species_x, gender_x, fed_x, plurality_x, age_x, method_x, mic_type_x, device_type_x, country_x, district_x, province_x, place_x, location_type_x, specie_ind_x, index_y, length_y, name_y, sample_rate_y, record_datetime_y, sound_type_y, species_y, gender_y, fed_y, plurality_y, age_y, method_y, mic_type_y, device_type_y, country_y, district_y, province_y, place_y, location_type_y, specie_ind_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_train,df_val, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be6cb1b",
   "metadata": {},
   "source": [
    "We've confirmed that there is no recording that is common in Train,Test,val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2144463f",
   "metadata": {},
   "source": [
    "### Next, we perform \"offsets\", spliting each(long) recording into multiple 1.92 secs chunk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7bdc336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_offset = get_offsets_df(df_train, short_audio=USE_SHORT_AUDIO)\n",
    "df_test_offset = get_offsets_df(df_test, short_audio=USE_SHORT_AUDIO)\n",
    "df_val_offset = get_offsets_df(df_val, short_audio=USE_SHORT_AUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68a5f11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train offset = 32239\n",
      "length of test offset = 10087\n",
      "length of val offset = 8692\n"
     ]
    }
   ],
   "source": [
    "print(\"length of train offset = \" +str(len(df_train_offset)))\n",
    "print(\"length of test offset = \" +str(len(df_test_offset)))\n",
    "print(\"length of val offset = \" +str(len(df_val_offset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf45f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ec480",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f4a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f41c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_temp.reset_index(inplace = True)\n",
    "df_train_offset.reset_index(inplace = True)\n",
    "df_test_offset.reset_index(inplace = True)\n",
    "df_val_offset.reset_index(inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092152dc",
   "metadata": {},
   "source": [
    "### Let's check for data leakage in offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dea5c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>offset_x</th>\n",
       "      <th>length_x</th>\n",
       "      <th>specie_ind_x</th>\n",
       "      <th>index_y</th>\n",
       "      <th>offset_y</th>\n",
       "      <th>length_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, offset_x, length_x, specie_ind_x, index_y, offset_y, length_y, specie_ind_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_train_offset , df_test_offset , on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecd9efec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>offset_x</th>\n",
       "      <th>length_x</th>\n",
       "      <th>specie_ind_x</th>\n",
       "      <th>index_y</th>\n",
       "      <th>offset_y</th>\n",
       "      <th>length_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, offset_x, length_x, specie_ind_x, index_y, offset_y, length_y, specie_ind_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_train_offset , df_val_offset , on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b511b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>offset_x</th>\n",
       "      <th>length_x</th>\n",
       "      <th>specie_ind_x</th>\n",
       "      <th>index_y</th>\n",
       "      <th>offset_y</th>\n",
       "      <th>length_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, offset_x, length_x, specie_ind_x, index_y, offset_y, length_y, specie_ind_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_test_offset , df_val_offset , on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1371e177",
   "metadata": {},
   "source": [
    "### At this stage we've a dataframe of recordin ids and each row corresponds to a 1.92 secs recording or shorter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "431af410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specie_distri(df , classes , type_df = None):\n",
    "    \"\"\"This function takes a dataframe and provides a count of each specie class\"\"\"\n",
    "    for i in range(len(classes)):\n",
    "        print(\"DF type = \" + str(type_df))\n",
    "        df_temp = df[df['specie_ind'] == i]\n",
    "        print(\"i = \" +str(i))\n",
    "        print(len(df_temp))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18f90394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32298429 0.56615271 3.6109991  0.61779473 1.98809817 4.24197368\n",
      " 3.08802682 5.57382434]\n"
     ]
    }
   ],
   "source": [
    "#Class imbalance \n",
    "np.array(df_train_offset.specie_ind)\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',classes=np.unique(np.array(df_train_offset.specie_ind)),y=np.array(np.array(df_train_offset.specie_ind)))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0cbdcb",
   "metadata": {},
   "source": [
    "Let us now get the class distribution for each of the dataframes- train,test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c274455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bbb69f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF type = train\n",
      "i = 0\n",
      "12477\n",
      "DF type = train\n",
      "i = 1\n",
      "7118\n",
      "DF type = train\n",
      "i = 2\n",
      "1116\n",
      "DF type = train\n",
      "i = 3\n",
      "6523\n",
      "DF type = train\n",
      "i = 4\n",
      "2027\n",
      "DF type = train\n",
      "i = 5\n",
      "950\n",
      "DF type = train\n",
      "i = 6\n",
      "1305\n",
      "DF type = train\n",
      "i = 7\n",
      "723\n"
     ]
    }
   ],
   "source": [
    "get_specie_distri(df_train_offset , classes , type_df = \"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1aafe6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF type = Val\n",
      "i = 0\n",
      "3613\n",
      "DF type = Val\n",
      "i = 1\n",
      "1994\n",
      "DF type = Val\n",
      "i = 2\n",
      "230\n",
      "DF type = Val\n",
      "i = 3\n",
      "1855\n",
      "DF type = Val\n",
      "i = 4\n",
      "280\n",
      "DF type = Val\n",
      "i = 5\n",
      "228\n",
      "DF type = Val\n",
      "i = 6\n",
      "426\n",
      "DF type = Val\n",
      "i = 7\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "get_specie_distri(df_val_offset , classes , type_df = \"Val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fafa0b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF type = test\n",
      "i = 0\n",
      "4356\n",
      "DF type = test\n",
      "i = 1\n",
      "1879\n",
      "DF type = test\n",
      "i = 2\n",
      "439\n",
      "DF type = test\n",
      "i = 3\n",
      "1959\n",
      "DF type = test\n",
      "i = 4\n",
      "507\n",
      "DF type = test\n",
      "i = 5\n",
      "312\n",
      "DF type = test\n",
      "i = 6\n",
      "441\n",
      "DF type = test\n",
      "i = 7\n",
      "194\n"
     ]
    }
   ],
   "source": [
    "get_specie_distri(df_test_offset , classes , type_df = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be7a9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "628f55aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function pads a short-audio tensor with its mean to ensure that it becomes a 1.92 sec long audio equivalent\n",
    "def pad_mean(x_temp,rate = config.rate, min_length = config.min_duration ):\n",
    "    if DEBUG:\n",
    "        print(\"inside padding mean...\")\n",
    "    x_mean = torch.mean(x_temp)\n",
    "    #x_mean.cuda()\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"X_mean = \" + str(x_mean))\n",
    "    left_pad_amt = int((rate*min_length-x_temp.shape[1])//2)\n",
    "    if DEBUG:\n",
    "        print(\"left_pad_amt = \" + str(left_pad_amt))\n",
    "    left_pad = torch.zeros(1,left_pad_amt) #+ (0.1**0.5)*torch.randn(1, left_pad_amt)\n",
    "    if DEBUG:\n",
    "        print(\"left_pad shape = \" + str(left_pad.shape))\n",
    "    left_pad_mean_add = left_pad + x_mean\n",
    "    if DEBUG:\n",
    "        print(\"left_pad_mean shape = \" + str(left_pad_mean_add))\n",
    "        print(\"sum of left pad mean add = \" + str(torch.sum(left_pad_mean_add)))\n",
    "    \n",
    "    right_pad_amt = int(rate*min_length-x_temp.shape[1]-left_pad_amt)\n",
    "    right_pad = torch.zeros(1,right_pad_amt)# + (0.1**0.5)*torch.randn(1, right_pad_amt)\n",
    "    if DEBUG:\n",
    "        print(\"right_pad shape = \" + str(right_pad.shape))\n",
    "    right_pad_mean_add = right_pad + x_mean\n",
    "    if DEBUG:\n",
    "        print(\"right_pad_mean shape = \" + str(right_pad_mean_add))\n",
    "        print(\"sum of right pad mean add = \"  + str(torch.sum(right_pad_mean_add)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    f = torch.cat([left_pad,x_temp,right_pad],dim=1)[0]\n",
    "    f = f.unsqueeze(dim = 0)\n",
    "    #print(\"returning a tensor of shape = \" + str(f.shape))\n",
    "    return(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709f49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6a089dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_hat,y_true,classes):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_hat, y_true ,labels= range(len(classes)))\n",
    "    import seaborn as sns\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, fmt = 'g'); #annot=True to annotate cellsplt.xticks(rotation=90)\n",
    "    ax.xaxis.set_ticklabels(classes, fontsize = 10)\n",
    "    ax.xaxis.tick_bottom()\n",
    "    plt.xticks(rotation=90)\n",
    "    ax.set_ylabel('True', fontsize=20)\n",
    "    ax.yaxis.set_ticklabels(classes, fontsize = 10)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ed9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b498188e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.92"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the min length based on config params\n",
    "min_length = (config.win_size * config.n_hop) / config.rate\n",
    "min_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bfc1c8",
   "metadata": {},
   "source": [
    "### Class Defintions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "151a4151",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalization():\n",
    "    \"\"\"This class is for normalizing the spectrograms batch by batch. The normalization used is min-max, two modes 'framewise' and 'imagewise' can be selected. In this paper, we found that 'imagewise' normalization works better than 'framewise'\"\"\"\n",
    "    def __init__(self, mode='framewise'):\n",
    "        if mode == 'framewise':\n",
    "            def normalize(x):\n",
    "                size = x.shape\n",
    "                x_max = x.max(1, keepdim=True)[0] # Finding max values for each frame\n",
    "                x_min = x.min(1, keepdim=True)[0]  \n",
    "                output = (x-x_min)/(x_max-x_min) # If there is a column with all zero, nan will occur\n",
    "                output[torch.isnan(output)]=0 # Making nan to 0\n",
    "                return output\n",
    "        elif mode == 'imagewise':\n",
    "            def normalize(x):\n",
    "                size = x.shape\n",
    "                x_max = x.reshape(size[0], size[1]*size[2]).max(1, keepdim=True)[0]\n",
    "                x_min = x.reshape(size[0], size[1]*size[2]).min(1, keepdim=True)[0]\n",
    "                x_max = x_max.unsqueeze(1) # Make it broadcastable\n",
    "                x_min = x_min.unsqueeze(1) # Make it broadcastable \n",
    "                return (x-x_min)/(x_max-x_min)\n",
    "        else:\n",
    "            print(f'please choose the correct mode')\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45febbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcen(x, eps=1e-6, s=0.025, alpha=0.98, delta=2, r=0.5, training=False):\n",
    "    frames = x.split(1, -2)\n",
    "    m_frames = []\n",
    "    last_state = None\n",
    "    for frame in frames:\n",
    "        if last_state is None:\n",
    "            last_state = s * frame\n",
    "            m_frames.append(last_state)\n",
    "            continue\n",
    "        if training:\n",
    "            m_frame = ((1 - s) * last_state).add_(s * frame)\n",
    "        else:\n",
    "            m_frame = (1 - s) * last_state + s * frame\n",
    "        last_state = m_frame\n",
    "        m_frames.append(m_frame)\n",
    "    M = torch.cat(m_frames, 1)\n",
    "    if training:\n",
    "        pcen_ = (x / (M + eps).pow(alpha) + delta).pow(r) - delta ** r\n",
    "    else:\n",
    "        pcen_ = x.div_(M.add_(eps).pow_(alpha)).add_(delta).pow_(r).sub_(delta ** r)\n",
    "    return pcen_\n",
    "\n",
    "\n",
    "class PCENTransform(nn.Module):\n",
    "\n",
    "    def __init__(self, eps=1e-6, s=0.025, alpha=0.98, delta=2, r=0.5, trainable=True):\n",
    "        super().__init__()\n",
    "        if trainable:\n",
    "            self.log_s = nn.Parameter(torch.log(torch.Tensor([s])))\n",
    "            self.log_alpha = nn.Parameter(torch.log(torch.Tensor([alpha])))\n",
    "            self.log_delta = nn.Parameter(torch.log(torch.Tensor([delta])))\n",
    "            self.log_r = nn.Parameter(torch.log(torch.Tensor([r])))\n",
    "        else:\n",
    "            self.s = s\n",
    "            self.alpha = alpha\n",
    "            self.delta = delta\n",
    "            self.r = r\n",
    "        self.eps = eps\n",
    "        self.trainable = trainable\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = x.permute((0,2,1)).squeeze(dim=1)\n",
    "        if self.trainable:\n",
    "            x = pcen(x, self.eps, torch.exp(self.log_s), torch.exp(self.log_alpha), torch.exp(self.log_delta), torch.exp(self.log_r), self.training and self.trainable)\n",
    "        else:\n",
    "            x = pcen(x, self.eps, self.s, self.alpha, self.delta, self.r, self.training and self.trainable)\n",
    "#         x = x.unsqueeze(dim=1).permute((0,1,3,2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8a95fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>specie_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>221103</td>\n",
       "      <td>0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>221111</td>\n",
       "      <td>0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>221110</td>\n",
       "      <td>0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>221149</td>\n",
       "      <td>0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>221144</td>\n",
       "      <td>0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      id  offset  length  specie_ind\n",
       "0      0  221103       0    2.56           7\n",
       "1      1  221111       0    2.56           7\n",
       "2      2  221110       0    2.56           7\n",
       "3      3  221149       0    2.56           0\n",
       "4      4  221144       0    2.56           1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_offset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c9b3672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_df(loader , trained_model, DEBUG = False):\n",
    "    err_dict = {'id': None,\n",
    "               'label': None,\n",
    "               'offset':None,\n",
    "               'y_hat':None}\n",
    "    model = trained_model\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        model.eval()\n",
    "        if DEBUG:\n",
    "            print(\"inside test....\")\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        all_wav_id = []\n",
    "        all_offset = []\n",
    "        if DEBUG:\n",
    "            print(\"length of loader = \" + str(len(loader)))\n",
    "        for idx,(x,y,offset,wav_id) in enumerate(loader):\n",
    "            if DEBUG:\n",
    "                print(\"loader index = \" + str(idx))\n",
    "                print(\"y = \" + str(y))\n",
    "                print(\"offset = \" + str(offset))\n",
    "                print(\"wav_id = \" + str(wav_id))\n",
    "                \n",
    "            x = x.to(device).float() \n",
    "            y = y.type(torch.LongTensor).to(device)\n",
    "            y_pred = model(x)['prediction']\n",
    "            preds = torch.argmax(y_pred, axis = 1)\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            if DEBUG:\n",
    "                print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "            preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "            if DEBUG:\n",
    "                print(\"preds = \" +str(preds))\n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "            all_y.append(y.cpu().detach())\n",
    "            all_wav_id.append(wav_id.cpu().detach())\n",
    "            all_offset.append(offset.cpu().detach())\n",
    "            #all_y_pred.append(np.argmax(y_pred.cpu().detach().numpy()))\n",
    "            \n",
    "            del x\n",
    "            del y\n",
    "            del y_pred\n",
    "        all_y = torch.cat(all_y).numpy()\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        all_wav_id = torch.cat(all_wav_id)\n",
    "        all_offset = torch.cat(all_offset)\n",
    "        \n",
    "        err_dict['id'] = all_wav_id\n",
    "        err_dict['label'] = all_y\n",
    "        err_dict['offset'] = all_offset\n",
    "        err_dict['y_hat'] = all_y_pred\n",
    "        df_err = pd.DataFrame.from_dict(err_dict)\n",
    "        df_err_uniq = df_err[df_err['label']!= df_err['y_hat']]\n",
    "        df_err_uniq.sort_values(by=['id','offset'])\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"inside error ....\")\n",
    "            print(\"y = \" + str(all_y))\n",
    "            print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "        #test_loss = test_loss/len(test_loader)\n",
    "        #test_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "    \n",
    "    \n",
    "    return df_err_uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59740738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loader, criterion,  classes = classes,device=None , call = \"val\"):\n",
    "    softmax = nn.Softmax()\n",
    "    if DEBUG:\n",
    "        print(\"calling for ...\" +str(call))\n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        sigmoid = nn.Sigmoid()\n",
    "        test_loss = 0.0\n",
    "        model.eval()\n",
    "        if DEBUG:\n",
    "            print(\"inside test....\")\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        counter = 1\n",
    "        if DEBUG:\n",
    "            print(\"length of loader = \" + str(len(loader)))\n",
    "        for idx,(x,y) in enumerate(loader):\n",
    "            if DEBUG:\n",
    "                print(\"loader index = \" + str(idx))\n",
    "                            \n",
    "            x = x.to(device).float() \n",
    "            y = y.type(torch.LongTensor).to(device)\n",
    "            if DEBUG:\n",
    "                print(\"y = \" + str(y))\n",
    "            y_pred = model(x)['prediction']\n",
    "            y_pred_smax = softmax(y_pred)\n",
    "            preds = torch.argmax(y_pred_smax, axis = 1)\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            if DEBUG:\n",
    "                print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "            #preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "            if DEBUG:\n",
    "                print(\"preds = \" +str(preds))\n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "                                   \n",
    "            loss = criterion(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            all_y.append(y.cpu().detach())\n",
    "            #all_y_pred.append(np.argmax(y_pred.cpu().detach().numpy()))\n",
    "            \n",
    "            del x\n",
    "            del y\n",
    "            del y_pred\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        if DEBUG:\n",
    "            print(\"inside test....\")\n",
    "            print(\"y = \" + str(all_y))\n",
    "            print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "        test_loss = test_loss/len(test_loader)\n",
    "        test_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "    \n",
    "    \n",
    "    return test_loss, test_f1 , all_y,all_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1228d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(train_loader, val_loader, test_loader,model, classes ,class_weights ,num_epochs = num_epochs )\n",
    "def train_model(train_loader, val_loader,test_loader, model = None,  classes = classes,class_weights = class_weights,num_epochs = num_epochs ,n_channels = 1):\n",
    "    # Creates a GradScaler once at the beginning of training.\n",
    "    loss_scaler = NativeScaler()\n",
    "    global_step = 0\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Training on {device}')    \n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using data parallel\")\n",
    "        model = nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "\n",
    "    model = model.to(device)\n",
    "    weights_adj = torch.tensor(class_weights).type(torch.float).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights_adj)\n",
    "    optimiser = timm.optim.create_optimizer_v2(model.parameters(), lr=config_pytorch.lr/10,opt = 'lookahead_adam')\n",
    "    #optimiser = timm.optim.AdamW(model.parameters(), lr=config_pytorch.lr)\n",
    "    timm.optim.Lookahead(optimiser, alpha=0.5, k=6)\n",
    "    \n",
    "    #optimiser = timm.optim.RAdam(model.parameters(), lr=config_pytorch.lr/10)\n",
    "    num_epochs = num_epochs\n",
    "    all_train_loss = []\n",
    "    all_train_f1 = []\n",
    "    all_val_loss = []\n",
    "    all_val_f1 = []\n",
    "    best_val_loss = np.inf\n",
    "    best_val_f1 = -np.inf\n",
    "    best_train_f1 = -np.inf\n",
    "    best_epoch = -1\n",
    "    checkpoint_name = None\n",
    "    overrun_counter = 0\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    softmax = nn.Softmax()\n",
    "    \n",
    "    lr_log = []\n",
    "    for e in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        #tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "        for batch_i, inputs in enumerate(train_loader):\n",
    "            if DEBUG:\n",
    "                print(\"inside train loop.. batch_ind = \" +str(batch_i))\n",
    "            if batch_i % 200 == 0:\n",
    "                bat_time = time.time()\n",
    "                durn = (bat_time - start_time)/60\n",
    "                print(\"epoch = \" +str(e) + \"batch = \" +str(batch_i) + \" of \" + str(len(train_loader)) + \"duraation = \" + str(durn))\n",
    "            x = inputs[0].to(device).float()\n",
    "            y = inputs[1].type(torch.LongTensor).to(device)\n",
    "            #global_step += 1\n",
    "            # AMP\n",
    "            x_sum = torch.sum(x,axis = 1)\n",
    "            x_sum.unsqueeze(dim = 1)\n",
    "            zero_chk = torch.where((x_sum == 0))[0]\n",
    "            if len(zero_chk) > 0:\n",
    "                print(\"ZERO ENCOUNTER\")\n",
    "                print(\"x = \" +str(x))\n",
    "                break\n",
    "                       \n",
    "            with autocast():\n",
    "                y_pred = model(x)['prediction']\n",
    "                y_pred_smax = softmax(y_pred)\n",
    "                preds = torch.argmax(y_pred_smax, axis = 1)\n",
    "                loss = criterion(y_pred, y)\n",
    "            \n",
    "            if DEBUG:\n",
    "                    print(\"y_pred  = \" +str(y_pred))\n",
    "                    print(\"preds = \" +str(preds))\n",
    "                \n",
    "                \n",
    "            #loss_scaler(loss, optimiser,parameters=model_parameters(model))\n",
    "            if loss.item() > 10000:\n",
    "                print(\"^^^^^^^^^^^^^^^^^ EXPLOSION^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "                print(\"x sum = \" + str(torch.sum(x)))\n",
    "                print(\"current loss = \" + str(loss.item()))\n",
    "            train_loss += loss.item()\n",
    "            all_y.append(y.cpu().detach())\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            #preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "            if DEBUG:\n",
    "                print(\"batch_ind = \" +str(batch_i))\n",
    "                print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "                \n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),error_if_nonfinite=False ,max_norm = 5.0 )\n",
    "            optimiser.step()\n",
    "            del x\n",
    "            del y\n",
    "            del y_pred,preds\n",
    "        \n",
    "        optimiser.sync_lookahead()\n",
    "        all_train_loss.append(train_loss/len(train_loader))\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        if DEBUG:\n",
    "            print(\"y = \" + str(all_y))\n",
    "            print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "        train_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "        if DEBUG:\n",
    "            print(\"train acc = \" +str(train_acc))\n",
    "        all_train_f1.append(train_f1)\n",
    "        val_loss, val_f1 , _,_ = test_model(model, val_loader, criterion = nn.CrossEntropyLoss(), classes = classes ,device=device, call = \"val\")\n",
    "        if DEBUG:\n",
    "            print(\"val F1 = \" + str(val_f1))\n",
    "        all_val_loss.append(val_loss)\n",
    "        all_val_f1.append(val_f1)\n",
    "        \n",
    "        acc_metric = val_f1\n",
    "        best_acc_metric = best_val_f1\n",
    "        if acc_metric > best_acc_metric:  \n",
    "            overrun_counter = -1\n",
    "            checkpoint_name = f'model_e{e}_{datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")}.pth'\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_dir,  checkpoint_name))\n",
    "            sys.stdout.flush()\n",
    "            print('Epoch: %d, Train Loss: %.8f, Train f1: %.8f, Val Loss: %.8f, Val f1: %.8f, overrun_counter %i' % (e, train_loss/len(train_loader), train_f1, val_loss/len(val_loader), val_f1,  overrun_counter))\n",
    "            print('Saving model to:', os.path.join(config.model_dir,  checkpoint_name)) \n",
    "            print(\"Now printing classification rport... \")\n",
    "            print(\"********************************\")\n",
    "            from sklearn.metrics import classification_report\n",
    "            _, _ , all_y_test,all_y_pred_test = test_model(model, test_loader, criterion = nn.CrossEntropyLoss(), classes = classes ,device=device, call = \"test\")\n",
    "            # at times output is not getting printed. Could be due to multi threading and hence adding sleep\n",
    "            time.sleep(2)\n",
    "            sys.stdout.flush()\n",
    "            print(classification_report(all_y_test.numpy(), all_y_pred_test.numpy(), target_names= classes))\n",
    "            print(\"********************************\")\n",
    "            time.sleep(2)\n",
    "            plot_confusion_matrix(all_y_pred_test.numpy(), all_y_test.numpy() , classes)\n",
    "            best_epoch = e\n",
    "            best_val_f1 = val_f1\n",
    "            best_val_loss = val_loss\n",
    "            \n",
    "        else:\n",
    "            print(\"..Overrun....no improvement\")\n",
    "            overrun_counter += 1\n",
    "            sys.stdout.flush()\n",
    "            print('Epoch: %d, Train Loss: %.8f, Train f1: %.8f, Val Loss: %.8f, Val f1: %.8f, overrun_counter %i' % (e, train_loss/len(train_loader), train_f1, val_loss/len(val_loader), val_f1,  overrun_counter))\n",
    "        if overrun_counter > config_pytorch.max_overrun:\n",
    "            break\n",
    "            \n",
    "    \n",
    "    return model, lr_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42e7eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_audiomentations import Compose, Gain, PolarityInversion,AddColoredNoise,ApplyImpulseResponse,PeakNormalization\n",
    "# #apply_augmentation = Compose(transforms=[PolarityInversion(p=0.5 ,output_type = 'tensor'),AddColoredNoise(), PeakNormalization(apply_to=\"only_too_loud_sounds\"),TimeInversion(output_type = 'tensor')  ])\n",
    "\n",
    "\n",
    "# apply_augmentation = Compose(transforms=[AddColoredNoise(p = 1) ,TimeInversion( p = 1) ,PolarityInversion(p = 1)])\n",
    "\n",
    "# #apply_augmentation = Compose(transforms=[PolarityInversion(p=0.5 ,output_type = 'tensor'),AddColoredNoise(), PeakNormalization(apply_to=\"only_too_loud_sounds\"),TimeInversion(output_type = 'tensor')  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3716b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MozTrainDataset(Dataset):\n",
    "\n",
    "    def __init__(self, audio_df, data_dir, min_length, cache=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            audio_df (DataFrame): from get_offsets_df function \n",
    "            noise_df (DataFrame): the df of noise files and lengths\n",
    "            data_dir (string): Directory with all the wavs.\n",
    "            cache (dict): Empty dictionary used as cache\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.audio_df = audio_df\n",
    "        #self.noise_df = noise_df\n",
    "        self.data_dir = data_dir\n",
    "        self.min_length = min_length\n",
    "        self.transform = transform\n",
    "        self.cache = cache\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_df)\n",
    "    \n",
    "    def _get_sample_(self, path, resample=None):\n",
    "        \n",
    "        waveform, inp_rate = torchaudio.load(path)\n",
    "        \n",
    "        if inp_rate != config.rate:\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "            waveform = resampler(waveform)\n",
    "    \n",
    "        \n",
    "        #waveform, rate = torchaudio.load(path)\n",
    "                \n",
    "        if waveform.shape[1] < config.rate*self.min_length:\n",
    "            #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "            f_out = pad_mean(waveform)\n",
    "        else:\n",
    "            f = waveform[0]\n",
    "            f_out = f.unsqueeze(0)\n",
    "            \n",
    "        return f_out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #real_idx = idx % len(self.audio_df)\n",
    "                   \n",
    "        x = self._get_sample_(os.path.join(self.data_dir,f\"{int(self.audio_df.loc[idx]['id'])}.wav\"), resample=config.rate)\n",
    "       # random noise on even number indexes\n",
    "        offset = int(self.audio_df.loc[idx]['offset'])\n",
    "        if DEBUG:\n",
    "            print(\"Debuggin\")\n",
    "            #print(\"offset = \" + str(offset))\n",
    "            #print(\"shape of x post augmentation = \" + str(x.shape))\n",
    "            #print(\"from get_item of train, returning  x of shape = \" +str(x[:,offset:int(offset+config.rate*self.min_length)].shape))\n",
    "        \n",
    "        x_val = x[:,offset:int(offset+config.rate*self.min_length)]\n",
    "        if torch.sum(x_val) == 0:\n",
    "            print(\"ZERO TENSOR IN DATASET\")\n",
    "            x_val = x_val + torch.tensor(1e-6)\n",
    "            \n",
    "        return (x_val,self.audio_df.loc[idx]['specie_ind'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b0c5bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MozErrAnalysisDataset(Dataset):\n",
    "\n",
    "    def __init__(self, audio_df, data_dir, min_length, cache=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            audio_df (DataFrame): from get_offsets_df function \n",
    "            noise_df (DataFrame): the df of noise files and lengths\n",
    "            data_dir (string): Directory with all the wavs.\n",
    "            cache (dict): Empty dictionary used as cache\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.audio_df = audio_df\n",
    "        #self.noise_df = noise_df\n",
    "        self.data_dir = data_dir\n",
    "        self.min_length = min_length\n",
    "        self.transform = transform\n",
    "        self.cache = cache\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_df)\n",
    "    \n",
    "    def _get_sample_(self, path, resample=None):\n",
    "        \n",
    "        waveform, inp_rate = torchaudio.load(path)\n",
    "        \n",
    "        if inp_rate != config.rate:\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "            waveform = resampler(waveform)\n",
    "    \n",
    "        \n",
    "        #waveform, rate = torchaudio.load(path)\n",
    "                \n",
    "        if waveform.shape[1] < config.rate*self.min_length:\n",
    "            #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "            f_out = pad_mean(waveform)\n",
    "        else:\n",
    "            f = waveform[0]\n",
    "            #mu = torch.std_mean(f)[1]\n",
    "            #st = torch.std_mean(f)[0]\n",
    "            # clip amplitudes\n",
    "            f_out = f.unsqueeze(0)\n",
    "            if self.cache is not None:\n",
    "                self.cache[path] = f_out\n",
    "        return f_out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #real_idx = idx % len(self.audio_df)\n",
    "        if DEBUG:\n",
    "            print(\"idx = \" + str(idx))\n",
    "        x = self._get_sample_(os.path.join(self.data_dir,f\"{int(self.audio_df.loc[idx]['id'])}.wav\"), resample=config.rate)\n",
    "        \n",
    "        # random noise on even number indexes\n",
    "        offset = int(self.audio_df.loc[idx]['offset'])\n",
    "        \n",
    "        return (x[:,offset:int(offset+config.rate*self.min_length)],self.audio_df.loc[idx]['specie_ind'],offset, self.audio_df.loc[idx]['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b499471",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MozTestDataset(Dataset):\n",
    "\n",
    "    def __init__(self, audio_df, data_dir, min_length, cache=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            audio_df (DataFrame): from get_offsets_df function \n",
    "            noise_df (DataFrame): the df of noise files and lengths\n",
    "            data_dir (string): Directory with all the wavs.\n",
    "            cache (dict): Empty dictionary used as cache\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.audio_df = audio_df\n",
    "        #self.noise_df = noise_df\n",
    "        self.data_dir = data_dir\n",
    "        self.min_length = min_length\n",
    "        self.transform = transform\n",
    "        self.cache = cache\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_df)\n",
    "    \n",
    "    def _get_sample_(self, path, resample=None):\n",
    "        \n",
    "        waveform, inp_rate = torchaudio.load(path)\n",
    "        \n",
    "        if inp_rate != config.rate:\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "            waveform = resampler(waveform)\n",
    "    \n",
    "        \n",
    "        #waveform, rate = torchaudio.load(path)\n",
    "                \n",
    "        if waveform.shape[1] < config.rate*self.min_length:\n",
    "            #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "            f_out = pad_mean(waveform)\n",
    "        else:\n",
    "            f = waveform[0]\n",
    "            #mu = torch.std_mean(f)[1]\n",
    "            #st = torch.std_mean(f)[0]\n",
    "            # clip amplitudes\n",
    "            f_out = f.unsqueeze(0)\n",
    "            if self.cache is not None:\n",
    "                self.cache[path] = f_out\n",
    "        return f_out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #real_idx = idx % len(self.audio_df)\n",
    "        x = self._get_sample_(os.path.join(self.data_dir,f\"{int(self.audio_df.loc[idx]['id'])}.wav\"), resample=config.rate)\n",
    "        \n",
    "        # random noise on even number indexes\n",
    "        offset = int(self.audio_df.loc[idx]['offset'])\n",
    "        if DEBUG:\n",
    "\n",
    "              print(\"DEBUGGING\")\n",
    "#             print(\"shape of x post augmentation = \" + str(x.shape))\n",
    "#             print(\"offset = \" + str(offset))\n",
    "#             print(\"from get_item of train, returning  x of shape = \" +str(x[:,offset:int(offset+config.rate*self.min_length)].shape))\n",
    "            \n",
    "        x_val = x[:,offset:int(offset+config.rate*self.min_length)]\n",
    "        if torch.sum(x_val) == 0:\n",
    "            print(\"ZERO TENSOR IN DATASET\")\n",
    "            x_val = x_val + torch.tensor(1e-6)\n",
    "        \n",
    "        return (x_val,self.audio_df.loc[idx]['specie_ind'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dbb8af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_aug(x,rate):\n",
    "        apply_augmentation = Compose(transforms=[AddColoredNoise(p = .85) ,TimeInversion( p = .75) ,PolarityInversion(p = .25)])\n",
    "        aug_audio = apply_augmentation(x,sample_rate = rate)\n",
    "        return(aug_audio)\n",
    "    \n",
    "\n",
    "class augment_audio(nn.Module):\n",
    "    \"\"\"This is a class to introduce randomness in the data.\n",
    "    We implement it as a layer in the NN to ensure that it learns from the propertis of the data\"\"\"\n",
    "    def __init__(self , trainable = True, sample_rate = config.rate):\n",
    "        super().__init__()\n",
    "        self.trainable = trainable\n",
    "        self.rate = sample_rate\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(dim = 1)\n",
    "           \n",
    "        if self.trainable:\n",
    "            x = apply_aug(x , self.rate)\n",
    "        else:\n",
    "            x = x\n",
    "#         x = x.unsqueeze(dim=1).permute((0,1,3,2))\n",
    "        return x.squeeze(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "34972352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass the pretrained model and make it a binary classification\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name, image_size):\n",
    "        super().__init__()\n",
    "        # num_classes=0 removes the pretrained head\n",
    "        self.backbone = timm.create_model(model_name,\n",
    "                        pretrained=True, num_classes=8, in_chans=1, \n",
    "                        drop_path_rate=0.2, global_pool='max',\n",
    "                        drop_rate=0.25)\n",
    "        #####  This section is model specific\n",
    "        #### It freezes some fo the layers by name\n",
    "        #### you'll have to inspect the model to see the names\n",
    "                #### end layer freezing\n",
    "        self.spec_layer = features.STFT(n_fft=int(config.NFFT), freq_bins=None, hop_length=int(config.n_hop),\n",
    "                              window='hann', freq_scale='linear', center=True, pad_mode='reflect',\n",
    "                           sr=config.rate, output_format=\"Magnitude\", trainable=True,)\n",
    "        self.out = nn.Linear(self.backbone.num_features, 1)\n",
    "        self.sizer = VT.Resize((image_size,image_size))\n",
    "        self.timeMasking = T.TimeMasking(time_mask_param=int(config.win_size*0.4), iid_masks=True)\n",
    "        self.freqMasking = T.FrequencyMasking(freq_mask_param=int((config.NFFT//4)*0.15), iid_masks=True)\n",
    "        self.norm_layer = Normalization(mode='framewise')\n",
    "        self.pcen_layer = PCENTransform(eps=1e-6, s=0.025, alpha=0.6, delta=0.1, r=0.2, trainable=True)\n",
    "        #self.augment_layer = augment_audio(trainable = True, sample_rate = config.rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # first compute spectrogram\n",
    "        #if DEBUG:\n",
    "            #print(\"input shape that goes for augmentation = \" + str(x.squeeze().shape))\n",
    "        #spec = self.augment_layer(x.squeeze())\n",
    "        #if DEBUG:\n",
    "            #print(\"Out put of augment and input shape that goes for STFT = \" + str(x.shape))\n",
    "        spec = self.spec_layer(x)  # (B, F, T)\n",
    "        # normalize\n",
    "#         spec = spec.transpose(1,2) # (B, T, F)\n",
    "        #if DEBUG:\n",
    "            #print(\"Out put of STFT and input shape that goes for PCEN = \" + str(spec.shape))\n",
    "        spec = self.pcen_layer(spec)\n",
    "        #if DEBUG:\n",
    "            #print(\"Out put of PCEN and input shape that goes for NORM = \" + str(spec.shape))\n",
    "        spec = self.norm_layer(spec)\n",
    "        \n",
    "        #if DEBUG:\n",
    "            #print(\"Out put of NORM and input shape that goes for time mask = \" + str(spec.shape))\n",
    "        spec = self.timeMasking(spec)\n",
    "        #if DEBUG:\n",
    "            #print(\"Out put of timemask and input shape that goes for freq mask = \" + str(spec.shape))\n",
    "        spec = self.freqMasking(spec)\n",
    "\n",
    "        # then size for CNN model\n",
    "        # and create a channel\n",
    "        spec = self.sizer(spec)\n",
    "        x = spec.unsqueeze(1)\n",
    "        # then repeat channels\n",
    "        #if DEBUG:\n",
    "            #print(\"Final shape that goes to backbone = \" + str(x.shape))\n",
    "        if torch.sum(x) == 0:\n",
    "            print(\"ZERO INPUT in forward\")\n",
    "            x  = x+torch.tensor(1e-6)\n",
    "            \n",
    "            \n",
    "        x = self.backbone(x)\n",
    "        #print(\"x shape = \" + str(x.shape))\n",
    "        #print(\"x = \" +str(x))\n",
    "        #pred = nn.Softmax(x)\n",
    "        pred = x\n",
    "        #print(np.argmax(pred.detach().cpu().numpy()))\n",
    "        #print(pred)\n",
    "        output = {\"prediction\": pred,\n",
    "                  \"spectrogram\": spec}\n",
    "        #print(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b0f4cd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/audio\n"
     ]
    }
   ],
   "source": [
    "print(config.data_dir)\n",
    "train_dataset = MozTrainDataset(df_train_offset,  config.data_dir, min_length , transform = None)\n",
    "val_dataset = MozTestDataset(df_val_offset,  config.data_dir, min_length)\n",
    "test_dataset = MozTestDataset(df_test_offset,  config.data_dir, min_length)\n",
    "error_dataset = MozErrAnalysisDataset(df_val_offset,  config.data_dir, min_length = config.min_duration)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, num_workers=num_workers,batch_size = batch_size,shuffle = True\n",
    "    , pin_memory=True )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=batch_size,\n",
    "        num_workers= num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "error_loader = torch.utils.data.DataLoader(\n",
    "        error_dataset, batch_size=batch_size,\n",
    "        num_workers= num_workers, pin_memory=pin_memory,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae2910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab6ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of train dataset = \" +str(len(train_dataset)))\n",
    "print(\"Length of train loader = \" +str(len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5c8e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_itr = iter(train_loader)\n",
    "# a,b = train_itr.next()\n",
    "# print(a.shape)\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec_layer = features.STFT(n_fft=int(config.NFFT), freq_bins=None, hop_length=int(config.n_hop),\n",
    "#                               window='hann', freq_scale='linear', center=True, pad_mode='reflect',\n",
    "#                            sr=config.rate, output_format=\"Magnitude\", trainable=True,)\n",
    "# x = spec_layer(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac241b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_mod = Model('convnext_small',224)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1dd29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mod(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840bd65f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath, model=Model('convnext_small',224)):\n",
    "    # Instantiate model to inspect\n",
    "    print(\"Filepath = \" + str(filepath))\n",
    "    print(\"model = \" +str(model))\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    print(f'Training on {device}')\n",
    "        \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using data parallel\")\n",
    "        model = nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "    model = model.to(device)\n",
    "    # Load trained parameters from checkpoint (may need to download from S3 first)\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        map_location=lambda storage, loc: storage.cuda()\n",
    "    else:\n",
    "        map_location='cpu'\n",
    "        \n",
    "    checkpoint = model.load_state_dict(torch.load(filepath))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "be0742dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling rate = 8000. Please make sure the sampling rate is correct in order toget a valid freq range\n",
      "STFT kernels created, time used = 0.0846 seconds\n",
      "Training on cuda:0\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 0\n",
      "epoch = 0batch = 0 of 8060duraation = 0.003220641613006592\n",
      "y_pred  = tensor([[ 0.0842,  0.0826, -0.0482,  0.3608,  0.2507,  0.1564,  0.2150,  0.2267],\n",
      "        [ 0.1503,  0.0582, -0.0198,  0.2827,  0.0872, -0.0458,  0.1844,  0.0402],\n",
      "        [ 0.1600, -0.2053, -0.1691,  0.3047,  0.2008, -0.2330,  0.0130,  0.1205],\n",
      "        [ 0.2339, -0.0277,  0.2598,  0.3391,  0.0673, -0.1166,  0.2384,  0.0864]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([3, 3, 3, 3], device='cuda:0')\n",
      "batch_ind = 0\n",
      "y_pred_cpu = tensor([[ 0.0842,  0.0826, -0.0482,  0.3608,  0.2507,  0.1564,  0.2150,  0.2267],\n",
      "        [ 0.1503,  0.0582, -0.0198,  0.2827,  0.0872, -0.0458,  0.1844,  0.0402],\n",
      "        [ 0.1600, -0.2053, -0.1691,  0.3047,  0.2008, -0.2330,  0.0130,  0.1205],\n",
      "        [ 0.2339, -0.0277,  0.2598,  0.3391,  0.0673, -0.1166,  0.2384,  0.0864]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 1\n",
      "y_pred  = tensor([[ 0.3276,  0.0592,  0.3181,  0.1342,  0.2317, -0.1318, -0.2021,  0.0838],\n",
      "        [ 0.1490,  0.0589,  0.1733, -0.0944,  0.1874, -0.0197,  0.0551, -0.0624],\n",
      "        [ 0.1132,  0.3027, -0.0242, -0.0739,  0.0663, -0.1458, -0.0673, -0.0005],\n",
      "        [ 0.1337,  0.2306,  0.2651,  0.0537,  0.1953, -0.0864, -0.0251,  0.1305]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 4, 1, 2], device='cuda:0')\n",
      "batch_ind = 1\n",
      "y_pred_cpu = tensor([[ 0.3276,  0.0592,  0.3181,  0.1342,  0.2317, -0.1318, -0.2021,  0.0838],\n",
      "        [ 0.1490,  0.0589,  0.1733, -0.0944,  0.1874, -0.0197,  0.0551, -0.0624],\n",
      "        [ 0.1132,  0.3027, -0.0242, -0.0739,  0.0663, -0.1458, -0.0673, -0.0005],\n",
      "        [ 0.1337,  0.2306,  0.2651,  0.0537,  0.1953, -0.0864, -0.0251,  0.1305]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 2\n",
      "y_pred  = tensor([[ 0.2715,  0.2622,  0.1205,  0.1047,  0.0970, -0.1311,  0.0188,  0.2778],\n",
      "        [ 0.1196,  0.1912,  0.0144, -0.0357, -0.1118,  0.0527,  0.0809,  0.0185],\n",
      "        [ 0.1123,  0.1412,  0.1212,  0.0792, -0.0018, -0.1143,  0.1666, -0.0733],\n",
      "        [ 0.2196,  0.2493,  0.0261, -0.0569,  0.0860, -0.0046,  0.0125, -0.0239]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([7, 1, 6, 1], device='cuda:0')\n",
      "batch_ind = 2\n",
      "y_pred_cpu = tensor([[ 0.2715,  0.2622,  0.1205,  0.1047,  0.0970, -0.1311,  0.0188,  0.2778],\n",
      "        [ 0.1196,  0.1912,  0.0144, -0.0357, -0.1118,  0.0527,  0.0809,  0.0185],\n",
      "        [ 0.1123,  0.1412,  0.1212,  0.0792, -0.0018, -0.1143,  0.1666, -0.0733],\n",
      "        [ 0.2196,  0.2493,  0.0261, -0.0569,  0.0860, -0.0046,  0.0125, -0.0239]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 3\n",
      "y_pred  = tensor([[ 0.3462, -0.1361, -0.1115,  0.2664,  0.2683, -0.1364, -0.1368, -0.0266],\n",
      "        [ 0.0161,  0.2703,  0.0956,  0.1992, -0.0533, -0.2932, -0.0692, -0.0800],\n",
      "        [ 0.3308, -0.0072, -0.0567,  0.1263,  0.4265, -0.3179, -0.0546, -0.1544],\n",
      "        [ 0.1241, -0.0706, -0.1089,  0.2053,  0.2510, -0.1533, -0.2089, -0.0371]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 1, 4, 4], device='cuda:0')\n",
      "batch_ind = 3\n",
      "y_pred_cpu = tensor([[ 0.3462, -0.1361, -0.1115,  0.2664,  0.2683, -0.1364, -0.1368, -0.0266],\n",
      "        [ 0.0161,  0.2703,  0.0956,  0.1992, -0.0533, -0.2932, -0.0692, -0.0800],\n",
      "        [ 0.3308, -0.0072, -0.0567,  0.1263,  0.4265, -0.3179, -0.0546, -0.1544],\n",
      "        [ 0.1241, -0.0706, -0.1089,  0.2053,  0.2510, -0.1533, -0.2089, -0.0371]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 4\n",
      "y_pred  = tensor([[ 0.1416,  0.0064, -0.1090,  0.0887,  0.3176,  0.0745, -0.3037, -0.0575],\n",
      "        [ 0.2520,  0.0609, -0.1377,  0.4028,  0.4236,  0.1455, -0.0489, -0.2072],\n",
      "        [ 0.3269,  0.1510, -0.2396,  0.5659,  0.3647,  0.0355, -0.1030, -0.3630],\n",
      "        [ 0.3486,  0.2595,  0.0714,  0.1344,  0.2756,  0.0044,  0.0810, -0.1665]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 4, 3, 0], device='cuda:0')\n",
      "batch_ind = 4\n",
      "y_pred_cpu = tensor([[ 0.1416,  0.0064, -0.1090,  0.0887,  0.3176,  0.0745, -0.3037, -0.0575],\n",
      "        [ 0.2520,  0.0609, -0.1377,  0.4028,  0.4236,  0.1455, -0.0489, -0.2072],\n",
      "        [ 0.3269,  0.1510, -0.2396,  0.5659,  0.3647,  0.0355, -0.1030, -0.3630],\n",
      "        [ 0.3486,  0.2595,  0.0714,  0.1344,  0.2756,  0.0044,  0.0810, -0.1665]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 5\n",
      "y_pred  = tensor([[ 0.0496,  0.0448, -0.1914,  0.2324,  0.2935, -0.0655,  0.0473, -0.0921],\n",
      "        [ 0.3721,  0.1207, -0.0298,  0.4788,  0.2952, -0.0119, -0.3010, -0.1693],\n",
      "        [ 0.1840,  0.0340, -0.0980,  0.5830,  0.2666, -0.0701, -0.3086, -0.0363],\n",
      "        [ 0.0374, -0.0652, -0.0925,  0.2800,  0.1393, -0.1287, -0.1082, -0.2505]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 3, 3, 3], device='cuda:0')\n",
      "batch_ind = 5\n",
      "y_pred_cpu = tensor([[ 0.0496,  0.0448, -0.1914,  0.2324,  0.2935, -0.0655,  0.0473, -0.0921],\n",
      "        [ 0.3721,  0.1207, -0.0298,  0.4788,  0.2952, -0.0119, -0.3010, -0.1693],\n",
      "        [ 0.1840,  0.0340, -0.0980,  0.5830,  0.2666, -0.0701, -0.3086, -0.0363],\n",
      "        [ 0.0374, -0.0652, -0.0925,  0.2800,  0.1393, -0.1287, -0.1082, -0.2505]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 6\n",
      "y_pred  = tensor([[ 0.0433, -0.0191,  0.0192,  0.4492,  0.3008, -0.2832, -0.1061, -0.0258],\n",
      "        [ 0.2959,  0.1383, -0.0594,  0.3162,  0.2856, -0.2480, -0.1101, -0.3125],\n",
      "        [ 0.2357,  0.2405, -0.0256,  0.2625,  0.2837, -0.3179, -0.2654, -0.1479],\n",
      "        [ 0.0923, -0.0846,  0.1119,  0.5186,  0.5347, -0.2462,  0.3384, -0.2764]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([3, 3, 4, 4], device='cuda:0')\n",
      "batch_ind = 6\n",
      "y_pred_cpu = tensor([[ 0.0433, -0.0191,  0.0192,  0.4492,  0.3008, -0.2832, -0.1061, -0.0258],\n",
      "        [ 0.2959,  0.1383, -0.0594,  0.3162,  0.2856, -0.2480, -0.1101, -0.3125],\n",
      "        [ 0.2357,  0.2405, -0.0256,  0.2625,  0.2837, -0.3179, -0.2654, -0.1479],\n",
      "        [ 0.0923, -0.0846,  0.1119,  0.5186,  0.5347, -0.2462,  0.3384, -0.2764]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 7\n",
      "y_pred  = tensor([[ 0.4487,  0.1228, -0.1079,  0.3264,  0.1581, -0.0659, -0.2310, -0.2324],\n",
      "        [ 0.1804,  0.0764,  0.0687,  0.6553,  0.3975, -0.2059, -0.1218, -0.3528],\n",
      "        [ 0.4829,  0.0843, -0.0652,  0.3555,  0.4070, -0.0500, -0.1378, -0.1212],\n",
      "        [ 0.3772,  0.1132, -0.1215,  0.4277,  0.0948, -0.2683, -0.1173, -0.4670]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 3, 0, 3], device='cuda:0')\n",
      "batch_ind = 7\n",
      "y_pred_cpu = tensor([[ 0.4487,  0.1228, -0.1079,  0.3264,  0.1581, -0.0659, -0.2310, -0.2324],\n",
      "        [ 0.1804,  0.0764,  0.0687,  0.6553,  0.3975, -0.2059, -0.1218, -0.3528],\n",
      "        [ 0.4829,  0.0843, -0.0652,  0.3555,  0.4070, -0.0500, -0.1378, -0.1212],\n",
      "        [ 0.3772,  0.1132, -0.1215,  0.4277,  0.0948, -0.2683, -0.1173, -0.4670]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 8\n",
      "y_pred  = tensor([[ 0.3794,  0.1798, -0.1064,  0.3831,  0.3352, -0.1648, -0.1285, -0.2847],\n",
      "        [ 0.3882, -0.4116, -0.1387,  0.4980,  0.2930, -0.2292, -0.0569, -0.3005],\n",
      "        [ 0.6113,  0.1176, -0.0482,  0.4382,  0.3223, -0.0354, -0.2300, -0.1812],\n",
      "        [ 0.6299,  0.0598,  0.1438,  0.3169,  0.4177, -0.4707, -0.2903, -0.2988]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([3, 3, 0, 0], device='cuda:0')\n",
      "batch_ind = 8\n",
      "y_pred_cpu = tensor([[ 0.3794,  0.1798, -0.1064,  0.3831,  0.3352, -0.1648, -0.1285, -0.2847],\n",
      "        [ 0.3882, -0.4116, -0.1387,  0.4980,  0.2930, -0.2292, -0.0569, -0.3005],\n",
      "        [ 0.6113,  0.1176, -0.0482,  0.4382,  0.3223, -0.0354, -0.2300, -0.1812],\n",
      "        [ 0.6299,  0.0598,  0.1438,  0.3169,  0.4177, -0.4707, -0.2903, -0.2988]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 9\n",
      "y_pred  = tensor([[ 0.2925,  0.1581, -0.2136,  0.1517,  0.4590, -0.1109, -0.0707, -0.1428],\n",
      "        [ 0.1339, -0.2852,  0.2571,  0.4272,  0.4377, -0.0867, -0.2413, -0.4741],\n",
      "        [ 0.3760, -0.1028, -0.0533,  0.0014,  0.4700,  0.0421, -0.0925, -0.3757],\n",
      "        [ 0.3379,  0.0345, -0.0858,  0.2418,  0.5718, -0.0586, -0.1193, -0.3521]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 4, 4, 4], device='cuda:0')\n",
      "batch_ind = 9\n",
      "y_pred_cpu = tensor([[ 0.2925,  0.1581, -0.2136,  0.1517,  0.4590, -0.1109, -0.0707, -0.1428],\n",
      "        [ 0.1339, -0.2852,  0.2571,  0.4272,  0.4377, -0.0867, -0.2413, -0.4741],\n",
      "        [ 0.3760, -0.1028, -0.0533,  0.0014,  0.4700,  0.0421, -0.0925, -0.3757],\n",
      "        [ 0.3379,  0.0345, -0.0858,  0.2418,  0.5718, -0.0586, -0.1193, -0.3521]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 10\n",
      "y_pred  = tensor([[ 0.2563, -0.0034,  0.0670,  0.2229,  0.5889, -0.1774, -0.1140, -0.3372],\n",
      "        [ 0.2708,  0.0253,  0.0528,  0.0503,  0.5479,  0.0341, -0.0825, -0.2283],\n",
      "        [ 0.1174, -0.0072, -0.1060,  0.1542,  0.4351,  0.0260, -0.0609, -0.3198],\n",
      "        [ 0.3938,  0.1006,  0.0034,  0.0401,  0.3364,  0.0288, -0.1171, -0.2563]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 4, 4, 0], device='cuda:0')\n",
      "batch_ind = 10\n",
      "y_pred_cpu = tensor([[ 0.2563, -0.0034,  0.0670,  0.2229,  0.5889, -0.1774, -0.1140, -0.3372],\n",
      "        [ 0.2708,  0.0253,  0.0528,  0.0503,  0.5479,  0.0341, -0.0825, -0.2283],\n",
      "        [ 0.1174, -0.0072, -0.1060,  0.1542,  0.4351,  0.0260, -0.0609, -0.3198],\n",
      "        [ 0.3938,  0.1006,  0.0034,  0.0401,  0.3364,  0.0288, -0.1171, -0.2563]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 11\n",
      "y_pred  = tensor([[ 0.5049,  0.0350, -0.3442,  0.1420,  0.3586,  0.2429, -0.1279, -0.3328],\n",
      "        [ 0.4148, -0.2524,  0.0813,  0.2440,  0.2759, -0.2054, -0.2161, -0.3804],\n",
      "        [ 0.3564, -0.0198, -0.2159,  0.0890,  0.3215,  0.1575, -0.0567, -0.3450],\n",
      "        [ 0.2942, -0.0562, -0.2852,  0.2446,  0.1890,  0.2474, -0.0441, -0.3301]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 11\n",
      "y_pred_cpu = tensor([[ 0.5049,  0.0350, -0.3442,  0.1420,  0.3586,  0.2429, -0.1279, -0.3328],\n",
      "        [ 0.4148, -0.2524,  0.0813,  0.2440,  0.2759, -0.2054, -0.2161, -0.3804],\n",
      "        [ 0.3564, -0.0198, -0.2159,  0.0890,  0.3215,  0.1575, -0.0567, -0.3450],\n",
      "        [ 0.2942, -0.0562, -0.2852,  0.2446,  0.1890,  0.2474, -0.0441, -0.3301]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 12\n",
      "y_pred  = tensor([[ 3.8501e-01,  1.6638e-01, -1.2122e-01, -6.1768e-02,  3.4937e-01,\n",
      "          1.5564e-01, -8.4656e-02, -4.0332e-01],\n",
      "        [ 2.2302e-01,  2.3853e-01, -1.5894e-01,  2.8467e-01,  3.9453e-01,\n",
      "          2.9907e-01, -7.6477e-02, -4.0405e-01],\n",
      "        [ 3.7646e-01, -9.8755e-02, -5.9662e-02,  2.4084e-01,  3.7305e-01,\n",
      "          6.3599e-02, -3.5583e-02, -3.0713e-01],\n",
      "        [ 1.2830e-01, -4.7241e-02, -1.3245e-01,  2.7490e-01,  4.8315e-01,\n",
      "          1.7393e-04, -5.1544e-02, -3.3984e-01]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 4, 0, 4], device='cuda:0')\n",
      "batch_ind = 12\n",
      "y_pred_cpu = tensor([[ 3.8501e-01,  1.6638e-01, -1.2122e-01, -6.1768e-02,  3.4937e-01,\n",
      "          1.5564e-01, -8.4656e-02, -4.0332e-01],\n",
      "        [ 2.2302e-01,  2.3853e-01, -1.5894e-01,  2.8467e-01,  3.9453e-01,\n",
      "          2.9907e-01, -7.6477e-02, -4.0405e-01],\n",
      "        [ 3.7646e-01, -9.8755e-02, -5.9662e-02,  2.4084e-01,  3.7305e-01,\n",
      "          6.3599e-02, -3.5583e-02, -3.0713e-01],\n",
      "        [ 1.2830e-01, -4.7241e-02, -1.3245e-01,  2.7490e-01,  4.8315e-01,\n",
      "          1.7393e-04, -5.1544e-02, -3.3984e-01]], dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 13\n",
      "y_pred  = tensor([[ 0.3635, -0.0750, -0.0902,  0.3276,  0.6152, -0.2463, -0.0738, -0.2583],\n",
      "        [ 0.2448, -0.0649, -0.0453,  0.1882,  0.5093, -0.1812, -0.0682, -0.4436],\n",
      "        [ 0.4031, -0.0956, -0.0729,  0.1261,  0.4478,  0.1249, -0.1670, -0.4004],\n",
      "        [ 0.3435, -0.0107, -0.1794,  0.1818,  0.5874, -0.2190, -0.1385, -0.5957]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 4, 4, 4], device='cuda:0')\n",
      "batch_ind = 13\n",
      "y_pred_cpu = tensor([[ 0.3635, -0.0750, -0.0902,  0.3276,  0.6152, -0.2463, -0.0738, -0.2583],\n",
      "        [ 0.2448, -0.0649, -0.0453,  0.1882,  0.5093, -0.1812, -0.0682, -0.4436],\n",
      "        [ 0.4031, -0.0956, -0.0729,  0.1261,  0.4478,  0.1249, -0.1670, -0.4004],\n",
      "        [ 0.3435, -0.0107, -0.1794,  0.1818,  0.5874, -0.2190, -0.1385, -0.5957]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 14\n",
      "y_pred  = tensor([[ 0.4768, -0.2485, -0.1016, -0.0206,  0.5190, -0.3787, -0.0306, -0.5952],\n",
      "        [ 0.7729, -0.0263, -0.1844,  0.2993,  0.7109, -0.2454, -0.1901, -0.4729],\n",
      "        [ 0.5205,  0.0791, -0.3630, -0.0480,  0.5391, -0.2183, -0.1224, -0.3455],\n",
      "        [ 0.4578, -0.0887, -0.0793, -0.0205,  0.4709, -0.2607, -0.2478, -0.3059]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 0, 4, 4], device='cuda:0')\n",
      "batch_ind = 14\n",
      "y_pred_cpu = tensor([[ 0.4768, -0.2485, -0.1016, -0.0206,  0.5190, -0.3787, -0.0306, -0.5952],\n",
      "        [ 0.7729, -0.0263, -0.1844,  0.2993,  0.7109, -0.2454, -0.1901, -0.4729],\n",
      "        [ 0.5205,  0.0791, -0.3630, -0.0480,  0.5391, -0.2183, -0.1224, -0.3455],\n",
      "        [ 0.4578, -0.0887, -0.0793, -0.0205,  0.4709, -0.2607, -0.2478, -0.3059]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 15\n",
      "y_pred  = tensor([[ 0.4734,  0.1216, -0.2480,  0.0149,  0.6318, -0.1043,  0.0224, -0.4314],\n",
      "        [ 0.4163, -0.1162, -0.1500,  0.1576,  0.5825, -0.0425, -0.0038, -0.5430],\n",
      "        [ 0.3191,  0.0452, -0.1092,  0.0544,  0.3425, -0.1162, -0.0737, -0.2014],\n",
      "        [ 0.3269,  0.1957, -0.1246,  0.0184,  0.5645, -0.0792, -0.1494, -0.4399]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 4, 4, 4], device='cuda:0')\n",
      "batch_ind = 15\n",
      "y_pred_cpu = tensor([[ 0.4734,  0.1216, -0.2480,  0.0149,  0.6318, -0.1043,  0.0224, -0.4314],\n",
      "        [ 0.4163, -0.1162, -0.1500,  0.1576,  0.5825, -0.0425, -0.0038, -0.5430],\n",
      "        [ 0.3191,  0.0452, -0.1092,  0.0544,  0.3425, -0.1162, -0.0737, -0.2014],\n",
      "        [ 0.3269,  0.1957, -0.1246,  0.0184,  0.5645, -0.0792, -0.1494, -0.4399]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 16\n",
      "y_pred  = tensor([[ 0.4917,  0.1805, -0.2981, -0.1915,  0.3970,  0.0600, -0.2195, -0.3796],\n",
      "        [ 0.5449,  0.1190, -0.2986, -0.1151,  0.5439, -0.0163, -0.0307, -0.3984],\n",
      "        [ 0.4502, -0.0028, -0.3240,  0.0530,  0.5371, -0.0928, -0.0807, -0.4678],\n",
      "        [ 0.3516,  0.0885, -0.2252,  0.0097,  0.4663, -0.0424, -0.0785, -0.4426]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 4, 4], device='cuda:0')\n",
      "batch_ind = 16\n",
      "y_pred_cpu = tensor([[ 0.4917,  0.1805, -0.2981, -0.1915,  0.3970,  0.0600, -0.2195, -0.3796],\n",
      "        [ 0.5449,  0.1190, -0.2986, -0.1151,  0.5439, -0.0163, -0.0307, -0.3984],\n",
      "        [ 0.4502, -0.0028, -0.3240,  0.0530,  0.5371, -0.0928, -0.0807, -0.4678],\n",
      "        [ 0.3516,  0.0885, -0.2252,  0.0097,  0.4663, -0.0424, -0.0785, -0.4426]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 17\n",
      "y_pred  = tensor([[ 0.4106,  0.1317, -0.1655,  0.0440,  0.3843, -0.0358, -0.0612, -0.3262],\n",
      "        [ 0.3643,  0.1243, -0.2096, -0.0370,  0.3621, -0.0232, -0.1926, -0.2773],\n",
      "        [ 0.3320, -0.0043, -0.1555,  0.0621,  0.3181, -0.0547,  0.0314, -0.2974],\n",
      "        [ 0.3657,  0.0764, -0.0975,  0.1116,  0.3914, -0.1356, -0.1243, -0.3484]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 4], device='cuda:0')\n",
      "batch_ind = 17\n",
      "y_pred_cpu = tensor([[ 0.4106,  0.1317, -0.1655,  0.0440,  0.3843, -0.0358, -0.0612, -0.3262],\n",
      "        [ 0.3643,  0.1243, -0.2096, -0.0370,  0.3621, -0.0232, -0.1926, -0.2773],\n",
      "        [ 0.3320, -0.0043, -0.1555,  0.0621,  0.3181, -0.0547,  0.0314, -0.2974],\n",
      "        [ 0.3657,  0.0764, -0.0975,  0.1116,  0.3914, -0.1356, -0.1243, -0.3484]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 18\n",
      "y_pred  = tensor([[ 0.3223, -0.1335, -0.1829,  0.2115,  0.6055, -0.2328, -0.0979, -0.6484],\n",
      "        [ 0.3752,  0.0468, -0.0666,  0.2174,  0.3757, -0.1907,  0.0019, -0.7476],\n",
      "        [ 0.2437,  0.0373, -0.0283, -0.0100,  0.1626,  0.1499,  0.0490, -0.5317],\n",
      "        [ 0.5942,  0.1998, -0.2632,  0.0575,  0.6108, -0.1185, -0.2218, -0.4238]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 4, 0, 4], device='cuda:0')\n",
      "batch_ind = 18\n",
      "y_pred_cpu = tensor([[ 0.3223, -0.1335, -0.1829,  0.2115,  0.6055, -0.2328, -0.0979, -0.6484],\n",
      "        [ 0.3752,  0.0468, -0.0666,  0.2174,  0.3757, -0.1907,  0.0019, -0.7476],\n",
      "        [ 0.2437,  0.0373, -0.0283, -0.0100,  0.1626,  0.1499,  0.0490, -0.5317],\n",
      "        [ 0.5942,  0.1998, -0.2632,  0.0575,  0.6108, -0.1185, -0.2218, -0.4238]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 19\n",
      "y_pred  = tensor([[ 0.2893,  0.0577, -0.2137,  0.1736,  0.4502, -0.1431, -0.0322, -0.2729],\n",
      "        [ 0.3176,  0.1240, -0.1257,  0.0471,  0.3674, -0.0144, -0.0541, -0.2710],\n",
      "        [ 0.3003,  0.1327, -0.1998, -0.0541,  0.3804, -0.0894, -0.1747, -0.3318],\n",
      "        [ 0.1761, -0.0859, -0.0978,  0.0396,  0.3735, -0.0312,  0.0165, -0.2583]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 4, 4, 4], device='cuda:0')\n",
      "batch_ind = 19\n",
      "y_pred_cpu = tensor([[ 0.2893,  0.0577, -0.2137,  0.1736,  0.4502, -0.1431, -0.0322, -0.2729],\n",
      "        [ 0.3176,  0.1240, -0.1257,  0.0471,  0.3674, -0.0144, -0.0541, -0.2710],\n",
      "        [ 0.3003,  0.1327, -0.1998, -0.0541,  0.3804, -0.0894, -0.1747, -0.3318],\n",
      "        [ 0.1761, -0.0859, -0.0978,  0.0396,  0.3735, -0.0312,  0.0165, -0.2583]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 20\n",
      "y_pred  = tensor([[ 0.2196,  0.1694, -0.1901,  0.0506,  0.3462, -0.0809, -0.1890, -0.2262],\n",
      "        [ 0.2512, -0.1292, -0.0978,  0.0734,  0.4126, -0.0609,  0.0689, -0.3665],\n",
      "        [ 0.3362,  0.2374, -0.2844, -0.0337,  0.2277, -0.1335, -0.1855, -0.1599],\n",
      "        [ 0.2445,  0.3450, -0.2742,  0.0651,  0.4412,  0.0302, -0.1060, -0.2155]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 4, 0, 4], device='cuda:0')\n",
      "batch_ind = 20\n",
      "y_pred_cpu = tensor([[ 0.2196,  0.1694, -0.1901,  0.0506,  0.3462, -0.0809, -0.1890, -0.2262],\n",
      "        [ 0.2512, -0.1292, -0.0978,  0.0734,  0.4126, -0.0609,  0.0689, -0.3665],\n",
      "        [ 0.3362,  0.2374, -0.2844, -0.0337,  0.2277, -0.1335, -0.1855, -0.1599],\n",
      "        [ 0.2445,  0.3450, -0.2742,  0.0651,  0.4412,  0.0302, -0.1060, -0.2155]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 21\n",
      "y_pred  = tensor([[ 0.3191,  0.1884, -0.2393, -0.0998,  0.2478, -0.0200, -0.1058, -0.1479],\n",
      "        [ 0.3535,  0.1720, -0.1746, -0.0044,  0.3247, -0.0259, -0.2208, -0.2668],\n",
      "        [ 0.2842,  0.1913, -0.2356,  0.0196,  0.2761, -0.0174, -0.1427, -0.2222],\n",
      "        [ 0.3206,  0.2089, -0.2178, -0.0162,  0.3403, -0.0021, -0.1929, -0.2693]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 4], device='cuda:0')\n",
      "batch_ind = 21\n",
      "y_pred_cpu = tensor([[ 0.3191,  0.1884, -0.2393, -0.0998,  0.2478, -0.0200, -0.1058, -0.1479],\n",
      "        [ 0.3535,  0.1720, -0.1746, -0.0044,  0.3247, -0.0259, -0.2208, -0.2668],\n",
      "        [ 0.2842,  0.1913, -0.2356,  0.0196,  0.2761, -0.0174, -0.1427, -0.2222],\n",
      "        [ 0.3206,  0.2089, -0.2178, -0.0162,  0.3403, -0.0021, -0.1929, -0.2693]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 22\n",
      "y_pred  = tensor([[ 0.2595,  0.3245, -0.1451,  0.0203,  0.1852, -0.1370, -0.1591, -0.2874],\n",
      "        [ 0.2798,  0.2693, -0.1978,  0.0043,  0.3855, -0.0073, -0.0975, -0.2847],\n",
      "        [ 0.3088,  0.3420, -0.2800,  0.0517,  0.2864, -0.0660, -0.0937, -0.0826],\n",
      "        [ 0.2079,  0.0649, -0.1515,  0.1149,  0.2329, -0.1053, -0.0112, -0.2375]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([1, 4, 1, 4], device='cuda:0')\n",
      "batch_ind = 22\n",
      "y_pred_cpu = tensor([[ 0.2595,  0.3245, -0.1451,  0.0203,  0.1852, -0.1370, -0.1591, -0.2874],\n",
      "        [ 0.2798,  0.2693, -0.1978,  0.0043,  0.3855, -0.0073, -0.0975, -0.2847],\n",
      "        [ 0.3088,  0.3420, -0.2800,  0.0517,  0.2864, -0.0660, -0.0937, -0.0826],\n",
      "        [ 0.2079,  0.0649, -0.1515,  0.1149,  0.2329, -0.1053, -0.0112, -0.2375]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 23\n",
      "y_pred  = tensor([[ 0.3164,  0.3159, -0.2139, -0.0224,  0.2029,  0.0226, -0.1666, -0.2024],\n",
      "        [ 0.1874,  0.1842, -0.2205,  0.0682,  0.2712, -0.0316,  0.0008, -0.1555],\n",
      "        [ 0.2432,  0.2725, -0.3018,  0.0643,  0.2517,  0.0543, -0.2473, -0.2756],\n",
      "        [ 0.2493,  0.2722, -0.3782,  0.2338,  0.4993, -0.0880, -0.2228, -0.4250]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 4, 1, 4], device='cuda:0')\n",
      "batch_ind = 23\n",
      "y_pred_cpu = tensor([[ 0.3164,  0.3159, -0.2139, -0.0224,  0.2029,  0.0226, -0.1666, -0.2024],\n",
      "        [ 0.1874,  0.1842, -0.2205,  0.0682,  0.2712, -0.0316,  0.0008, -0.1555],\n",
      "        [ 0.2432,  0.2725, -0.3018,  0.0643,  0.2517,  0.0543, -0.2473, -0.2756],\n",
      "        [ 0.2493,  0.2722, -0.3782,  0.2338,  0.4993, -0.0880, -0.2228, -0.4250]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 24\n",
      "y_pred  = tensor([[ 0.2024,  0.3020, -0.1960,  0.1005,  0.2267, -0.0818,  0.0059, -0.1753],\n",
      "        [ 0.2461,  0.3271, -0.2108,  0.0998,  0.2903, -0.0451, -0.2355, -0.2666],\n",
      "        [ 0.1831,  0.2128, -0.1320,  0.1179,  0.3103, -0.1320, -0.1254, -0.2727],\n",
      "        [ 0.1794,  0.2374, -0.1221,  0.0653,  0.1757, -0.0141, -0.1293, -0.1648]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([1, 1, 4, 1], device='cuda:0')\n",
      "batch_ind = 24\n",
      "y_pred_cpu = tensor([[ 0.2024,  0.3020, -0.1960,  0.1005,  0.2267, -0.0818,  0.0059, -0.1753],\n",
      "        [ 0.2461,  0.3271, -0.2108,  0.0998,  0.2903, -0.0451, -0.2355, -0.2666],\n",
      "        [ 0.1831,  0.2128, -0.1320,  0.1179,  0.3103, -0.1320, -0.1254, -0.2727],\n",
      "        [ 0.1794,  0.2374, -0.1221,  0.0653,  0.1757, -0.0141, -0.1293, -0.1648]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 25\n",
      "y_pred  = tensor([[ 0.3926,  0.3464, -0.2363,  0.1495,  0.2622,  0.0591, -0.1537, -0.3044],\n",
      "        [ 0.4246,  0.2764, -0.2949,  0.1436,  0.3208, -0.0164, -0.2913, -0.3569],\n",
      "        [ 0.3379,  0.2534, -0.2681,  0.0476,  0.3169,  0.0297, -0.1582, -0.2979],\n",
      "        [ 0.2332,  0.2542, -0.2214,  0.0762,  0.2820, -0.0488, -0.2035, -0.3103]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 4], device='cuda:0')\n",
      "batch_ind = 25\n",
      "y_pred_cpu = tensor([[ 0.3926,  0.3464, -0.2363,  0.1495,  0.2622,  0.0591, -0.1537, -0.3044],\n",
      "        [ 0.4246,  0.2764, -0.2949,  0.1436,  0.3208, -0.0164, -0.2913, -0.3569],\n",
      "        [ 0.3379,  0.2534, -0.2681,  0.0476,  0.3169,  0.0297, -0.1582, -0.2979],\n",
      "        [ 0.2332,  0.2542, -0.2214,  0.0762,  0.2820, -0.0488, -0.2035, -0.3103]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 26\n",
      "y_pred  = tensor([[ 0.4819,  0.2388, -0.1757,  0.2306,  0.2399, -0.0449, -0.0755, -0.4180],\n",
      "        [ 0.3940,  0.1989, -0.2893,  0.3557,  0.3682, -0.1473, -0.1885, -0.4858],\n",
      "        [ 0.4297,  0.4194, -0.4060,  0.2793,  0.2177,  0.0345, -0.2891, -0.5312],\n",
      "        [ 0.3862,  0.1406, -0.3188,  0.3271,  0.4626, -0.2052, -0.0994, -0.5093]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 4], device='cuda:0')\n",
      "batch_ind = 26\n",
      "y_pred_cpu = tensor([[ 0.4819,  0.2388, -0.1757,  0.2306,  0.2399, -0.0449, -0.0755, -0.4180],\n",
      "        [ 0.3940,  0.1989, -0.2893,  0.3557,  0.3682, -0.1473, -0.1885, -0.4858],\n",
      "        [ 0.4297,  0.4194, -0.4060,  0.2793,  0.2177,  0.0345, -0.2891, -0.5312],\n",
      "        [ 0.3862,  0.1406, -0.3188,  0.3271,  0.4626, -0.2052, -0.0994, -0.5093]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 27\n",
      "y_pred  = tensor([[ 0.5928,  0.4089, -0.2759,  0.3562,  0.4114,  0.0850, -0.1119, -0.6953],\n",
      "        [ 0.6567,  0.2622, -0.3909,  0.2146,  0.1891,  0.0256, -0.1586, -0.5078],\n",
      "        [ 0.5029, -0.0536, -0.3323,  0.3721,  0.3164,  0.0858, -0.1843, -0.6968],\n",
      "        [ 0.4541,  0.0023, -0.2666,  0.3652,  0.3911,  0.2842, -0.1129, -0.4460]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 27\n",
      "y_pred_cpu = tensor([[ 0.5928,  0.4089, -0.2759,  0.3562,  0.4114,  0.0850, -0.1119, -0.6953],\n",
      "        [ 0.6567,  0.2622, -0.3909,  0.2146,  0.1891,  0.0256, -0.1586, -0.5078],\n",
      "        [ 0.5029, -0.0536, -0.3323,  0.3721,  0.3164,  0.0858, -0.1843, -0.6968],\n",
      "        [ 0.4541,  0.0023, -0.2666,  0.3652,  0.3911,  0.2842, -0.1129, -0.4460]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 28\n",
      "y_pred  = tensor([[ 0.8315,  0.5098, -0.5703,  0.5264,  0.3652, -0.1732, -0.3308, -0.8530],\n",
      "        [ 0.5962,  0.2766, -0.5918,  0.5049,  0.2284,  0.2275, -0.2832, -0.8555],\n",
      "        [ 0.4465,  0.1544, -0.5220,  0.4788,  0.3174, -0.1307, -0.2593, -0.6353],\n",
      "        [ 0.5034,  0.3738, -0.5879,  0.5190,  0.3420, -0.0538, -0.1893, -0.7769]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 3, 3], device='cuda:0')\n",
      "batch_ind = 28\n",
      "y_pred_cpu = tensor([[ 0.8315,  0.5098, -0.5703,  0.5264,  0.3652, -0.1732, -0.3308, -0.8530],\n",
      "        [ 0.5962,  0.2766, -0.5918,  0.5049,  0.2284,  0.2275, -0.2832, -0.8555],\n",
      "        [ 0.4465,  0.1544, -0.5220,  0.4788,  0.3174, -0.1307, -0.2593, -0.6353],\n",
      "        [ 0.5034,  0.3738, -0.5879,  0.5190,  0.3420, -0.0538, -0.1893, -0.7769]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 29\n",
      "y_pred  = tensor([[ 0.4365,  0.2056, -0.4041,  0.4055,  0.1796,  0.2527, -0.0274, -0.5215],\n",
      "        [ 0.2440, -0.0434, -0.3467,  0.5303,  0.4204,  0.1565,  0.1203, -0.6582],\n",
      "        [ 0.5830,  0.3757, -0.3982,  0.3850,  0.1791,  0.0699,  0.2306, -0.6387],\n",
      "        [ 0.6157,  0.3691, -0.3369,  0.1884,  0.2949,  0.0509, -0.1165, -0.5552]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 3, 0, 0], device='cuda:0')\n",
      "batch_ind = 29\n",
      "y_pred_cpu = tensor([[ 0.4365,  0.2056, -0.4041,  0.4055,  0.1796,  0.2527, -0.0274, -0.5215],\n",
      "        [ 0.2440, -0.0434, -0.3467,  0.5303,  0.4204,  0.1565,  0.1203, -0.6582],\n",
      "        [ 0.5830,  0.3757, -0.3982,  0.3850,  0.1791,  0.0699,  0.2306, -0.6387],\n",
      "        [ 0.6157,  0.3691, -0.3369,  0.1884,  0.2949,  0.0509, -0.1165, -0.5552]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 30\n",
      "y_pred  = tensor([[ 0.4141,  0.3472, -0.5674,  0.4612,  0.4636, -0.1312, -0.3025, -0.6187],\n",
      "        [ 0.4443,  0.3564, -0.3699,  0.3860,  0.3010,  0.1021, -0.3540, -0.4709],\n",
      "        [ 0.5068,  0.3569, -0.3618,  0.4229,  0.3247,  0.0151, -0.3608, -0.5308],\n",
      "        [ 0.3984,  0.1293, -0.3848,  0.4221,  0.2727, -0.0921, -0.2637, -0.4395]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 0, 0, 3], device='cuda:0')\n",
      "batch_ind = 30\n",
      "y_pred_cpu = tensor([[ 0.4141,  0.3472, -0.5674,  0.4612,  0.4636, -0.1312, -0.3025, -0.6187],\n",
      "        [ 0.4443,  0.3564, -0.3699,  0.3860,  0.3010,  0.1021, -0.3540, -0.4709],\n",
      "        [ 0.5068,  0.3569, -0.3618,  0.4229,  0.3247,  0.0151, -0.3608, -0.5308],\n",
      "        [ 0.3984,  0.1293, -0.3848,  0.4221,  0.2727, -0.0921, -0.2637, -0.4395]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 31\n",
      "y_pred  = tensor([[ 0.6860,  0.2947, -0.5908,  0.4133,  0.3770, -0.0254, -0.3567, -0.6572],\n",
      "        [ 0.6045,  0.4084, -0.7290,  0.3965,  0.4329, -0.0147, -0.1276, -0.6426],\n",
      "        [ 0.6035,  0.3950, -0.4519,  0.5181,  0.5005, -0.1532, -0.0321, -0.6797],\n",
      "        [ 0.5210, -0.0873, -0.2664,  0.4351,  0.1174, -0.2383, -0.0764, -0.2913]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 31\n",
      "y_pred_cpu = tensor([[ 0.6860,  0.2947, -0.5908,  0.4133,  0.3770, -0.0254, -0.3567, -0.6572],\n",
      "        [ 0.6045,  0.4084, -0.7290,  0.3965,  0.4329, -0.0147, -0.1276, -0.6426],\n",
      "        [ 0.6035,  0.3950, -0.4519,  0.5181,  0.5005, -0.1532, -0.0321, -0.6797],\n",
      "        [ 0.5210, -0.0873, -0.2664,  0.4351,  0.1174, -0.2383, -0.0764, -0.2913]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 32\n",
      "y_pred  = tensor([[ 1.1758,  0.2720, -0.6626,  0.6182,  0.5518, -0.2529, -0.4631, -1.0596],\n",
      "        [ 0.8604,  0.1594, -0.6294,  0.4565,  0.4177, -0.1464, -0.1077, -0.8491],\n",
      "        [ 0.7261,  0.2825, -0.6436,  0.4907,  0.3069, -0.0352, -0.3098, -0.6743],\n",
      "        [ 0.8096,  0.5825, -0.7080,  0.6226,  0.5156, -0.0365, -0.4783, -0.8042]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 32\n",
      "y_pred_cpu = tensor([[ 1.1758,  0.2720, -0.6626,  0.6182,  0.5518, -0.2529, -0.4631, -1.0596],\n",
      "        [ 0.8604,  0.1594, -0.6294,  0.4565,  0.4177, -0.1464, -0.1077, -0.8491],\n",
      "        [ 0.7261,  0.2825, -0.6436,  0.4907,  0.3069, -0.0352, -0.3098, -0.6743],\n",
      "        [ 0.8096,  0.5825, -0.7080,  0.6226,  0.5156, -0.0365, -0.4783, -0.8042]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 33\n",
      "y_pred  = tensor([[ 0.4807,  0.2607, -0.6016,  0.4209,  0.4219,  0.1565, -0.1114, -0.6914],\n",
      "        [ 0.6875,  0.2566, -0.7847,  0.3545,  0.4675,  0.0390, -0.1289, -0.7432],\n",
      "        [ 0.5356,  0.2352, -0.7456,  0.3647,  0.3992,  0.0064, -0.0206, -0.8848],\n",
      "        [ 0.6890,  0.0628, -0.2747,  0.4897,  0.3728, -0.1403, -0.1809, -0.5098]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 33\n",
      "y_pred_cpu = tensor([[ 0.4807,  0.2607, -0.6016,  0.4209,  0.4219,  0.1565, -0.1114, -0.6914],\n",
      "        [ 0.6875,  0.2566, -0.7847,  0.3545,  0.4675,  0.0390, -0.1289, -0.7432],\n",
      "        [ 0.5356,  0.2352, -0.7456,  0.3647,  0.3992,  0.0064, -0.0206, -0.8848],\n",
      "        [ 0.6890,  0.0628, -0.2747,  0.4897,  0.3728, -0.1403, -0.1809, -0.5098]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 34\n",
      "y_pred  = tensor([[ 0.4583,  0.1246, -0.4119,  0.5220,  0.4851, -0.1034, -0.2654, -0.7900],\n",
      "        [ 0.6777,  0.3445, -0.5356,  0.4490,  0.3562,  0.1177, -0.0173, -0.8008],\n",
      "        [ 0.5923,  0.3616, -0.7280,  0.5796,  0.8599,  0.1721, -0.0586, -0.9971],\n",
      "        [ 0.4102,  0.0767, -0.5913,  0.4905,  0.5654,  0.0483,  0.1549, -0.7925]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([3, 0, 4, 4], device='cuda:0')\n",
      "batch_ind = 34\n",
      "y_pred_cpu = tensor([[ 0.4583,  0.1246, -0.4119,  0.5220,  0.4851, -0.1034, -0.2654, -0.7900],\n",
      "        [ 0.6777,  0.3445, -0.5356,  0.4490,  0.3562,  0.1177, -0.0173, -0.8008],\n",
      "        [ 0.5923,  0.3616, -0.7280,  0.5796,  0.8599,  0.1721, -0.0586, -0.9971],\n",
      "        [ 0.4102,  0.0767, -0.5913,  0.4905,  0.5654,  0.0483,  0.1549, -0.7925]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 35\n",
      "y_pred  = tensor([[ 0.5298,  0.1354, -0.4807,  0.5518,  0.2466,  0.0473, -0.0780, -0.7275],\n",
      "        [ 0.4131,  0.1295, -0.3069,  0.2810,  0.1765,  0.1626, -0.0475, -0.4045],\n",
      "        [ 0.5400,  0.0950, -0.6128,  0.3989,  0.3794, -0.0394,  0.1425, -0.4812],\n",
      "        [ 0.5693,  0.4570, -0.7310,  0.7227,  0.4209, -0.0421, -0.3223, -0.8535]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([3, 0, 0, 3], device='cuda:0')\n",
      "batch_ind = 35\n",
      "y_pred_cpu = tensor([[ 0.5298,  0.1354, -0.4807,  0.5518,  0.2466,  0.0473, -0.0780, -0.7275],\n",
      "        [ 0.4131,  0.1295, -0.3069,  0.2810,  0.1765,  0.1626, -0.0475, -0.4045],\n",
      "        [ 0.5400,  0.0950, -0.6128,  0.3989,  0.3794, -0.0394,  0.1425, -0.4812],\n",
      "        [ 0.5693,  0.4570, -0.7310,  0.7227,  0.4209, -0.0421, -0.3223, -0.8535]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 36\n",
      "y_pred  = tensor([[ 0.5962,  0.0451, -0.6631,  0.5547,  0.3484, -0.1133,  0.0444, -0.6953],\n",
      "        [ 0.6245, -0.0061, -0.6401,  0.4585,  0.3765,  0.0400, -0.1373, -0.6016],\n",
      "        [ 0.7451,  0.1656, -0.7139,  0.3943,  0.3318, -0.1289,  0.0807, -0.6650],\n",
      "        [ 0.6416, -0.0334, -0.6284,  0.4036,  0.2690, -0.0561, -0.0410, -0.7588]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 36\n",
      "y_pred_cpu = tensor([[ 0.5962,  0.0451, -0.6631,  0.5547,  0.3484, -0.1133,  0.0444, -0.6953],\n",
      "        [ 0.6245, -0.0061, -0.6401,  0.4585,  0.3765,  0.0400, -0.1373, -0.6016],\n",
      "        [ 0.7451,  0.1656, -0.7139,  0.3943,  0.3318, -0.1289,  0.0807, -0.6650],\n",
      "        [ 0.6416, -0.0334, -0.6284,  0.4036,  0.2690, -0.0561, -0.0410, -0.7588]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 37\n",
      "y_pred  = tensor([[ 0.3169, -0.0786, -0.3879,  0.2566,  0.2888,  0.0061, -0.0312, -0.5049],\n",
      "        [ 0.5254,  0.0186, -0.5400,  0.4573,  0.4707, -0.0217, -0.2069, -0.8267],\n",
      "        [ 0.7373,  0.2266, -0.5239,  0.3333,  0.3049,  0.0454,  0.0269, -0.8149],\n",
      "        [ 0.3557, -0.0070, -0.4724,  0.7588,  0.5239, -0.0873, -0.1431, -0.7773]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 3], device='cuda:0')\n",
      "batch_ind = 37\n",
      "y_pred_cpu = tensor([[ 0.3169, -0.0786, -0.3879,  0.2566,  0.2888,  0.0061, -0.0312, -0.5049],\n",
      "        [ 0.5254,  0.0186, -0.5400,  0.4573,  0.4707, -0.0217, -0.2069, -0.8267],\n",
      "        [ 0.7373,  0.2266, -0.5239,  0.3333,  0.3049,  0.0454,  0.0269, -0.8149],\n",
      "        [ 0.3557, -0.0070, -0.4724,  0.7588,  0.5239, -0.0873, -0.1431, -0.7773]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 38\n",
      "y_pred  = tensor([[ 0.5547,  0.0943, -0.4324,  0.2612,  0.3511,  0.0085, -0.2311, -0.5239],\n",
      "        [ 0.2932,  0.1296, -0.3389,  0.2295,  0.2922,  0.0981, -0.0419, -0.5786],\n",
      "        [ 0.4661,  0.1233, -0.3721,  0.2401,  0.3770, -0.0428, -0.0933, -0.5703],\n",
      "        [ 0.6919,  0.2109, -0.4436,  0.4851,  0.4021, -0.1208, -0.2603, -0.5815]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 38\n",
      "y_pred_cpu = tensor([[ 0.5547,  0.0943, -0.4324,  0.2612,  0.3511,  0.0085, -0.2311, -0.5239],\n",
      "        [ 0.2932,  0.1296, -0.3389,  0.2295,  0.2922,  0.0981, -0.0419, -0.5786],\n",
      "        [ 0.4661,  0.1233, -0.3721,  0.2401,  0.3770, -0.0428, -0.0933, -0.5703],\n",
      "        [ 0.6919,  0.2109, -0.4436,  0.4851,  0.4021, -0.1208, -0.2603, -0.5815]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 39\n",
      "y_pred  = tensor([[ 0.5337, -0.1898, -0.4087,  0.3916,  0.4941, -0.3633, -0.2343, -0.7759],\n",
      "        [ 0.4905,  0.0148, -0.3755,  0.2081,  0.4170, -0.3940, -0.2137, -0.6904],\n",
      "        [ 0.4712, -0.0731, -0.2966,  0.5200,  0.5146, -0.2844, -0.2717, -0.7583],\n",
      "        [ 0.8193,  0.1840, -0.7769,  0.6143,  0.7671, -0.3062, -0.4109, -0.9194]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 3, 0], device='cuda:0')\n",
      "batch_ind = 39\n",
      "y_pred_cpu = tensor([[ 0.5337, -0.1898, -0.4087,  0.3916,  0.4941, -0.3633, -0.2343, -0.7759],\n",
      "        [ 0.4905,  0.0148, -0.3755,  0.2081,  0.4170, -0.3940, -0.2137, -0.6904],\n",
      "        [ 0.4712, -0.0731, -0.2966,  0.5200,  0.5146, -0.2844, -0.2717, -0.7583],\n",
      "        [ 0.8193,  0.1840, -0.7769,  0.6143,  0.7671, -0.3062, -0.4109, -0.9194]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 40\n",
      "y_pred  = tensor([[ 0.5542,  0.2090, -0.5640,  0.3333,  0.4019, -0.1902, -0.3872, -0.7822],\n",
      "        [ 0.5483, -0.1973, -0.2976,  0.4160,  0.5542, -0.3354, -0.3188, -0.6943],\n",
      "        [ 0.6147,  0.2976, -0.5464,  0.4238,  0.4243, -0.1691, -0.2815, -0.7915],\n",
      "        [ 0.5376, -0.0126, -0.5103,  0.3687,  0.5015, -0.2927, -0.2681, -0.7451]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 4, 0, 0], device='cuda:0')\n",
      "batch_ind = 40\n",
      "y_pred_cpu = tensor([[ 0.5542,  0.2090, -0.5640,  0.3333,  0.4019, -0.1902, -0.3872, -0.7822],\n",
      "        [ 0.5483, -0.1973, -0.2976,  0.4160,  0.5542, -0.3354, -0.3188, -0.6943],\n",
      "        [ 0.6147,  0.2976, -0.5464,  0.4238,  0.4243, -0.1691, -0.2815, -0.7915],\n",
      "        [ 0.5376, -0.0126, -0.5103,  0.3687,  0.5015, -0.2927, -0.2681, -0.7451]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 41\n",
      "y_pred  = tensor([[ 0.5205,  0.3291, -0.3149,  0.5288,  0.3726, -0.1816, -0.2729, -0.6733],\n",
      "        [ 0.4622,  0.4277, -0.3682,  0.4280,  0.2827, -0.0665, -0.1866, -0.5156],\n",
      "        [ 0.3384,  0.0721, -0.4905,  0.1942,  0.4766,  0.1777, -0.0680, -0.2133],\n",
      "        [ 0.6440,  0.5059, -0.4094,  0.5298,  0.4626, -0.2056, -0.2318, -0.7041]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([3, 0, 4, 0], device='cuda:0')\n",
      "batch_ind = 41\n",
      "y_pred_cpu = tensor([[ 0.5205,  0.3291, -0.3149,  0.5288,  0.3726, -0.1816, -0.2729, -0.6733],\n",
      "        [ 0.4622,  0.4277, -0.3682,  0.4280,  0.2827, -0.0665, -0.1866, -0.5156],\n",
      "        [ 0.3384,  0.0721, -0.4905,  0.1942,  0.4766,  0.1777, -0.0680, -0.2133],\n",
      "        [ 0.6440,  0.5059, -0.4094,  0.5298,  0.4626, -0.2056, -0.2318, -0.7041]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 42\n",
      "y_pred  = tensor([[ 0.3716,  0.1558, -0.2028,  0.3757,  0.2949,  0.0024, -0.1886, -0.4832],\n",
      "        [ 0.5781,  0.1753, -0.3813,  0.2773,  0.2703, -0.0204, -0.1414, -0.7427],\n",
      "        [ 0.4539,  0.3022, -0.6636,  0.3633,  0.4067,  0.0964, -0.1080, -0.6348],\n",
      "        [ 0.3425,  0.2039, -0.2659,  0.3210,  0.2756,  0.1364, -0.1957, -0.3035]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([3, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 42\n",
      "y_pred_cpu = tensor([[ 0.3716,  0.1558, -0.2028,  0.3757,  0.2949,  0.0024, -0.1886, -0.4832],\n",
      "        [ 0.5781,  0.1753, -0.3813,  0.2773,  0.2703, -0.0204, -0.1414, -0.7427],\n",
      "        [ 0.4539,  0.3022, -0.6636,  0.3633,  0.4067,  0.0964, -0.1080, -0.6348],\n",
      "        [ 0.3425,  0.2039, -0.2659,  0.3210,  0.2756,  0.1364, -0.1957, -0.3035]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 43\n",
      "y_pred  = tensor([[ 0.4248,  0.1635, -0.4966,  0.4524,  0.3130, -0.2130, -0.2235, -0.6694],\n",
      "        [ 0.4561,  0.1076, -0.4807,  0.2169,  0.3303, -0.0461, -0.2297, -0.4590],\n",
      "        [ 0.5088,  0.4163, -0.6255,  0.3887,  0.4209, -0.0372, -0.2617, -0.8237],\n",
      "        [ 0.3708,  0.1667, -0.4177,  0.2007,  0.2979,  0.0285, -0.0823, -0.4041]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([3, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 43\n",
      "y_pred_cpu = tensor([[ 0.4248,  0.1635, -0.4966,  0.4524,  0.3130, -0.2130, -0.2235, -0.6694],\n",
      "        [ 0.4561,  0.1076, -0.4807,  0.2169,  0.3303, -0.0461, -0.2297, -0.4590],\n",
      "        [ 0.5088,  0.4163, -0.6255,  0.3887,  0.4209, -0.0372, -0.2617, -0.8237],\n",
      "        [ 0.3708,  0.1667, -0.4177,  0.2007,  0.2979,  0.0285, -0.0823, -0.4041]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 44\n",
      "y_pred  = tensor([[ 0.7012,  0.4287, -0.6333,  0.5239,  0.3953, -0.1567, -0.1870, -0.7783],\n",
      "        [ 0.5269,  0.3882, -0.3848,  0.5410,  0.4758, -0.2085, -0.3176, -0.7520],\n",
      "        [ 0.4502,  0.6147, -0.6006,  0.5762,  0.4543, -0.0065, -0.0652, -0.9292],\n",
      "        [ 0.5464,  0.3484, -0.4919,  0.6084,  0.5830, -0.1482, -0.2399, -0.8369]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 3, 1, 3], device='cuda:0')\n",
      "batch_ind = 44\n",
      "y_pred_cpu = tensor([[ 0.7012,  0.4287, -0.6333,  0.5239,  0.3953, -0.1567, -0.1870, -0.7783],\n",
      "        [ 0.5269,  0.3882, -0.3848,  0.5410,  0.4758, -0.2085, -0.3176, -0.7520],\n",
      "        [ 0.4502,  0.6147, -0.6006,  0.5762,  0.4543, -0.0065, -0.0652, -0.9292],\n",
      "        [ 0.5464,  0.3484, -0.4919,  0.6084,  0.5830, -0.1482, -0.2399, -0.8369]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 45\n",
      "y_pred  = tensor([[ 0.2157,  0.1710, -0.2449,  0.4160,  0.2908,  0.0030, -0.1781, -0.6123],\n",
      "        [ 0.4204,  0.1736, -0.4404,  0.3945,  0.2844,  0.0896, -0.0690, -0.5591],\n",
      "        [ 0.3213,  0.1385, -0.3875,  0.3730,  0.3479, -0.1427,  0.0442, -0.5938],\n",
      "        [ 0.4419,  0.2133, -0.5059,  0.4214,  0.2832, -0.0512, -0.2161, -0.7158]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([3, 0, 3, 0], device='cuda:0')\n",
      "batch_ind = 45\n",
      "y_pred_cpu = tensor([[ 0.2157,  0.1710, -0.2449,  0.4160,  0.2908,  0.0030, -0.1781, -0.6123],\n",
      "        [ 0.4204,  0.1736, -0.4404,  0.3945,  0.2844,  0.0896, -0.0690, -0.5591],\n",
      "        [ 0.3213,  0.1385, -0.3875,  0.3730,  0.3479, -0.1427,  0.0442, -0.5938],\n",
      "        [ 0.4419,  0.2133, -0.5059,  0.4214,  0.2832, -0.0512, -0.2161, -0.7158]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 46\n",
      "y_pred  = tensor([[ 0.3635,  0.4854, -0.5229,  0.3794,  0.2480, -0.0439, -0.0748, -0.6909],\n",
      "        [ 0.4912,  0.2449, -0.3779,  0.1835,  0.2878, -0.0027, -0.1160, -0.6963],\n",
      "        [ 0.3120,  0.3250, -0.4089,  0.3855,  0.4080, -0.0711, -0.0415, -0.5493],\n",
      "        [ 0.2842,  0.4062, -0.3713,  0.3191,  0.3081,  0.0014, -0.1260, -0.6274]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([1, 0, 4, 1], device='cuda:0')\n",
      "batch_ind = 46\n",
      "y_pred_cpu = tensor([[ 0.3635,  0.4854, -0.5229,  0.3794,  0.2480, -0.0439, -0.0748, -0.6909],\n",
      "        [ 0.4912,  0.2449, -0.3779,  0.1835,  0.2878, -0.0027, -0.1160, -0.6963],\n",
      "        [ 0.3120,  0.3250, -0.4089,  0.3855,  0.4080, -0.0711, -0.0415, -0.5493],\n",
      "        [ 0.2842,  0.4062, -0.3713,  0.3191,  0.3081,  0.0014, -0.1260, -0.6274]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 47\n",
      "y_pred  = tensor([[ 0.3625,  0.3069, -0.4412,  0.3550,  0.4048, -0.0779, -0.0823, -0.6899],\n",
      "        [ 0.2180,  0.1521, -0.2048,  0.2966,  0.2710,  0.0560, -0.0964, -0.2920],\n",
      "        [ 0.2344,  0.1837, -0.3364,  0.3179,  0.2537,  0.0334, -0.0862, -0.3589],\n",
      "        [ 0.3420,  0.1532, -0.3833,  0.2969,  0.2556,  0.0200, -0.0347, -0.4233]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 3, 3, 0], device='cuda:0')\n",
      "batch_ind = 47\n",
      "y_pred_cpu = tensor([[ 0.3625,  0.3069, -0.4412,  0.3550,  0.4048, -0.0779, -0.0823, -0.6899],\n",
      "        [ 0.2180,  0.1521, -0.2048,  0.2966,  0.2710,  0.0560, -0.0964, -0.2920],\n",
      "        [ 0.2344,  0.1837, -0.3364,  0.3179,  0.2537,  0.0334, -0.0862, -0.3589],\n",
      "        [ 0.3420,  0.1532, -0.3833,  0.2969,  0.2556,  0.0200, -0.0347, -0.4233]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 48\n",
      "y_pred  = tensor([[ 0.5464,  0.2686, -0.6074,  0.5659,  0.3896, -0.3511, -0.1420, -0.8647],\n",
      "        [ 0.5874,  0.3142, -0.5444,  0.5938,  0.2334, -0.3145, -0.2299, -0.7871],\n",
      "        [ 0.6006,  0.2062, -0.5322,  0.5903,  0.2532, -0.1848, -0.2225, -0.8740],\n",
      "        [ 0.3770,  0.2896, -0.1526,  0.2656,  0.2720, -0.2020, -0.1584, -0.5352]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([3, 3, 0, 0], device='cuda:0')\n",
      "batch_ind = 48\n",
      "y_pred_cpu = tensor([[ 0.5464,  0.2686, -0.6074,  0.5659,  0.3896, -0.3511, -0.1420, -0.8647],\n",
      "        [ 0.5874,  0.3142, -0.5444,  0.5938,  0.2334, -0.3145, -0.2299, -0.7871],\n",
      "        [ 0.6006,  0.2062, -0.5322,  0.5903,  0.2532, -0.1848, -0.2225, -0.8740],\n",
      "        [ 0.3770,  0.2896, -0.1526,  0.2656,  0.2720, -0.2020, -0.1584, -0.5352]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 49\n",
      "y_pred  = tensor([[ 0.3306,  0.2974, -0.2681,  0.3701,  0.3379, -0.1152, -0.1315, -0.8779],\n",
      "        [ 0.2155, -0.1132, -0.1130,  0.2856,  0.5474, -0.3594, -0.1731, -0.6323],\n",
      "        [ 0.5791,  0.2537, -0.4512,  0.3704,  0.3118, -0.0917, -0.1757, -0.6987],\n",
      "        [ 0.4211,  0.2267, -0.3875,  0.2539,  0.2607, -0.0281, -0.1418, -0.5820]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([3, 4, 0, 0], device='cuda:0')\n",
      "batch_ind = 49\n",
      "y_pred_cpu = tensor([[ 0.3306,  0.2974, -0.2681,  0.3701,  0.3379, -0.1152, -0.1315, -0.8779],\n",
      "        [ 0.2155, -0.1132, -0.1130,  0.2856,  0.5474, -0.3594, -0.1731, -0.6323],\n",
      "        [ 0.5791,  0.2537, -0.4512,  0.3704,  0.3118, -0.0917, -0.1757, -0.6987],\n",
      "        [ 0.4211,  0.2267, -0.3875,  0.2539,  0.2607, -0.0281, -0.1418, -0.5820]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 50\n",
      "y_pred  = tensor([[ 0.4526,  0.1082, -0.4585,  0.2903,  0.3125, -0.1425, -0.0729, -0.5195],\n",
      "        [ 0.5015,  0.2220, -0.4470,  0.4919,  0.3813, -0.3762, -0.1072, -0.6528],\n",
      "        [ 0.4961,  0.3555, -0.5522,  0.3032,  0.3640, -0.1294, -0.0805, -0.7061],\n",
      "        [ 0.5542,  0.3613, -0.3938,  0.5117,  0.4521, -0.2627, -0.1497, -0.6841]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 50\n",
      "y_pred_cpu = tensor([[ 0.4526,  0.1082, -0.4585,  0.2903,  0.3125, -0.1425, -0.0729, -0.5195],\n",
      "        [ 0.5015,  0.2220, -0.4470,  0.4919,  0.3813, -0.3762, -0.1072, -0.6528],\n",
      "        [ 0.4961,  0.3555, -0.5522,  0.3032,  0.3640, -0.1294, -0.0805, -0.7061],\n",
      "        [ 0.5542,  0.3613, -0.3938,  0.5117,  0.4521, -0.2627, -0.1497, -0.6841]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 51\n",
      "y_pred  = tensor([[ 0.4329,  0.1299, -0.3826,  0.3352,  0.2585, -0.0393, -0.0852, -0.6475],\n",
      "        [ 0.4783,  0.3223, -0.5176,  0.4978,  0.2520,  0.0750,  0.0039, -0.6421],\n",
      "        [ 0.3848,  0.3835, -0.8018,  0.2325,  0.3430,  0.0463, -0.0117, -0.7310],\n",
      "        [ 0.3774,  0.2588, -0.2847,  0.3643,  0.3665, -0.0798, -0.0745, -0.5518]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 3, 0, 0], device='cuda:0')\n",
      "batch_ind = 51\n",
      "y_pred_cpu = tensor([[ 0.4329,  0.1299, -0.3826,  0.3352,  0.2585, -0.0393, -0.0852, -0.6475],\n",
      "        [ 0.4783,  0.3223, -0.5176,  0.4978,  0.2520,  0.0750,  0.0039, -0.6421],\n",
      "        [ 0.3848,  0.3835, -0.8018,  0.2325,  0.3430,  0.0463, -0.0117, -0.7310],\n",
      "        [ 0.3774,  0.2588, -0.2847,  0.3643,  0.3665, -0.0798, -0.0745, -0.5518]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 52\n",
      "y_pred  = tensor([[ 0.3215,  0.2986, -0.5435,  0.3284,  0.3477,  0.0616, -0.0419, -0.8003],\n",
      "        [ 0.8247,  0.3589, -0.7827,  0.5532,  0.5581, -0.0125, -0.1077, -1.0830],\n",
      "        [ 0.6108,  0.2771, -0.6523,  0.5010,  0.5005, -0.2493, -0.2224, -0.9985],\n",
      "        [ 0.4343,  0.0919, -0.3992,  0.2009,  0.2795,  0.1322, -0.0073, -0.3975]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 52\n",
      "y_pred_cpu = tensor([[ 0.3215,  0.2986, -0.5435,  0.3284,  0.3477,  0.0616, -0.0419, -0.8003],\n",
      "        [ 0.8247,  0.3589, -0.7827,  0.5532,  0.5581, -0.0125, -0.1077, -1.0830],\n",
      "        [ 0.6108,  0.2771, -0.6523,  0.5010,  0.5005, -0.2493, -0.2224, -0.9985],\n",
      "        [ 0.4343,  0.0919, -0.3992,  0.2009,  0.2795,  0.1322, -0.0073, -0.3975]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 53\n",
      "y_pred  = tensor([[ 0.6279,  0.3887, -0.7305,  0.4399,  0.3701, -0.3630, -0.0175, -0.9253],\n",
      "        [ 0.7949,  0.2225, -0.5586,  0.5015,  0.5732, -0.1829, -0.2271, -0.7246],\n",
      "        [ 0.5874,  0.1698, -0.6504,  0.6411,  0.4304, -0.3792, -0.1718, -0.8799],\n",
      "        [ 0.8203,  0.2539, -0.4465,  0.5713,  0.4929, -0.3362,  0.1506, -0.7383]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 3, 0], device='cuda:0')\n",
      "batch_ind = 53\n",
      "y_pred_cpu = tensor([[ 0.6279,  0.3887, -0.7305,  0.4399,  0.3701, -0.3630, -0.0175, -0.9253],\n",
      "        [ 0.7949,  0.2225, -0.5586,  0.5015,  0.5732, -0.1829, -0.2271, -0.7246],\n",
      "        [ 0.5874,  0.1698, -0.6504,  0.6411,  0.4304, -0.3792, -0.1718, -0.8799],\n",
      "        [ 0.8203,  0.2539, -0.4465,  0.5713,  0.4929, -0.3362,  0.1506, -0.7383]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 54\n",
      "y_pred  = tensor([[ 0.3096,  0.1042, -0.3057,  0.3965,  0.5303, -0.2358, -0.2534, -0.8042],\n",
      "        [ 0.3625,  0.2937, -0.5566,  0.6152,  0.3328,  0.0463,  0.0615, -0.8110],\n",
      "        [ 0.3665, -0.0120, -0.4260,  0.3374,  0.3101, -0.1641, -0.1262, -0.4839],\n",
      "        [ 0.3723,  0.1063, -0.2771,  0.3071,  0.4653, -0.1595, -0.2363, -0.8784]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 3, 0, 4], device='cuda:0')\n",
      "batch_ind = 54\n",
      "y_pred_cpu = tensor([[ 0.3096,  0.1042, -0.3057,  0.3965,  0.5303, -0.2358, -0.2534, -0.8042],\n",
      "        [ 0.3625,  0.2937, -0.5566,  0.6152,  0.3328,  0.0463,  0.0615, -0.8110],\n",
      "        [ 0.3665, -0.0120, -0.4260,  0.3374,  0.3101, -0.1641, -0.1262, -0.4839],\n",
      "        [ 0.3723,  0.1063, -0.2771,  0.3071,  0.4653, -0.1595, -0.2363, -0.8784]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 55\n",
      "y_pred  = tensor([[ 0.4128,  0.1660, -0.3577,  0.1927,  0.2595, -0.0293, -0.0558, -0.4080],\n",
      "        [ 0.3687,  0.1827, -0.3457,  0.4197,  0.3489, -0.0796, -0.0845, -0.7295],\n",
      "        [ 0.3132,  0.1108, -0.5249,  0.4595,  0.5054,  0.0502, -0.0887, -0.9419],\n",
      "        [ 0.4324,  0.2822, -0.4780,  0.4106,  0.4150, -0.1104, -0.0311, -0.6816]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 3, 4, 0], device='cuda:0')\n",
      "batch_ind = 55\n",
      "y_pred_cpu = tensor([[ 0.4128,  0.1660, -0.3577,  0.1927,  0.2595, -0.0293, -0.0558, -0.4080],\n",
      "        [ 0.3687,  0.1827, -0.3457,  0.4197,  0.3489, -0.0796, -0.0845, -0.7295],\n",
      "        [ 0.3132,  0.1108, -0.5249,  0.4595,  0.5054,  0.0502, -0.0887, -0.9419],\n",
      "        [ 0.4324,  0.2822, -0.4780,  0.4106,  0.4150, -0.1104, -0.0311, -0.6816]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 56\n",
      "y_pred  = tensor([[ 0.5610,  0.2527, -0.4485,  0.2893,  0.3406, -0.2568, -0.2410, -0.6782],\n",
      "        [ 0.5913, -0.0487, -0.4146,  0.3687,  0.3203, -0.3333, -0.2087, -0.6138],\n",
      "        [ 0.3979,  0.1426, -0.4734,  0.6377,  0.3611, -0.3347, -0.0518, -0.9180],\n",
      "        [ 0.4961,  0.1486, -0.4587,  0.5254,  0.3921, -0.2729, -0.1754, -0.7974]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 3, 3], device='cuda:0')\n",
      "batch_ind = 56\n",
      "y_pred_cpu = tensor([[ 0.5610,  0.2527, -0.4485,  0.2893,  0.3406, -0.2568, -0.2410, -0.6782],\n",
      "        [ 0.5913, -0.0487, -0.4146,  0.3687,  0.3203, -0.3333, -0.2087, -0.6138],\n",
      "        [ 0.3979,  0.1426, -0.4734,  0.6377,  0.3611, -0.3347, -0.0518, -0.9180],\n",
      "        [ 0.4961,  0.1486, -0.4587,  0.5254,  0.3921, -0.2729, -0.1754, -0.7974]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 57\n",
      "y_pred  = tensor([[ 0.4233,  0.1597, -0.6094,  0.4763,  0.3887, -0.0568, -0.0789, -0.7642],\n",
      "        [ 0.2164, -0.0465, -0.3740,  0.4446,  0.4314, -0.2147,  0.0425, -0.6660],\n",
      "        [ 0.3518,  0.2729, -0.5679,  0.5239,  0.5967, -0.1753,  0.0098, -0.9224],\n",
      "        [ 0.3967,  0.2837, -0.3555,  0.4526,  0.3975, -0.1641, -0.0988, -0.7354]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([3, 3, 4, 3], device='cuda:0')\n",
      "batch_ind = 57\n",
      "y_pred_cpu = tensor([[ 0.4233,  0.1597, -0.6094,  0.4763,  0.3887, -0.0568, -0.0789, -0.7642],\n",
      "        [ 0.2164, -0.0465, -0.3740,  0.4446,  0.4314, -0.2147,  0.0425, -0.6660],\n",
      "        [ 0.3518,  0.2729, -0.5679,  0.5239,  0.5967, -0.1753,  0.0098, -0.9224],\n",
      "        [ 0.3967,  0.2837, -0.3555,  0.4526,  0.3975, -0.1641, -0.0988, -0.7354]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 58\n",
      "y_pred  = tensor([[ 0.3875,  0.2986, -0.5122,  0.6094,  0.5225, -0.2773, -0.2352, -0.9292],\n",
      "        [ 0.4390,  0.1940, -0.3315,  0.4270,  0.3689, -0.2179, -0.1144, -0.6914],\n",
      "        [ 0.4048, -0.0461, -0.1804,  0.3086,  0.4556, -0.2013, -0.1427, -0.4536],\n",
      "        [ 0.5571,  0.3486, -0.6304,  0.8091,  0.5591, -0.1133, -0.1414, -0.9854]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([3, 0, 4, 3], device='cuda:0')\n",
      "batch_ind = 58\n",
      "y_pred_cpu = tensor([[ 0.3875,  0.2986, -0.5122,  0.6094,  0.5225, -0.2773, -0.2352, -0.9292],\n",
      "        [ 0.4390,  0.1940, -0.3315,  0.4270,  0.3689, -0.2179, -0.1144, -0.6914],\n",
      "        [ 0.4048, -0.0461, -0.1804,  0.3086,  0.4556, -0.2013, -0.1427, -0.4536],\n",
      "        [ 0.5571,  0.3486, -0.6304,  0.8091,  0.5591, -0.1133, -0.1414, -0.9854]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 59\n",
      "y_pred  = tensor([[ 0.2981,  0.0616, -0.3462,  0.4980,  0.5728, -0.4126, -0.1152, -0.6260],\n",
      "        [ 0.3835,  0.2258, -0.6465,  0.6372,  0.5962, -0.1331, -0.0334, -0.8936],\n",
      "        [ 0.2727,  0.1814, -0.4617,  0.4587,  0.3738, -0.2312, -0.0391, -1.0166],\n",
      "        [ 0.5093,  0.2140, -0.5757,  0.6050,  0.6450, -0.1125, -0.2102, -0.9380]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 3, 3, 4], device='cuda:0')\n",
      "batch_ind = 59\n",
      "y_pred_cpu = tensor([[ 0.2981,  0.0616, -0.3462,  0.4980,  0.5728, -0.4126, -0.1152, -0.6260],\n",
      "        [ 0.3835,  0.2258, -0.6465,  0.6372,  0.5962, -0.1331, -0.0334, -0.8936],\n",
      "        [ 0.2727,  0.1814, -0.4617,  0.4587,  0.3738, -0.2312, -0.0391, -1.0166],\n",
      "        [ 0.5093,  0.2140, -0.5757,  0.6050,  0.6450, -0.1125, -0.2102, -0.9380]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 60\n",
      "y_pred  = tensor([[ 0.5571,  0.2362, -0.4226,  0.4062,  0.4116, -0.0278, -0.1071, -0.5903],\n",
      "        [ 0.4431,  0.0657, -0.3088,  0.2988,  0.2450, -0.0912,  0.0116, -0.4038],\n",
      "        [ 0.4014,  0.1224, -0.4270,  0.4878,  0.4382, -0.2771, -0.1497, -0.8423],\n",
      "        [ 0.3989,  0.2551, -0.2355,  0.2815,  0.1660, -0.1274, -0.1262, -0.4792]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 3, 0], device='cuda:0')\n",
      "batch_ind = 60\n",
      "y_pred_cpu = tensor([[ 0.5571,  0.2362, -0.4226,  0.4062,  0.4116, -0.0278, -0.1071, -0.5903],\n",
      "        [ 0.4431,  0.0657, -0.3088,  0.2988,  0.2450, -0.0912,  0.0116, -0.4038],\n",
      "        [ 0.4014,  0.1224, -0.4270,  0.4878,  0.4382, -0.2771, -0.1497, -0.8423],\n",
      "        [ 0.3989,  0.2551, -0.2355,  0.2815,  0.1660, -0.1274, -0.1262, -0.4792]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 61\n",
      "y_pred  = tensor([[ 0.7554,  0.2808, -0.7026,  0.4971,  0.5508, -0.7544, -0.2046, -1.0244],\n",
      "        [ 0.6812,  0.2324, -0.7598,  0.7773,  0.3677, -0.1620, -0.1394, -0.9141],\n",
      "        [ 0.5508,  0.3296, -0.7476,  0.6494,  0.2749, -0.2563, -0.1475, -1.1982],\n",
      "        [ 0.4453,  0.2002, -0.4885,  0.5024,  0.6533, -0.5215, -0.2581, -0.8945]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 3, 3, 4], device='cuda:0')\n",
      "batch_ind = 61\n",
      "y_pred_cpu = tensor([[ 0.7554,  0.2808, -0.7026,  0.4971,  0.5508, -0.7544, -0.2046, -1.0244],\n",
      "        [ 0.6812,  0.2324, -0.7598,  0.7773,  0.3677, -0.1620, -0.1394, -0.9141],\n",
      "        [ 0.5508,  0.3296, -0.7476,  0.6494,  0.2749, -0.2563, -0.1475, -1.1982],\n",
      "        [ 0.4453,  0.2002, -0.4885,  0.5024,  0.6533, -0.5215, -0.2581, -0.8945]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 62\n",
      "y_pred  = tensor([[ 0.7119,  0.3386, -0.4255,  0.6201,  0.5762, -0.2544, -0.1236, -0.6680],\n",
      "        [ 0.7349,  0.3301, -0.6694,  0.6567,  0.5791, -0.3098, -0.3362, -0.6851],\n",
      "        [ 0.7148,  0.2561, -0.6221,  0.6646,  0.5483, -0.6836, -0.4951, -0.8921],\n",
      "        [ 1.0312,  0.2445, -0.5049,  0.4202,  0.8062, -0.4507, -0.4353, -0.9131]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 62\n",
      "y_pred_cpu = tensor([[ 0.7119,  0.3386, -0.4255,  0.6201,  0.5762, -0.2544, -0.1236, -0.6680],\n",
      "        [ 0.7349,  0.3301, -0.6694,  0.6567,  0.5791, -0.3098, -0.3362, -0.6851],\n",
      "        [ 0.7148,  0.2561, -0.6221,  0.6646,  0.5483, -0.6836, -0.4951, -0.8921],\n",
      "        [ 1.0312,  0.2445, -0.5049,  0.4202,  0.8062, -0.4507, -0.4353, -0.9131]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 63\n",
      "y_pred  = tensor([[ 0.3928,  0.1716, -0.3745,  0.3516,  0.5024, -0.5645, -0.0597, -0.5098],\n",
      "        [ 0.7437,  0.4236, -0.5361,  0.2487,  0.2947, -0.1685, -0.1342, -0.7192],\n",
      "        [ 0.6440,  0.2622, -0.5635,  0.5732,  0.3684, -0.3450, -0.1185, -0.8848],\n",
      "        [ 0.6597,  0.2615, -0.4724,  0.5093,  0.5303, -0.4844,  0.0068, -0.8477]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 63\n",
      "y_pred_cpu = tensor([[ 0.3928,  0.1716, -0.3745,  0.3516,  0.5024, -0.5645, -0.0597, -0.5098],\n",
      "        [ 0.7437,  0.4236, -0.5361,  0.2487,  0.2947, -0.1685, -0.1342, -0.7192],\n",
      "        [ 0.6440,  0.2622, -0.5635,  0.5732,  0.3684, -0.3450, -0.1185, -0.8848],\n",
      "        [ 0.6597,  0.2615, -0.4724,  0.5093,  0.5303, -0.4844,  0.0068, -0.8477]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 64\n",
      "y_pred  = tensor([[ 0.6675,  0.2527, -0.6138,  0.6494,  0.3303, -0.5435,  0.0455, -0.5962],\n",
      "        [ 0.6665,  0.0431, -0.6543,  0.4319,  0.7437, -0.9150, -0.1757, -0.8652],\n",
      "        [ 0.7051,  0.4336, -0.4468,  0.5581,  0.6807, -0.5571, -0.0087, -0.6812],\n",
      "        [ 0.5854,  0.0285, -0.4780,  0.6797,  0.4316, -0.7607,  0.0521, -0.6401]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 4, 0, 3], device='cuda:0')\n",
      "batch_ind = 64\n",
      "y_pred_cpu = tensor([[ 0.6675,  0.2527, -0.6138,  0.6494,  0.3303, -0.5435,  0.0455, -0.5962],\n",
      "        [ 0.6665,  0.0431, -0.6543,  0.4319,  0.7437, -0.9150, -0.1757, -0.8652],\n",
      "        [ 0.7051,  0.4336, -0.4468,  0.5581,  0.6807, -0.5571, -0.0087, -0.6812],\n",
      "        [ 0.5854,  0.0285, -0.4780,  0.6797,  0.4316, -0.7607,  0.0521, -0.6401]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 65\n",
      "y_pred  = tensor([[ 1.2051,  0.0643, -0.6704,  0.4236,  0.3735, -0.9673, -0.4817, -0.7837],\n",
      "        [ 0.7065,  0.1615, -0.6919,  0.5068,  0.5850, -0.5728, -0.2117, -0.7783],\n",
      "        [ 0.8647,  0.2898, -0.9536,  0.5483,  0.4546, -0.4778, -0.4900, -0.7563],\n",
      "        [ 0.7700,  0.1100, -0.7036,  0.5518,  0.4482, -0.6919, -0.0947, -0.9160]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 65\n",
      "y_pred_cpu = tensor([[ 1.2051,  0.0643, -0.6704,  0.4236,  0.3735, -0.9673, -0.4817, -0.7837],\n",
      "        [ 0.7065,  0.1615, -0.6919,  0.5068,  0.5850, -0.5728, -0.2117, -0.7783],\n",
      "        [ 0.8647,  0.2898, -0.9536,  0.5483,  0.4546, -0.4778, -0.4900, -0.7563],\n",
      "        [ 0.7700,  0.1100, -0.7036,  0.5518,  0.4482, -0.6919, -0.0947, -0.9160]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 66\n",
      "y_pred  = tensor([[ 0.6836,  0.4663, -0.7661,  0.4043,  0.3647, -0.1667, -0.2627, -0.8706],\n",
      "        [ 0.4978,  0.2346, -0.6069,  0.5444,  0.5986, -0.1620, -0.2218, -0.7773],\n",
      "        [ 0.6978,  0.3401, -0.4041,  0.3291,  0.4761, -0.2905, -0.2983, -0.8442],\n",
      "        [ 0.8018,  0.1016, -0.6021,  0.6060,  0.4272, -0.4043, -0.1752, -0.8193]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 4, 0, 0], device='cuda:0')\n",
      "batch_ind = 66\n",
      "y_pred_cpu = tensor([[ 0.6836,  0.4663, -0.7661,  0.4043,  0.3647, -0.1667, -0.2627, -0.8706],\n",
      "        [ 0.4978,  0.2346, -0.6069,  0.5444,  0.5986, -0.1620, -0.2218, -0.7773],\n",
      "        [ 0.6978,  0.3401, -0.4041,  0.3291,  0.4761, -0.2905, -0.2983, -0.8442],\n",
      "        [ 0.8018,  0.1016, -0.6021,  0.6060,  0.4272, -0.4043, -0.1752, -0.8193]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 67\n",
      "y_pred  = tensor([[ 0.4314,  0.0741, -0.3882,  0.2590,  0.1763, -0.1586,  0.0310, -0.1844],\n",
      "        [ 0.5308,  0.3179, -0.5571,  0.3303,  0.2607, -0.2164,  0.0806, -0.3386],\n",
      "        [ 0.5679,  0.3718, -0.5708,  0.4255,  0.3557, -0.1091, -0.0638, -0.5596],\n",
      "        [ 0.5312,  0.2090, -0.5029,  0.1356,  0.4644, -0.3677, -0.1106, -0.3665]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 67\n",
      "y_pred_cpu = tensor([[ 0.4314,  0.0741, -0.3882,  0.2590,  0.1763, -0.1586,  0.0310, -0.1844],\n",
      "        [ 0.5308,  0.3179, -0.5571,  0.3303,  0.2607, -0.2164,  0.0806, -0.3386],\n",
      "        [ 0.5679,  0.3718, -0.5708,  0.4255,  0.3557, -0.1091, -0.0638, -0.5596],\n",
      "        [ 0.5312,  0.2090, -0.5029,  0.1356,  0.4644, -0.3677, -0.1106, -0.3665]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 68\n",
      "y_pred  = tensor([[ 0.7056,  0.5508, -0.5332,  0.4536,  0.4495, -0.2607, -0.3669, -0.8276],\n",
      "        [ 0.6978,  0.3701, -0.6934,  0.5815,  0.5161, -0.5435, -0.0564, -0.8101],\n",
      "        [ 0.6763,  0.1349, -0.4812,  0.6865,  0.7832, -0.5356, -0.3313, -0.5977],\n",
      "        [ 0.7676,  0.4678, -0.5195,  0.6431,  0.4180, -0.4893, -0.4670, -0.8179]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 4, 0], device='cuda:0')\n",
      "batch_ind = 68\n",
      "y_pred_cpu = tensor([[ 0.7056,  0.5508, -0.5332,  0.4536,  0.4495, -0.2607, -0.3669, -0.8276],\n",
      "        [ 0.6978,  0.3701, -0.6934,  0.5815,  0.5161, -0.5435, -0.0564, -0.8101],\n",
      "        [ 0.6763,  0.1349, -0.4812,  0.6865,  0.7832, -0.5356, -0.3313, -0.5977],\n",
      "        [ 0.7676,  0.4678, -0.5195,  0.6431,  0.4180, -0.4893, -0.4670, -0.8179]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 69\n",
      "y_pred  = tensor([[ 1.0732,  0.2156, -0.6968,  0.2522,  0.5171, -0.9170, -0.7256, -0.7441],\n",
      "        [ 0.9775,  0.2145, -0.3306,  0.2317,  0.3240, -0.6987, -0.3218, -0.6064],\n",
      "        [ 0.6533,  0.1611, -0.0757,  0.3989,  0.8081, -0.6699, -0.3430, -0.7144],\n",
      "        [ 0.9282,  0.2676, -0.6606,  0.3032,  0.6479, -0.7856, -0.5425, -0.7847]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 4, 0], device='cuda:0')\n",
      "batch_ind = 69\n",
      "y_pred_cpu = tensor([[ 1.0732,  0.2156, -0.6968,  0.2522,  0.5171, -0.9170, -0.7256, -0.7441],\n",
      "        [ 0.9775,  0.2145, -0.3306,  0.2317,  0.3240, -0.6987, -0.3218, -0.6064],\n",
      "        [ 0.6533,  0.1611, -0.0757,  0.3989,  0.8081, -0.6699, -0.3430, -0.7144],\n",
      "        [ 0.9282,  0.2676, -0.6606,  0.3032,  0.6479, -0.7856, -0.5425, -0.7847]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 70\n",
      "y_pred  = tensor([[ 0.7520,  0.2571, -0.5439,  0.3782,  0.6274, -0.7783, -0.3713, -0.6714],\n",
      "        [ 0.7847,  0.4236, -0.7812,  0.4341,  0.4700, -0.6074, -0.2891, -0.7412],\n",
      "        [ 0.6235,  0.3359, -0.6055,  0.5288,  0.4094, -0.6055, -0.2396, -0.7544],\n",
      "        [ 0.7368, -0.1216, -0.4395,  0.2551,  0.4956, -0.7002, -0.3245, -0.5371]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 70\n",
      "y_pred_cpu = tensor([[ 0.7520,  0.2571, -0.5439,  0.3782,  0.6274, -0.7783, -0.3713, -0.6714],\n",
      "        [ 0.7847,  0.4236, -0.7812,  0.4341,  0.4700, -0.6074, -0.2891, -0.7412],\n",
      "        [ 0.6235,  0.3359, -0.6055,  0.5288,  0.4094, -0.6055, -0.2396, -0.7544],\n",
      "        [ 0.7368, -0.1216, -0.4395,  0.2551,  0.4956, -0.7002, -0.3245, -0.5371]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 71\n",
      "y_pred  = tensor([[ 0.8130,  0.4939, -0.4573,  0.4253,  0.7036, -0.7100, -0.2335, -0.8262],\n",
      "        [ 0.8486,  0.1572, -0.9155,  0.6006,  0.4426, -0.9082, -0.4670, -0.9077],\n",
      "        [ 0.8599,  0.2783, -0.7744,  0.7974,  0.7568, -0.8882, -0.4028, -0.9863],\n",
      "        [ 0.7891,  0.0314, -0.5640,  0.3284,  0.5400, -1.0693, -0.4099, -0.8970]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 71\n",
      "y_pred_cpu = tensor([[ 0.8130,  0.4939, -0.4573,  0.4253,  0.7036, -0.7100, -0.2335, -0.8262],\n",
      "        [ 0.8486,  0.1572, -0.9155,  0.6006,  0.4426, -0.9082, -0.4670, -0.9077],\n",
      "        [ 0.8599,  0.2783, -0.7744,  0.7974,  0.7568, -0.8882, -0.4028, -0.9863],\n",
      "        [ 0.7891,  0.0314, -0.5640,  0.3284,  0.5400, -1.0693, -0.4099, -0.8970]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 72\n",
      "y_pred  = tensor([[ 0.7734,  0.4717, -0.8628,  0.4343,  0.5444, -1.0039, -0.2764, -0.7979],\n",
      "        [ 0.9102,  0.3621, -0.7568,  0.4766,  0.4561, -0.5898, -0.5610, -0.7095],\n",
      "        [ 0.7271,  0.3857, -0.5078,  0.3850,  0.3770, -0.5332, -0.3379, -0.6816],\n",
      "        [ 0.9688,  0.2227, -0.5786,  0.4868,  0.5415, -0.8711, -0.3867, -0.8379]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 72\n",
      "y_pred_cpu = tensor([[ 0.7734,  0.4717, -0.8628,  0.4343,  0.5444, -1.0039, -0.2764, -0.7979],\n",
      "        [ 0.9102,  0.3621, -0.7568,  0.4766,  0.4561, -0.5898, -0.5610, -0.7095],\n",
      "        [ 0.7271,  0.3857, -0.5078,  0.3850,  0.3770, -0.5332, -0.3379, -0.6816],\n",
      "        [ 0.9688,  0.2227, -0.5786,  0.4868,  0.5415, -0.8711, -0.3867, -0.8379]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 73\n",
      "y_pred  = tensor([[ 0.7891,  0.4583, -0.8784,  0.4004,  0.6309, -0.5356, -0.6855, -1.0674],\n",
      "        [ 0.7671,  0.6401, -0.7749,  0.7402,  0.5117, -0.1506, -0.4060, -1.1025],\n",
      "        [ 0.7422,  0.1426, -0.7197,  0.4006,  0.7769, -0.7334, -0.3457, -0.8994],\n",
      "        [ 0.6865,  0.2717, -0.6260,  0.5361,  0.5547, -0.1561, -0.2059, -0.9097]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 4, 0], device='cuda:0')\n",
      "batch_ind = 73\n",
      "y_pred_cpu = tensor([[ 0.7891,  0.4583, -0.8784,  0.4004,  0.6309, -0.5356, -0.6855, -1.0674],\n",
      "        [ 0.7671,  0.6401, -0.7749,  0.7402,  0.5117, -0.1506, -0.4060, -1.1025],\n",
      "        [ 0.7422,  0.1426, -0.7197,  0.4006,  0.7769, -0.7334, -0.3457, -0.8994],\n",
      "        [ 0.6865,  0.2717, -0.6260,  0.5361,  0.5547, -0.1561, -0.2059, -0.9097]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 74\n",
      "y_pred  = tensor([[ 0.7373,  0.1262, -0.4265,  0.3040,  0.2417, -0.4983, -0.0808, -0.4778],\n",
      "        [ 0.6577,  0.2998, -0.6797,  0.6240,  0.4036, -0.2233, -0.3281, -0.8403],\n",
      "        [ 0.7363,  0.4880, -0.3289,  0.4175,  0.5195, -0.4436, -0.2274, -0.7817],\n",
      "        [ 0.7412,  0.4531, -0.4521,  0.5903,  0.2920, -0.4900, -0.2786, -0.9028]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 74\n",
      "y_pred_cpu = tensor([[ 0.7373,  0.1262, -0.4265,  0.3040,  0.2417, -0.4983, -0.0808, -0.4778],\n",
      "        [ 0.6577,  0.2998, -0.6797,  0.6240,  0.4036, -0.2233, -0.3281, -0.8403],\n",
      "        [ 0.7363,  0.4880, -0.3289,  0.4175,  0.5195, -0.4436, -0.2274, -0.7817],\n",
      "        [ 0.7412,  0.4531, -0.4521,  0.5903,  0.2920, -0.4900, -0.2786, -0.9028]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 75\n",
      "y_pred  = tensor([[ 0.7715,  0.4702, -0.5425,  0.7339,  0.5879, -0.1178, -0.2795, -0.8872],\n",
      "        [ 0.5347,  0.3726, -0.5845,  0.5737,  0.4229, -0.3196, -0.2666, -0.9883],\n",
      "        [ 0.6099,  0.4612, -0.5171,  0.3506,  0.4255, -0.1945, -0.1140, -0.7607],\n",
      "        [ 0.5093,  0.5181, -0.6338,  0.6733,  0.4480, -0.1365, -0.3203, -0.8643]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 3, 0, 3], device='cuda:0')\n",
      "batch_ind = 75\n",
      "y_pred_cpu = tensor([[ 0.7715,  0.4702, -0.5425,  0.7339,  0.5879, -0.1178, -0.2795, -0.8872],\n",
      "        [ 0.5347,  0.3726, -0.5845,  0.5737,  0.4229, -0.3196, -0.2666, -0.9883],\n",
      "        [ 0.6099,  0.4612, -0.5171,  0.3506,  0.4255, -0.1945, -0.1140, -0.7607],\n",
      "        [ 0.5093,  0.5181, -0.6338,  0.6733,  0.4480, -0.1365, -0.3203, -0.8643]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 76\n",
      "y_pred  = tensor([[ 0.5483,  0.5542, -0.5317,  0.6128,  0.3696, -0.1516, -0.2426, -0.8770],\n",
      "        [ 0.7437,  0.6167, -0.6938,  0.4988,  0.6743, -0.0247, -0.6279, -0.8481],\n",
      "        [ 0.5112,  0.3345, -0.5581,  0.6074,  0.6162, -0.2220, -0.3701, -0.7300],\n",
      "        [ 0.7124,  0.5469, -0.7534,  0.6987,  0.4797, -0.0936, -0.2389, -0.8486]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([3, 0, 4, 0], device='cuda:0')\n",
      "batch_ind = 76\n",
      "y_pred_cpu = tensor([[ 0.5483,  0.5542, -0.5317,  0.6128,  0.3696, -0.1516, -0.2426, -0.8770],\n",
      "        [ 0.7437,  0.6167, -0.6938,  0.4988,  0.6743, -0.0247, -0.6279, -0.8481],\n",
      "        [ 0.5112,  0.3345, -0.5581,  0.6074,  0.6162, -0.2220, -0.3701, -0.7300],\n",
      "        [ 0.7124,  0.5469, -0.7534,  0.6987,  0.4797, -0.0936, -0.2389, -0.8486]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 77\n",
      "y_pred  = tensor([[ 0.5947,  0.4519, -0.7705,  0.4927,  0.3813,  0.0213, -0.3638, -0.7329],\n",
      "        [ 0.4834,  0.4890, -0.6367,  0.6387,  0.5703, -0.1702, -0.5142, -0.8374],\n",
      "        [ 0.6650,  0.6768, -0.7559,  0.5166,  0.3779, -0.0974, -0.3394, -0.8281],\n",
      "        [ 0.6646,  0.5493, -0.6201,  0.3792,  0.4309,  0.0304, -0.4583, -0.7656]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 3, 1, 0], device='cuda:0')\n",
      "batch_ind = 77\n",
      "y_pred_cpu = tensor([[ 0.5947,  0.4519, -0.7705,  0.4927,  0.3813,  0.0213, -0.3638, -0.7329],\n",
      "        [ 0.4834,  0.4890, -0.6367,  0.6387,  0.5703, -0.1702, -0.5142, -0.8374],\n",
      "        [ 0.6650,  0.6768, -0.7559,  0.5166,  0.3779, -0.0974, -0.3394, -0.8281],\n",
      "        [ 0.6646,  0.5493, -0.6201,  0.3792,  0.4309,  0.0304, -0.4583, -0.7656]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 78\n",
      "y_pred  = tensor([[ 0.7422,  0.5649, -0.5029,  0.5332,  0.3667, -0.4521, -0.5127, -0.8267],\n",
      "        [ 0.7197,  0.0316, -0.4417,  0.6528,  0.4065, -0.8325, -0.1786, -0.7461],\n",
      "        [ 0.9082,  0.5454, -0.6548,  0.7578,  0.4954, -0.7002, -0.5137, -0.9375],\n",
      "        [ 0.8970,  0.2028, -0.4265,  0.6011,  0.4268, -0.7725, -0.3210, -0.7153]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([0, 0, 0, 0], device='cuda:0')\n",
      "batch_ind = 78\n",
      "y_pred_cpu = tensor([[ 0.7422,  0.5649, -0.5029,  0.5332,  0.3667, -0.4521, -0.5127, -0.8267],\n",
      "        [ 0.7197,  0.0316, -0.4417,  0.6528,  0.4065, -0.8325, -0.1786, -0.7461],\n",
      "        [ 0.9082,  0.5454, -0.6548,  0.7578,  0.4954, -0.7002, -0.5137, -0.9375],\n",
      "        [ 0.8970,  0.2028, -0.4265,  0.6011,  0.4268, -0.7725, -0.3210, -0.7153]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 79\n",
      "y_pred  = tensor([[ 0.4895,  0.3721, -0.5713,  0.6470,  0.3862, -0.1272, -0.4414, -0.7080],\n",
      "        [ 0.7012,  0.3713, -0.5938,  0.4773,  0.4097, -0.2190, -0.3528, -0.5615],\n",
      "        [ 0.5659,  0.2092, -0.2991,  0.3860,  0.5801, -0.3054, -0.5034, -0.5371],\n",
      "        [ 0.8267,  0.5903, -0.5283,  0.7446,  0.5327, -0.2058, -0.3542, -0.9634]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([3, 0, 4, 0], device='cuda:0')\n",
      "batch_ind = 79\n",
      "y_pred_cpu = tensor([[ 0.4895,  0.3721, -0.5713,  0.6470,  0.3862, -0.1272, -0.4414, -0.7080],\n",
      "        [ 0.7012,  0.3713, -0.5938,  0.4773,  0.4097, -0.2190, -0.3528, -0.5615],\n",
      "        [ 0.5659,  0.2092, -0.2991,  0.3860,  0.5801, -0.3054, -0.5034, -0.5371],\n",
      "        [ 0.8267,  0.5903, -0.5283,  0.7446,  0.5327, -0.2058, -0.3542, -0.9634]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 80\n",
      "y_pred  = tensor([[ 0.5078,  0.0746, -0.1465,  0.4915,  0.5747, -0.2285, -0.1956, -0.3193],\n",
      "        [ 0.6396,  0.2563, -0.4219,  0.4070,  0.3152, -0.0202, -0.0864, -0.3889],\n",
      "        [ 0.5317,  0.4988, -0.6304,  0.6011,  0.4402, -0.2357, -0.2676, -0.8237],\n",
      "        [ 0.4514,  0.3354, -0.4028,  0.5337,  0.5293, -0.3472, -0.1995, -0.6108]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "preds = tensor([4, 0, 3, 3], device='cuda:0')\n",
      "batch_ind = 80\n",
      "y_pred_cpu = tensor([[ 0.5078,  0.0746, -0.1465,  0.4915,  0.5747, -0.2285, -0.1956, -0.3193],\n",
      "        [ 0.6396,  0.2563, -0.4219,  0.4070,  0.3152, -0.0202, -0.0864, -0.3889],\n",
      "        [ 0.5317,  0.4988, -0.6304,  0.6011,  0.4402, -0.2357, -0.2676, -0.8237],\n",
      "        [ 0.4514,  0.3354, -0.4028,  0.5337,  0.5293, -0.3472, -0.1995, -0.6108]],\n",
      "       dtype=torch.float16)\n",
      "Debuggin\n",
      "Debuggin\n",
      "Debuggin\n",
      "inside train loop.. batch_ind = 81\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1125782/840790139.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#filepath = \"../../models/model_e33_2022_10_01_16_12_42.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#model_epcoh_55 = load_model(filepath,model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mclass_weights\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1125782/1342892305.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, val_loader, test_loader, model, classes, class_weights, num_epochs, n_channels)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0my_pred_smax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_smax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1125782/602397231.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;31m#print(\"x shape = \" + str(x.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m#print(\"x = \" +str(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/timm/models/convnext.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/timm/models/convnext.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/timm/models/convnext.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/timm/models/convnext.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/timm/models/layers/mlp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model =Model('convnext_small',224)\n",
    "#filepath = \"../../models/model_e33_2022_10_01_16_12_42.pth\"\n",
    "#model_epcoh_55 = load_model(filepath,model)\n",
    "model, lr_log = train_model(train_loader, val_loader, test_loader,model, classes ,class_weights ,num_epochs = num_epochs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3670d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x,b = torchaudio.load(\"../../data/audio/221529.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a49e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_new = MozTestDataset(df_val_offset,  config.data_dir, min_length)\n",
    "val_loader_new = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=2,\n",
    "        num_workers=0, pin_memory=pin_memory  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4774bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_iter = iter(val_loader_new)\n",
    "x1,y1 = val_iter.next()\n",
    "print(x1.shape)\n",
    "model = model_epcoh_10\n",
    "model.to('cuda')\n",
    "x_g = x1.to('cuda')\n",
    "model(x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b70494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error = df_val_offset\n",
    "model = model_epcoh_10\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "for idx,(x,y) in enumerate(val_dataset):\n",
    "    print(idx)\n",
    "    print(y)\n",
    "    x = x.to('cuda').float()\n",
    "    print(\"x shape = \" +str(x.shape))\n",
    "    #x_new = x.unsqueeze(dim = 1)\n",
    "    print(\"x_new shape = \" +str(x_new.shape))\n",
    "    x_new = x.to('cuda')\n",
    "    y_pred = model(x_new)['prediction']\n",
    "    y_pred_cpu = y_pred.cpu().detach()\n",
    "    preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "    df_erroriloc[idx]['y_hat'] = preds\n",
    "    del x_new\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cc5502",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,15360)\n",
    "x = x.unsqueeze(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4e5974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_offset.head()\n",
    "path_temp = \"../data/audio/\"\n",
    "for i,row in df_val_offset.iterrows():\n",
    "    print(\"i = \" +str(i))\n",
    "    print(\"id = \" + str(int(row['id'])))\n",
    "    file = str(int(row['id']))+\".wav\"\n",
    "    print(file)\n",
    "    path = path_temp + file\n",
    "    waveform, inp_rate = torchaudio.load(path)\n",
    "    if inp_rate != config.rate:\n",
    "        import torchaudio.transforms as T\n",
    "        resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "        waveform = resampler(waveform)\n",
    "    if waveform.shape[1] < config.rate*min_length:\n",
    "        #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "        f_out = pad_mean(waveform)\n",
    "    else:\n",
    "        f = waveform[0]\n",
    "        f_out = f.unsqueeze(0)\n",
    "    \n",
    "    \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor(df):\n",
    "    \n",
    "    path_name = \"../data/audio/\"\n",
    "    file = df.loc[idx]['id'])}.wav\")\n",
    "    waveform, inp_rate = torchaudio.load(path)\n",
    "        \n",
    "        if inp_rate != config.rate:\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "            waveform = resampler(waveform)\n",
    "    \n",
    "        \n",
    "        #waveform, rate = torchaudio.load(path)\n",
    "                \n",
    "        if waveform.shape[1] < config.rate*self.min_length:\n",
    "            #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "            f_out = pad_mean(waveform)\n",
    "        else:\n",
    "            f = waveform[0]\n",
    "            f_out = f.unsqueeze(0)\n",
    "            \n",
    "        return f_out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #real_idx = idx % len(self.audio_df)\n",
    "        if DEBUG:\n",
    "            print(\"\")\n",
    "            print(\"idx = \" + str(idx))\n",
    "        x = self._get_sample_(os.path.join(self.data_dir,f\"{int(self.audio_df.loc[idx]['id'])}.wav\"), resample=config.rate)\n",
    "        \n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"shape of x post augmentation = \" + str(x.shape))\n",
    "            \n",
    "        \n",
    "        # random noise on even number indexes\n",
    "        offset = int(self.audio_df.loc[idx]['offset'])\n",
    "        if DEBUG:\n",
    "            print(\"returning x of shape ...\" + str(x[:,offset:int(offset+config.rate*self.min_length)].shape))\n",
    "        \n",
    "        return (x[:,offset:int(offset+config.rate*self.min_length)],self.audio_df.loc[idx]['specie_ind'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59367aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the model checkpoint as a parameter as input\n",
    "# read the val df\n",
    "#get the tensor rep for the offset.\n",
    "#pass it to the model get add get the prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f128fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "pred = []\n",
    "for i in range(10):\n",
    "    label.append(np.random.rand(9))\n",
    "    pred.append(np.random.rand(9))\n",
    "print(label)\n",
    "print(pred)\n",
    "print(classification_report(label, pred, target_names= classes, labels= classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e32b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.tensor(8, device = \"cuda\")\n",
    "print(label)\n",
    "label_cpu = label.cpu().detach()\n",
    "print(label_cpu)\n",
    "label_np = label_cpu.numpy()\n",
    "print(type(label_np))\n",
    "label_np_item = label_np.item()\n",
    "print(type(label_np_item))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f10399",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.randn(4,9)\n",
    "y_pred.shape\n",
    "#y_pred_np = y_pred.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b3a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_np\n",
    "# y_pred_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0031706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(y_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d738b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63031e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c7ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,(x,y) in enumerate(test_loader):\n",
    "    print(\"idx = \" + str(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c36a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62269fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbadca76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
